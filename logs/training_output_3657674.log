Training set erstellt: /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/data_training/train_metadataHC_0.720251103_1640.csv (1955 Patienten)
Test set erstellt: /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/data_training/test_metadataHC_0.720251103_1640.csv (2213 Patienten, davon 838 HC und 1375 andere)
Only one CUDA device found. Using cuda:0

####################################################################################################

Starting Catatonia CPA training session NormativeVAE20_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_20251103_1640_HC_columnwise at 2025-11-03_18-40
----------------------------------------------------------------------------------------------------------------------------------------------------------------

Using Device:        cuda:0
Queued Epochs:       250
Batch Size:          32
Data Summary:        ['/net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/data_training/train_metadataHC_0.720251103_1640.csv']
MRI Data Directory:  /net/data.isilon/ag-cherrmann/lduttenhoefer/project/CAT12_newvals/QC/CAT12_results_final.csv
Loading Model:       False
Output Directory:    /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640

More details in log file: /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/logs/2025-11-03_18-40_NormativeVAE20_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_20251103_1640_HC_columnwise_training_log_.txt

####################################################################################################
Starting normative modeling with atlas: lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux, epochs: 250, bootstraps: 80
Normalization method: columnwise
Configuration saved to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/config.csv
Using device: cuda
Loading NORM control data...
================================================================================
[INFO] Loading PRE-NORMALIZED MRI data
================================================================================
[INFO] Selected atlases: ['lpba40', 'neuromorphometrics', 'ibsr', 'aparc_dk40', 'aparc_destrieux']
[INFO] Target volume types: ['Vgm', 'G', 'T']
[INFO] Loading metadata from: ['/net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/data_training/train_metadataHC_0.720251103_1640.csv']
[INFO] Loaded metadata with 1955 subjects
[INFO] Filtered to 1955 subjects with diagnoses: ['HC']
[INFO] Loading pre-normalized MRI data from: /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/data_training/CAT12_results_NORMALIZED_columnwise_HC_separate_TRAIN.csv
[INFO] Loaded MRI data with shape: (1954, 1211)
[INFO] Found 1194 total ROI columns in MRI data
[INFO] Filtering columns by selected atlases and volume types...
[INFO] Processing atlas: lpba40 (prefix: lpba40)
[INFO] Found 56 columns for atlas lpba40
[INFO] Processing atlas: neuromorphometrics (prefix: Neurom)
[INFO] Found 123 columns for atlas neuromorphometrics
[INFO] Processing atlas: ibsr (prefix: IBSR)
[INFO] Found 32 columns for atlas ibsr
[INFO] Processing atlas: aparc_dk40 (prefix: DK40)
[INFO] Found 137 columns for atlas aparc_dk40
[INFO] Processing atlas: aparc_destrieux (prefix: Destrieux)
[INFO] Found 296 columns for atlas aparc_destrieux
[INFO] Selected 644 feature columns total after filtering
[INFO]   - Vgm: 211 features
[INFO]   - G: 216 features
[INFO]   - T: 217 features
[INFO] Matching metadata subjects with MRI data...
[INFO] Successfully matched 1954/1955 subjects
[WARNING] 1 subjects not found in MRI data
[WARNING] Unmatched: ['sub-031461_T1w']
[INFO] Total subjects processed: 1954
[INFO] Total ROI features per subject: 644
[INFO] Data loading complete!
================================================================================
[DEBUG] Data shape: torch.Size([1954, 644])
[DEBUG] Data min: -7.208443641662598
[DEBUG] Data max: 8.865362167358398
[DEBUG] Data mean: -1.9401245887618046e-10
[DEBUG] Data std: 0.9997444748878479
[DEBUG] Has NaN: False
[DEBUG] Has Inf: False
[DEBUG] Sample values: tensor([0.3622, 0.4168, 0.2031, 0.1700, 0.1494, 1.0642, 1.0130, 0.6701, 0.8466,
        0.3796])
Number of ROIs in atlas: 644
[INFO] 1560 subjects in training set
[INFO] 390 subjects in validation set
[WARNING] 4 subjects not found in annotations:
  - sub-031704_T1w
  - sub-NDARINVEY033HCZ_run01_T1w
  - sub-031705_T1w
  - sub-NDARINVKC627BAV_run01_T1w
                        Filename Data_Type  ... NSS_Motor NSS_Total
0                       sub-0001     train  ...       NaN       NaN
1                       sub-0004     train  ...       NaN       NaN
2                       sub-0011     train  ...       NaN       NaN
3                       sub-0013     train  ...       NaN       NaN
4                       sub-0016     train  ...       NaN       NaN
...                          ...       ...  ...       ...       ...
1946           sub-NM5946_0_MPR1     valid  ...       NaN       NaN
1947           sub-NM7365_0_MPR1     valid  ...       NaN       NaN
1948           sub-NM8356_0_MPR1     valid  ...       NaN       NaN
1949  sub-whiteCAT191_ses-01_T1w     valid  ...       0.0       3.0
1950  sub-whiteCAT200_ses-01_T1w     valid  ...       1.0       9.0

[1951 rows x 21 columns]
Using atlas: ['lpba40', 'neuromorphometrics', 'ibsr', 'aparc_dk40', 'aparc_destrieux']
Number of ROIs: 644
---------------
Data Processing
---------------
Loading Data
  Training Data:       1560 subjects loaded
  Validation Data:      390 subjects loaded

Creating Model
--------------
Training data shape: torch.Size([1560, 644])
Validation data shape: torch.Size([390, 644])
/net/data.isilon/ag-cherrmann/lduttenhoefer/project/miniconda3/envs/LISA_ba_env/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/src/models/ContrastVAE_2D.py:137: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = GradScaler()
Model Archtecture: 
NormativeVAE_2D(
  (encoder): Sequential(
    (0): Linear(in_features=644, out_features=100, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=100, out_features=100, bias=True)
    (4): LeakyReLU(negative_slope=0.01)
    (5): Dropout(p=0.1, inplace=False)
    (6): Linear(in_features=100, out_features=20, bias=True)
  )
  (fc_mu): Linear(in_features=20, out_features=20, bias=True)
  (fc_var): Linear(in_features=20, out_features=20, bias=True)
  (decoder): Sequential(
    (0): Linear(in_features=20, out_features=100, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=100, out_features=100, bias=True)
    (4): LeakyReLU(negative_slope=0.01)
    (5): Dropout(p=0.1, inplace=False)
    (6): Linear(in_features=100, out_features=644, bias=True)
  )
)

    latent_dim:          20
    optimizer:           Adam (
    scheduler:           <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x2ab1ac23c450>
    scaler:              <torch.cuda.amp.grad_scaler.GradScaler object at 0x2ab1af7b95d0>
    recon_loss_weight:   16.6449
    kldiv_loss_weight:   1.2
    contr_loss_weight:   0.0
    schedule_on_validation: True
    scheduler_patience:  10
    scheduler_factor:    0.5
    learning_rate:       0.000559
    weight_decay:        1e-05
    dropout_prob:        0.1
    device:              cuda
    Total Parameters:    154,704
    Trainable Params:    154,704
Training baseline model before bootstrap training...
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9466, Val Loss: 0.7143, Recon: 0.9466, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7031, Val Loss: 4.6497, Recon: 0.8276, KL: 3.8755, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4640, Val Loss: 9.4163, Recon: 0.8047, KL: 8.6592, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2321, Val Loss: 14.2023, Recon: 0.7805, KL: 13.4516, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0376, Val Loss: 18.9900, Recon: 0.7848, KL: 18.2528, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8385, Val Loss: 23.7942, Recon: 0.7775, KL: 23.0610, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6170, Val Loss: 28.5874, Recon: 0.7644, KL: 27.8526, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4015, Val Loss: 33.3825, Recon: 0.7559, KL: 32.6457, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2104, Val Loss: 38.2021, Recon: 0.7578, KL: 37.4526, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0154, Val Loss: 42.9776, Recon: 0.7580, KL: 42.2574, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8095, Val Loss: 47.7930, Recon: 0.7600, KL: 47.0495, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7631, Val Loss: 48.7263, Recon: 0.7556, KL: 48.0075, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7535, Val Loss: 48.7149, Recon: 0.7495, KL: 48.0039, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7577, Val Loss: 48.7361, Recon: 0.7522, KL: 48.0055, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7601, Val Loss: 48.7287, Recon: 0.7477, KL: 48.0124, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7551, Val Loss: 48.7278, Recon: 0.7490, KL: 48.0061, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7518, Val Loss: 48.7379, Recon: 0.7387, KL: 48.0130, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7465, Val Loss: 48.7224, Recon: 0.7379, KL: 48.0086, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7374, Val Loss: 48.7181, Recon: 0.7327, KL: 48.0048, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7420, Val Loss: 48.7088, Recon: 0.7369, KL: 48.0051, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7304, Val Loss: 48.7104, Recon: 0.7278, KL: 48.0026, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7480, Val Loss: 48.7134, Recon: 0.7434, KL: 48.0046, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7420, Val Loss: 48.7169, Recon: 0.7374, KL: 48.0047, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7268, Val Loss: 48.7038, Recon: 0.7237, KL: 48.0030, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7505, Val Loss: 48.7215, Recon: 0.7413, KL: 48.0093, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7364, Val Loss: 48.7146, Recon: 0.7310, KL: 48.0054, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7330, Val Loss: 48.7039, Recon: 0.7303, KL: 48.0027, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7319, Val Loss: 48.7115, Recon: 0.7278, KL: 48.0040, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7384, Val Loss: 48.7104, Recon: 0.7316, KL: 48.0068, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7278, Val Loss: 48.7016, Recon: 0.7252, KL: 48.0026, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7225, Val Loss: 48.7106, Recon: 0.7189, KL: 48.0036, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7198, Val Loss: 48.7092, Recon: 0.7168, KL: 48.0030, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7402, Val Loss: 48.7236, Recon: 0.7299, KL: 48.0102, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7293, Val Loss: 48.7066, Recon: 0.7267, KL: 48.0026, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7178, Val Loss: 48.7006, Recon: 0.7161, KL: 48.0017, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7231, Val Loss: 48.7009, Recon: 0.7168, KL: 48.0063, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7351, Val Loss: 48.7007, Recon: 0.7327, KL: 48.0024, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7170, Val Loss: 48.6949, Recon: 0.7136, KL: 48.0034, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7217, Val Loss: 48.7094, Recon: 0.7168, KL: 48.0049, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7236, Val Loss: 48.7061, Recon: 0.7167, KL: 48.0069, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7215, Val Loss: 48.7075, Recon: 0.7093, KL: 48.0121, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7091, Val Loss: 48.6889, Recon: 0.7065, KL: 48.0027, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7051, Val Loss: 48.6889, Recon: 0.7018, KL: 48.0033, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7034, Val Loss: 48.6729, Recon: 0.6997, KL: 48.0037, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7127, Val Loss: 48.6862, Recon: 0.7082, KL: 48.0045, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7006, Val Loss: 48.6794, Recon: 0.6982, KL: 48.0024, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7162, Val Loss: 48.6996, Recon: 0.7101, KL: 48.0061, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6960, Val Loss: 48.6802, Recon: 0.6925, KL: 48.0036, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6933, Val Loss: 48.6815, Recon: 0.6899, KL: 48.0034, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6978, Val Loss: 48.6787, Recon: 0.6944, KL: 48.0034, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6951, Val Loss: 48.6766, Recon: 0.6905, KL: 48.0046, KL_weight: 4.8000
Training bootstrap models...
Starting bootstrap training with 80 iterations
KL warmup will occur over first 50 epochs
Training bootstrap model 1/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9565, Val Loss: 0.7663, Recon: 0.9565, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6770, Val Loss: 4.6462, Recon: 0.8114, KL: 3.8656, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4381, Val Loss: 9.4233, Recon: 0.7830, KL: 8.6550, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2320, Val Loss: 14.2149, Recon: 0.7744, KL: 13.4576, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0080, Val Loss: 18.9887, Recon: 0.7611, KL: 18.2469, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8197, Val Loss: 23.7959, Recon: 0.7589, KL: 23.0607, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6084, Val Loss: 28.5670, Recon: 0.7599, KL: 27.8484, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4060, Val Loss: 33.3824, Recon: 0.7514, KL: 32.6546, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1906, Val Loss: 38.1693, Recon: 0.7441, KL: 37.4465, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9900, Val Loss: 42.9911, Recon: 0.7466, KL: 42.2433, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7808, Val Loss: 47.7675, Recon: 0.7349, KL: 47.0459, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7403, Val Loss: 48.7318, Recon: 0.7303, KL: 48.0100, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7322, Val Loss: 48.7406, Recon: 0.7279, KL: 48.0043, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7442, Val Loss: 48.7194, Recon: 0.7366, KL: 48.0077, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7332, Val Loss: 48.7335, Recon: 0.7282, KL: 48.0051, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7323, Val Loss: 48.7274, Recon: 0.7252, KL: 48.0072, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7268, Val Loss: 48.7250, Recon: 0.7219, KL: 48.0049, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7243, Val Loss: 48.7247, Recon: 0.7195, KL: 48.0047, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7284, Val Loss: 48.7284, Recon: 0.7227, KL: 48.0057, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7400, Val Loss: 48.7253, Recon: 0.7257, KL: 48.0143, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7174, Val Loss: 48.7238, Recon: 0.7153, KL: 48.0021, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7282, Val Loss: 48.7126, Recon: 0.7229, KL: 48.0053, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7255, Val Loss: 48.7200, Recon: 0.7221, KL: 48.0034, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7255, Val Loss: 48.7275, Recon: 0.7188, KL: 48.0067, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7333, Val Loss: 48.7311, Recon: 0.7237, KL: 48.0097, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7175, Val Loss: 48.7176, Recon: 0.7151, KL: 48.0024, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7125, Val Loss: 48.7178, Recon: 0.7089, KL: 48.0036, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7111, Val Loss: 48.7063, Recon: 0.7087, KL: 48.0024, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7211, Val Loss: 48.7082, Recon: 0.7196, KL: 48.0014, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7072, Val Loss: 48.7041, Recon: 0.7045, KL: 48.0027, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7401, Val Loss: 48.7313, Recon: 0.7289, KL: 48.0113, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7170, Val Loss: 48.7112, Recon: 0.7146, KL: 48.0024, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7194, Val Loss: 48.7173, Recon: 0.7150, KL: 48.0044, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7197, Val Loss: 48.7156, Recon: 0.7182, KL: 48.0015, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7125, Val Loss: 48.7058, Recon: 0.7098, KL: 48.0027, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7134, Val Loss: 48.7093, Recon: 0.7101, KL: 48.0033, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7062, Val Loss: 48.7053, Recon: 0.7014, KL: 48.0047, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7098, Val Loss: 48.7022, Recon: 0.7062, KL: 48.0036, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7087, Val Loss: 48.6985, Recon: 0.7061, KL: 48.0027, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7169, Val Loss: 48.7051, Recon: 0.7116, KL: 48.0052, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7096, Val Loss: 48.7064, Recon: 0.7039, KL: 48.0056, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7059, Val Loss: 48.7141, Recon: 0.6992, KL: 48.0067, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7155, Val Loss: 48.7083, Recon: 0.7098, KL: 48.0057, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7066, Val Loss: 48.7052, Recon: 0.7039, KL: 48.0026, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7060, Val Loss: 48.7014, Recon: 0.7043, KL: 48.0017, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7050, Val Loss: 48.6941, Recon: 0.7023, KL: 48.0027, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7048, Val Loss: 48.7040, Recon: 0.7031, KL: 48.0017, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7057, Val Loss: 48.7047, Recon: 0.7015, KL: 48.0042, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7073, Val Loss: 48.7046, Recon: 0.7043, KL: 48.0030, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7030, Val Loss: 48.7095, Recon: 0.7002, KL: 48.0029, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.7051, Val Loss: 48.7001, Recon: 0.7014, KL: 48.0037, KL_weight: 4.8000
Saved model 1 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_0.pt
Training bootstrap model 2/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9845, Val Loss: 0.7204, Recon: 0.9845, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7136, Val Loss: 4.6396, Recon: 0.8438, KL: 3.8698, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4656, Val Loss: 9.4070, Recon: 0.8080, KL: 8.6576, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2496, Val Loss: 14.1985, Recon: 0.7911, KL: 13.4584, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0580, Val Loss: 18.9870, Recon: 0.7938, KL: 18.2643, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8248, Val Loss: 23.7809, Recon: 0.7766, KL: 23.0482, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6256, Val Loss: 28.5948, Recon: 0.7747, KL: 27.8510, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4296, Val Loss: 33.3717, Recon: 0.7750, KL: 32.6546, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2091, Val Loss: 38.1721, Recon: 0.7595, KL: 37.4496, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0286, Val Loss: 42.9670, Recon: 0.7785, KL: 42.2502, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8066, Val Loss: 47.7521, Recon: 0.7588, KL: 47.0479, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7673, Val Loss: 48.7244, Recon: 0.7609, KL: 48.0065, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7641, Val Loss: 48.7253, Recon: 0.7539, KL: 48.0103, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7514, Val Loss: 48.7081, Recon: 0.7467, KL: 48.0047, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7459, Val Loss: 48.7179, Recon: 0.7435, KL: 48.0024, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7677, Val Loss: 48.7165, Recon: 0.7549, KL: 48.0128, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7399, Val Loss: 48.7060, Recon: 0.7365, KL: 48.0034, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7683, Val Loss: 48.7190, Recon: 0.7591, KL: 48.0092, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7465, Val Loss: 48.7200, Recon: 0.7390, KL: 48.0075, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7431, Val Loss: 48.7300, Recon: 0.7352, KL: 48.0078, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7302, Val Loss: 48.7089, Recon: 0.7255, KL: 48.0047, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7226, Val Loss: 48.7116, Recon: 0.7167, KL: 48.0059, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7513, Val Loss: 48.7074, Recon: 0.7447, KL: 48.0066, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7244, Val Loss: 48.7152, Recon: 0.7206, KL: 48.0038, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7242, Val Loss: 48.7170, Recon: 0.7207, KL: 48.0035, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7183, Val Loss: 48.6894, Recon: 0.7134, KL: 48.0049, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7211, Val Loss: 48.7134, Recon: 0.7149, KL: 48.0062, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7189, Val Loss: 48.7009, Recon: 0.7160, KL: 48.0029, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7079, Val Loss: 48.6801, Recon: 0.7027, KL: 48.0052, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7086, Val Loss: 48.6906, Recon: 0.7025, KL: 48.0061, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7089, Val Loss: 48.6939, Recon: 0.7051, KL: 48.0039, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7106, Val Loss: 48.6935, Recon: 0.7034, KL: 48.0071, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6992, Val Loss: 48.6899, Recon: 0.6959, KL: 48.0033, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6987, Val Loss: 48.6870, Recon: 0.6950, KL: 48.0037, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7042, Val Loss: 48.6898, Recon: 0.7006, KL: 48.0036, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6967, Val Loss: 48.6842, Recon: 0.6919, KL: 48.0048, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6978, Val Loss: 48.6907, Recon: 0.6935, KL: 48.0043, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7133, Val Loss: 48.7120, Recon: 0.7042, KL: 48.0091, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7018, Val Loss: 48.6850, Recon: 0.6984, KL: 48.0035, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6982, Val Loss: 48.6741, Recon: 0.6931, KL: 48.0050, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6917, Val Loss: 48.6961, Recon: 0.6880, KL: 48.0036, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6982, Val Loss: 48.6812, Recon: 0.6943, KL: 48.0039, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7008, Val Loss: 48.6870, Recon: 0.6950, KL: 48.0058, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6951, Val Loss: 48.6738, Recon: 0.6916, KL: 48.0035, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6881, Val Loss: 48.6725, Recon: 0.6838, KL: 48.0043, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7027, Val Loss: 48.6869, Recon: 0.6957, KL: 48.0070, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7126, Val Loss: 48.6920, Recon: 0.7011, KL: 48.0115, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6904, Val Loss: 48.6882, Recon: 0.6858, KL: 48.0046, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6914, Val Loss: 48.6763, Recon: 0.6875, KL: 48.0039, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6886, Val Loss: 48.6805, Recon: 0.6853, KL: 48.0033, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6932, Val Loss: 48.6765, Recon: 0.6898, KL: 48.0033, KL_weight: 4.8000
Saved model 2 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_1.pt
Training bootstrap model 3/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9364, Val Loss: 0.7148, Recon: 0.9364, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6761, Val Loss: 4.6278, Recon: 0.8066, KL: 3.8695, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4438, Val Loss: 9.3956, Recon: 0.7855, KL: 8.6582, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2174, Val Loss: 14.2117, Recon: 0.7627, KL: 13.4546, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0104, Val Loss: 19.0097, Recon: 0.7579, KL: 18.2525, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8093, Val Loss: 23.7792, Recon: 0.7594, KL: 23.0499, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.5941, Val Loss: 28.5867, Recon: 0.7471, KL: 27.8470, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3843, Val Loss: 33.3663, Recon: 0.7397, KL: 32.6446, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2073, Val Loss: 38.1889, Recon: 0.7549, KL: 37.4525, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9865, Val Loss: 42.9644, Recon: 0.7409, KL: 42.2456, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7856, Val Loss: 47.7594, Recon: 0.7363, KL: 47.0493, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7446, Val Loss: 48.7380, Recon: 0.7343, KL: 48.0103, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7489, Val Loss: 48.7445, Recon: 0.7385, KL: 48.0104, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7489, Val Loss: 48.7225, Recon: 0.7444, KL: 48.0045, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7359, Val Loss: 48.7234, Recon: 0.7312, KL: 48.0047, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7238, Val Loss: 48.7208, Recon: 0.7200, KL: 48.0038, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7228, Val Loss: 48.7202, Recon: 0.7216, KL: 48.0012, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7307, Val Loss: 48.7400, Recon: 0.7239, KL: 48.0068, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7326, Val Loss: 48.7284, Recon: 0.7221, KL: 48.0105, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7219, Val Loss: 48.7054, Recon: 0.7165, KL: 48.0054, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7294, Val Loss: 48.7370, Recon: 0.7232, KL: 48.0062, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7215, Val Loss: 48.7192, Recon: 0.7195, KL: 48.0019, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7321, Val Loss: 48.7301, Recon: 0.7274, KL: 48.0046, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7295, Val Loss: 48.7061, Recon: 0.7248, KL: 48.0047, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7162, Val Loss: 48.7091, Recon: 0.7136, KL: 48.0026, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7089, Val Loss: 48.7009, Recon: 0.7070, KL: 48.0019, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7168, Val Loss: 48.6969, Recon: 0.7134, KL: 48.0034, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7134, Val Loss: 48.7080, Recon: 0.7084, KL: 48.0050, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7114, Val Loss: 48.7131, Recon: 0.7086, KL: 48.0028, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7201, Val Loss: 48.7035, Recon: 0.7169, KL: 48.0032, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7123, Val Loss: 48.7089, Recon: 0.7105, KL: 48.0018, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7069, Val Loss: 48.7090, Recon: 0.7027, KL: 48.0042, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7117, Val Loss: 48.7037, Recon: 0.7070, KL: 48.0047, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7101, Val Loss: 48.6980, Recon: 0.7049, KL: 48.0052, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7084, Val Loss: 48.7024, Recon: 0.7071, KL: 48.0013, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7049, Val Loss: 48.6960, Recon: 0.7024, KL: 48.0025, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7096, Val Loss: 48.6967, Recon: 0.7084, KL: 48.0012, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7232, Val Loss: 48.7190, Recon: 0.7109, KL: 48.0123, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7075, Val Loss: 48.7017, Recon: 0.7060, KL: 48.0015, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7147, Val Loss: 48.6972, Recon: 0.7097, KL: 48.0050, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7054, Val Loss: 48.7006, Recon: 0.7033, KL: 48.0021, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7083, Val Loss: 48.6978, Recon: 0.7051, KL: 48.0032, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7011, Val Loss: 48.6978, Recon: 0.6998, KL: 48.0013, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7076, Val Loss: 48.7353, Recon: 0.7030, KL: 48.0046, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7191, Val Loss: 48.7024, Recon: 0.7138, KL: 48.0052, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7057, Val Loss: 48.7039, Recon: 0.7038, KL: 48.0020, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7098, Val Loss: 48.7017, Recon: 0.7058, KL: 48.0039, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7035, Val Loss: 48.7023, Recon: 0.7004, KL: 48.0031, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7105, Val Loss: 48.7036, Recon: 0.7049, KL: 48.0055, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6933, Val Loss: 48.6940, Recon: 0.6919, KL: 48.0014, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6966, Val Loss: 48.6959, Recon: 0.6943, KL: 48.0023, KL_weight: 4.8000
Saved model 3 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_2.pt
Training bootstrap model 4/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 1.0144, Val Loss: 0.7664, Recon: 1.0144, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7427, Val Loss: 4.6800, Recon: 0.8539, KL: 3.8888, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4919, Val Loss: 9.4342, Recon: 0.8321, KL: 8.6598, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2699, Val Loss: 14.2286, Recon: 0.8142, KL: 13.4558, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0566, Val Loss: 19.0326, Recon: 0.7983, KL: 18.2583, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8324, Val Loss: 23.8072, Recon: 0.7859, KL: 23.0465, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6372, Val Loss: 28.5933, Recon: 0.7836, KL: 27.8535, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4134, Val Loss: 33.3840, Recon: 0.7681, KL: 32.6453, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2164, Val Loss: 38.1759, Recon: 0.7691, KL: 37.4473, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0177, Val Loss: 42.9673, Recon: 0.7688, KL: 42.2489, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8214, Val Loss: 47.7960, Recon: 0.7705, KL: 47.0509, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.8185, Val Loss: 48.7713, Recon: 0.7750, KL: 48.0435, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7638, Val Loss: 48.7366, Recon: 0.7604, KL: 48.0034, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7759, Val Loss: 48.7342, Recon: 0.7697, KL: 48.0062, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7594, Val Loss: 48.7322, Recon: 0.7542, KL: 48.0052, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7470, Val Loss: 48.7222, Recon: 0.7436, KL: 48.0033, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7504, Val Loss: 48.7169, Recon: 0.7430, KL: 48.0074, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7475, Val Loss: 48.7141, Recon: 0.7426, KL: 48.0049, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7410, Val Loss: 48.7120, Recon: 0.7336, KL: 48.0074, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7372, Val Loss: 48.7276, Recon: 0.7335, KL: 48.0037, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7427, Val Loss: 48.7226, Recon: 0.7376, KL: 48.0051, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7368, Val Loss: 48.7201, Recon: 0.7322, KL: 48.0046, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7428, Val Loss: 48.7247, Recon: 0.7377, KL: 48.0051, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7277, Val Loss: 48.7075, Recon: 0.7252, KL: 48.0025, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7338, Val Loss: 48.7359, Recon: 0.7292, KL: 48.0046, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7316, Val Loss: 48.7157, Recon: 0.7277, KL: 48.0038, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7414, Val Loss: 48.7352, Recon: 0.7311, KL: 48.0103, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7334, Val Loss: 48.7272, Recon: 0.7263, KL: 48.0071, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7280, Val Loss: 48.7247, Recon: 0.7245, KL: 48.0035, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7135, Val Loss: 48.7037, Recon: 0.7108, KL: 48.0026, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7302, Val Loss: 48.7125, Recon: 0.7257, KL: 48.0045, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7227, Val Loss: 48.7047, Recon: 0.7167, KL: 48.0060, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7243, Val Loss: 48.7066, Recon: 0.7185, KL: 48.0058, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7150, Val Loss: 48.7354, Recon: 0.7101, KL: 48.0049, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7150, Val Loss: 48.7121, Recon: 0.7083, KL: 48.0067, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7172, Val Loss: 48.7059, Recon: 0.7127, KL: 48.0045, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7121, Val Loss: 48.7105, Recon: 0.7058, KL: 48.0063, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7055, Val Loss: 48.7107, Recon: 0.7019, KL: 48.0036, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7018, Val Loss: 48.6925, Recon: 0.6961, KL: 48.0058, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7166, Val Loss: 48.6917, Recon: 0.7126, KL: 48.0040, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7170, Val Loss: 48.7099, Recon: 0.7028, KL: 48.0143, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7001, Val Loss: 48.7122, Recon: 0.6964, KL: 48.0037, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6945, Val Loss: 48.6920, Recon: 0.6906, KL: 48.0039, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7005, Val Loss: 48.7187, Recon: 0.6945, KL: 48.0060, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7033, Val Loss: 48.6874, Recon: 0.7003, KL: 48.0030, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6953, Val Loss: 48.6963, Recon: 0.6924, KL: 48.0029, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7048, Val Loss: 48.6811, Recon: 0.7010, KL: 48.0038, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7012, Val Loss: 48.6811, Recon: 0.6942, KL: 48.0069, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7100, Val Loss: 48.6994, Recon: 0.7036, KL: 48.0064, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6944, Val Loss: 48.6963, Recon: 0.6896, KL: 48.0048, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6931, Val Loss: 48.7021, Recon: 0.6891, KL: 48.0040, KL_weight: 4.8000
Saved model 4 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_3.pt
Training bootstrap model 5/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9600, Val Loss: 0.7386, Recon: 0.9600, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7005, Val Loss: 4.6387, Recon: 0.8281, KL: 3.8724, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4516, Val Loss: 9.4175, Recon: 0.7927, KL: 8.6589, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2227, Val Loss: 14.1918, Recon: 0.7730, KL: 13.4497, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0133, Val Loss: 18.9870, Recon: 0.7640, KL: 18.2493, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8062, Val Loss: 23.8022, Recon: 0.7587, KL: 23.0474, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6092, Val Loss: 28.5827, Recon: 0.7591, KL: 27.8501, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4090, Val Loss: 33.3838, Recon: 0.7585, KL: 32.6505, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1925, Val Loss: 38.1598, Recon: 0.7460, KL: 37.4465, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9955, Val Loss: 42.9721, Recon: 0.7471, KL: 42.2485, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7959, Val Loss: 47.7615, Recon: 0.7453, KL: 47.0506, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7524, Val Loss: 48.7221, Recon: 0.7443, KL: 48.0081, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7458, Val Loss: 48.7244, Recon: 0.7392, KL: 48.0066, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7420, Val Loss: 48.7360, Recon: 0.7360, KL: 48.0060, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7343, Val Loss: 48.7319, Recon: 0.7266, KL: 48.0077, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7348, Val Loss: 48.7157, Recon: 0.7278, KL: 48.0070, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7231, Val Loss: 48.7157, Recon: 0.7196, KL: 48.0036, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7488, Val Loss: 48.7508, Recon: 0.7430, KL: 48.0059, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7298, Val Loss: 48.7134, Recon: 0.7249, KL: 48.0049, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7319, Val Loss: 48.7217, Recon: 0.7253, KL: 48.0066, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7278, Val Loss: 48.7206, Recon: 0.7213, KL: 48.0065, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7215, Val Loss: 48.7087, Recon: 0.7185, KL: 48.0030, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7247, Val Loss: 48.7156, Recon: 0.7189, KL: 48.0057, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7334, Val Loss: 48.7339, Recon: 0.7262, KL: 48.0072, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7205, Val Loss: 48.7058, Recon: 0.7156, KL: 48.0049, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7107, Val Loss: 48.6923, Recon: 0.7082, KL: 48.0024, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7041, Val Loss: 48.6971, Recon: 0.7018, KL: 48.0024, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7107, Val Loss: 48.7029, Recon: 0.7079, KL: 48.0028, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7288, Val Loss: 48.7068, Recon: 0.7165, KL: 48.0124, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7065, Val Loss: 48.6894, Recon: 0.7033, KL: 48.0032, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7026, Val Loss: 48.6865, Recon: 0.6993, KL: 48.0033, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6983, Val Loss: 48.6934, Recon: 0.6960, KL: 48.0023, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7071, Val Loss: 48.6997, Recon: 0.7023, KL: 48.0048, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6986, Val Loss: 48.6839, Recon: 0.6962, KL: 48.0023, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6963, Val Loss: 48.6824, Recon: 0.6924, KL: 48.0039, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7159, Val Loss: 48.7132, Recon: 0.6970, KL: 48.0190, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6962, Val Loss: 48.6835, Recon: 0.6939, KL: 48.0023, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6971, Val Loss: 48.6939, Recon: 0.6911, KL: 48.0060, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6997, Val Loss: 48.6845, Recon: 0.6964, KL: 48.0033, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6880, Val Loss: 48.6966, Recon: 0.6858, KL: 48.0021, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6882, Val Loss: 48.6826, Recon: 0.6849, KL: 48.0033, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6945, Val Loss: 48.6786, Recon: 0.6888, KL: 48.0056, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6912, Val Loss: 48.6766, Recon: 0.6891, KL: 48.0021, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6938, Val Loss: 48.6838, Recon: 0.6877, KL: 48.0061, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6840, Val Loss: 48.6729, Recon: 0.6804, KL: 48.0036, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6817, Val Loss: 48.6808, Recon: 0.6790, KL: 48.0027, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6734, Val Loss: 48.6789, Recon: 0.6706, KL: 48.0028, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6899, Val Loss: 48.6816, Recon: 0.6867, KL: 48.0031, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6877, Val Loss: 48.6721, Recon: 0.6729, KL: 48.0148, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6805, Val Loss: 48.6774, Recon: 0.6767, KL: 48.0038, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6769, Val Loss: 48.6872, Recon: 0.6734, KL: 48.0034, KL_weight: 4.8000
Saved model 5 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_4.pt
Training bootstrap model 6/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9689, Val Loss: 0.7429, Recon: 0.9689, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7101, Val Loss: 4.6411, Recon: 0.8348, KL: 3.8753, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4794, Val Loss: 9.4291, Recon: 0.8189, KL: 8.6605, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2471, Val Loss: 14.2070, Recon: 0.7943, KL: 13.4528, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0493, Val Loss: 18.9926, Recon: 0.7935, KL: 18.2558, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8292, Val Loss: 23.7837, Recon: 0.7793, KL: 23.0499, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6160, Val Loss: 28.6004, Recon: 0.7662, KL: 27.8498, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4144, Val Loss: 33.3789, Recon: 0.7661, KL: 32.6482, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2035, Val Loss: 38.1779, Recon: 0.7587, KL: 37.4448, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0111, Val Loss: 43.0036, Recon: 0.7652, KL: 42.2459, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8176, Val Loss: 47.7964, Recon: 0.7600, KL: 47.0576, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7625, Val Loss: 48.7404, Recon: 0.7572, KL: 48.0053, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7682, Val Loss: 48.7334, Recon: 0.7574, KL: 48.0107, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7591, Val Loss: 48.7339, Recon: 0.7515, KL: 48.0076, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7553, Val Loss: 48.7281, Recon: 0.7467, KL: 48.0086, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7532, Val Loss: 48.7303, Recon: 0.7466, KL: 48.0066, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7469, Val Loss: 48.7329, Recon: 0.7403, KL: 48.0066, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7622, Val Loss: 48.7423, Recon: 0.7523, KL: 48.0099, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7450, Val Loss: 48.7312, Recon: 0.7378, KL: 48.0072, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7391, Val Loss: 48.7239, Recon: 0.7336, KL: 48.0055, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7570, Val Loss: 48.7300, Recon: 0.7450, KL: 48.0120, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7484, Val Loss: 48.7427, Recon: 0.7345, KL: 48.0140, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7322, Val Loss: 48.7282, Recon: 0.7303, KL: 48.0019, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7328, Val Loss: 48.7132, Recon: 0.7248, KL: 48.0080, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7560, Val Loss: 48.7245, Recon: 0.7366, KL: 48.0194, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7363, Val Loss: 48.7245, Recon: 0.7295, KL: 48.0068, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7264, Val Loss: 48.7212, Recon: 0.7217, KL: 48.0047, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7277, Val Loss: 48.7147, Recon: 0.7215, KL: 48.0062, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7231, Val Loss: 48.7081, Recon: 0.7194, KL: 48.0037, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7336, Val Loss: 48.7245, Recon: 0.7293, KL: 48.0042, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7195, Val Loss: 48.7152, Recon: 0.7157, KL: 48.0038, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7199, Val Loss: 48.7126, Recon: 0.7175, KL: 48.0024, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7054, Val Loss: 48.7019, Recon: 0.7028, KL: 48.0025, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7130, Val Loss: 48.6943, Recon: 0.7107, KL: 48.0023, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7254, Val Loss: 48.7086, Recon: 0.7205, KL: 48.0048, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7126, Val Loss: 48.7163, Recon: 0.7076, KL: 48.0050, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7117, Val Loss: 48.7076, Recon: 0.7063, KL: 48.0054, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7186, Val Loss: 48.6965, Recon: 0.7113, KL: 48.0073, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7307, Val Loss: 48.7258, Recon: 0.7216, KL: 48.0091, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6990, Val Loss: 48.6971, Recon: 0.6967, KL: 48.0023, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7052, Val Loss: 48.6937, Recon: 0.6994, KL: 48.0057, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6983, Val Loss: 48.6972, Recon: 0.6943, KL: 48.0039, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6952, Val Loss: 48.6967, Recon: 0.6931, KL: 48.0020, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7068, Val Loss: 48.7064, Recon: 0.7034, KL: 48.0034, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7052, Val Loss: 48.6987, Recon: 0.7001, KL: 48.0051, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7086, Val Loss: 48.6854, Recon: 0.7062, KL: 48.0024, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6949, Val Loss: 48.6935, Recon: 0.6885, KL: 48.0064, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6977, Val Loss: 48.6892, Recon: 0.6917, KL: 48.0060, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6809, Val Loss: 48.6836, Recon: 0.6780, KL: 48.0029, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6865, Val Loss: 48.6943, Recon: 0.6834, KL: 48.0031, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6988, Val Loss: 48.6959, Recon: 0.6948, KL: 48.0040, KL_weight: 4.8000
Saved model 6 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_5.pt
Training bootstrap model 7/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9725, Val Loss: 0.7329, Recon: 0.9725, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7049, Val Loss: 4.6502, Recon: 0.8350, KL: 3.8699, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4591, Val Loss: 9.4206, Recon: 0.8038, KL: 8.6553, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2487, Val Loss: 14.1905, Recon: 0.7925, KL: 13.4562, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0366, Val Loss: 19.0008, Recon: 0.7816, KL: 18.2549, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8226, Val Loss: 23.7800, Recon: 0.7658, KL: 23.0568, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6243, Val Loss: 28.6137, Recon: 0.7735, KL: 27.8508, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4078, Val Loss: 33.3653, Recon: 0.7601, KL: 32.6476, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2103, Val Loss: 38.1904, Recon: 0.7600, KL: 37.4503, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9937, Val Loss: 42.9633, Recon: 0.7474, KL: 42.2462, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7992, Val Loss: 47.7579, Recon: 0.7538, KL: 47.0454, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7544, Val Loss: 48.7123, Recon: 0.7469, KL: 48.0075, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7617, Val Loss: 48.7150, Recon: 0.7505, KL: 48.0112, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7463, Val Loss: 48.7249, Recon: 0.7411, KL: 48.0052, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7381, Val Loss: 48.7274, Recon: 0.7345, KL: 48.0036, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7485, Val Loss: 48.7215, Recon: 0.7449, KL: 48.0036, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7409, Val Loss: 48.7256, Recon: 0.7365, KL: 48.0044, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7401, Val Loss: 48.7108, Recon: 0.7337, KL: 48.0064, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7381, Val Loss: 48.7231, Recon: 0.7325, KL: 48.0057, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7340, Val Loss: 48.7216, Recon: 0.7316, KL: 48.0025, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7299, Val Loss: 48.7114, Recon: 0.7268, KL: 48.0031, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7269, Val Loss: 48.7038, Recon: 0.7237, KL: 48.0032, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7361, Val Loss: 48.7438, Recon: 0.7311, KL: 48.0050, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7304, Val Loss: 48.7072, Recon: 0.7230, KL: 48.0074, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7244, Val Loss: 48.7015, Recon: 0.7198, KL: 48.0046, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7224, Val Loss: 48.7103, Recon: 0.7194, KL: 48.0030, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7233, Val Loss: 48.7046, Recon: 0.7184, KL: 48.0048, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7247, Val Loss: 48.7196, Recon: 0.7211, KL: 48.0036, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7154, Val Loss: 48.6932, Recon: 0.7118, KL: 48.0036, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7071, Val Loss: 48.7039, Recon: 0.7047, KL: 48.0024, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7199, Val Loss: 48.7003, Recon: 0.7155, KL: 48.0044, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7216, Val Loss: 48.7064, Recon: 0.7141, KL: 48.0074, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7256, Val Loss: 48.7077, Recon: 0.7129, KL: 48.0127, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7052, Val Loss: 48.6957, Recon: 0.7023, KL: 48.0030, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7119, Val Loss: 48.6999, Recon: 0.7088, KL: 48.0031, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7212, Val Loss: 48.7168, Recon: 0.7129, KL: 48.0083, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7306, Val Loss: 48.7176, Recon: 0.7142, KL: 48.0164, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7212, Val Loss: 48.7147, Recon: 0.7151, KL: 48.0060, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6979, Val Loss: 48.6832, Recon: 0.6935, KL: 48.0044, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7025, Val Loss: 48.6736, Recon: 0.7001, KL: 48.0024, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6978, Val Loss: 48.6913, Recon: 0.6929, KL: 48.0048, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6924, Val Loss: 48.6835, Recon: 0.6885, KL: 48.0039, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7019, Val Loss: 48.6806, Recon: 0.6920, KL: 48.0099, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6942, Val Loss: 48.6841, Recon: 0.6911, KL: 48.0031, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6951, Val Loss: 48.6929, Recon: 0.6902, KL: 48.0049, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7028, Val Loss: 48.6753, Recon: 0.6989, KL: 48.0040, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6940, Val Loss: 48.6917, Recon: 0.6902, KL: 48.0038, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6920, Val Loss: 48.6698, Recon: 0.6884, KL: 48.0036, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6906, Val Loss: 48.6849, Recon: 0.6879, KL: 48.0027, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6909, Val Loss: 48.6778, Recon: 0.6861, KL: 48.0048, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6868, Val Loss: 48.6925, Recon: 0.6819, KL: 48.0049, KL_weight: 4.8000
Saved model 7 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_6.pt
Training bootstrap model 8/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9641, Val Loss: 0.7592, Recon: 0.9641, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6922, Val Loss: 4.6404, Recon: 0.8173, KL: 3.8749, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4421, Val Loss: 9.4244, Recon: 0.7848, KL: 8.6573, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2315, Val Loss: 14.2109, Recon: 0.7781, KL: 13.4534, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0093, Val Loss: 18.9877, Recon: 0.7608, KL: 18.2486, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8059, Val Loss: 23.8035, Recon: 0.7550, KL: 23.0508, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6030, Val Loss: 28.6024, Recon: 0.7535, KL: 27.8495, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4095, Val Loss: 33.3718, Recon: 0.7574, KL: 32.6522, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1952, Val Loss: 38.1802, Recon: 0.7465, KL: 37.4487, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9988, Val Loss: 42.9814, Recon: 0.7518, KL: 42.2470, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8066, Val Loss: 47.8072, Recon: 0.7565, KL: 47.0501, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7471, Val Loss: 48.7292, Recon: 0.7406, KL: 48.0065, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7418, Val Loss: 48.7231, Recon: 0.7377, KL: 48.0042, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7425, Val Loss: 48.7481, Recon: 0.7368, KL: 48.0056, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7335, Val Loss: 48.7227, Recon: 0.7285, KL: 48.0050, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7322, Val Loss: 48.7334, Recon: 0.7292, KL: 48.0030, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7328, Val Loss: 48.7380, Recon: 0.7266, KL: 48.0062, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7235, Val Loss: 48.7524, Recon: 0.7180, KL: 48.0055, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7180, Val Loss: 48.7226, Recon: 0.7140, KL: 48.0040, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7126, Val Loss: 48.7121, Recon: 0.7094, KL: 48.0032, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7118, Val Loss: 48.7285, Recon: 0.7082, KL: 48.0036, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7159, Val Loss: 48.7075, Recon: 0.7121, KL: 48.0038, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7188, Val Loss: 48.7377, Recon: 0.7103, KL: 48.0085, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7171, Val Loss: 48.7147, Recon: 0.7095, KL: 48.0076, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7090, Val Loss: 48.7018, Recon: 0.7053, KL: 48.0038, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7072, Val Loss: 48.7040, Recon: 0.7023, KL: 48.0049, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7012, Val Loss: 48.7317, Recon: 0.6964, KL: 48.0048, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.6979, Val Loss: 48.6958, Recon: 0.6958, KL: 48.0021, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7114, Val Loss: 48.7085, Recon: 0.7056, KL: 48.0059, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7180, Val Loss: 48.7501, Recon: 0.7053, KL: 48.0127, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7113, Val Loss: 48.7462, Recon: 0.7042, KL: 48.0071, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6964, Val Loss: 48.7082, Recon: 0.6923, KL: 48.0041, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6898, Val Loss: 48.7093, Recon: 0.6871, KL: 48.0027, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6923, Val Loss: 48.6853, Recon: 0.6882, KL: 48.0041, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6898, Val Loss: 48.6961, Recon: 0.6866, KL: 48.0032, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6926, Val Loss: 48.7037, Recon: 0.6890, KL: 48.0036, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6854, Val Loss: 48.7027, Recon: 0.6831, KL: 48.0022, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6946, Val Loss: 48.7064, Recon: 0.6917, KL: 48.0029, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6870, Val Loss: 48.6758, Recon: 0.6846, KL: 48.0024, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6814, Val Loss: 48.6755, Recon: 0.6778, KL: 48.0036, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6877, Val Loss: 48.7025, Recon: 0.6858, KL: 48.0019, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6896, Val Loss: 48.6743, Recon: 0.6841, KL: 48.0055, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6805, Val Loss: 48.6801, Recon: 0.6783, KL: 48.0023, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6952, Val Loss: 48.6793, Recon: 0.6835, KL: 48.0116, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6884, Val Loss: 48.6870, Recon: 0.6849, KL: 48.0036, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6832, Val Loss: 48.6799, Recon: 0.6778, KL: 48.0055, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6779, Val Loss: 48.6774, Recon: 0.6757, KL: 48.0021, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6845, Val Loss: 48.6845, Recon: 0.6799, KL: 48.0046, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6849, Val Loss: 48.6867, Recon: 0.6807, KL: 48.0042, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6788, Val Loss: 48.7202, Recon: 0.6760, KL: 48.0028, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6775, Val Loss: 48.6791, Recon: 0.6746, KL: 48.0029, KL_weight: 4.8000
Saved model 8 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_7.pt
Training bootstrap model 9/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9620, Val Loss: 0.7335, Recon: 0.9620, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6899, Val Loss: 4.6245, Recon: 0.8194, KL: 3.8705, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4563, Val Loss: 9.3951, Recon: 0.7987, KL: 8.6575, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2362, Val Loss: 14.2092, Recon: 0.7821, KL: 13.4541, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0209, Val Loss: 18.9954, Recon: 0.7687, KL: 18.2522, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8002, Val Loss: 23.7707, Recon: 0.7534, KL: 23.0468, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6182, Val Loss: 28.5723, Recon: 0.7696, KL: 27.8486, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4101, Val Loss: 33.3903, Recon: 0.7585, KL: 32.6515, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1980, Val Loss: 38.1890, Recon: 0.7511, KL: 37.4469, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9863, Val Loss: 42.9576, Recon: 0.7407, KL: 42.2457, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7940, Val Loss: 47.7971, Recon: 0.7464, KL: 47.0476, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7551, Val Loss: 48.7797, Recon: 0.7441, KL: 48.0111, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7489, Val Loss: 48.7425, Recon: 0.7442, KL: 48.0046, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7445, Val Loss: 48.7352, Recon: 0.7370, KL: 48.0075, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7322, Val Loss: 48.7435, Recon: 0.7286, KL: 48.0036, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7353, Val Loss: 48.7251, Recon: 0.7250, KL: 48.0103, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7389, Val Loss: 48.7433, Recon: 0.7335, KL: 48.0053, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7305, Val Loss: 48.7258, Recon: 0.7237, KL: 48.0068, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7170, Val Loss: 48.7155, Recon: 0.7149, KL: 48.0022, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7241, Val Loss: 48.7005, Recon: 0.7174, KL: 48.0067, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7158, Val Loss: 48.7127, Recon: 0.7081, KL: 48.0077, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7241, Val Loss: 48.7171, Recon: 0.7166, KL: 48.0075, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7314, Val Loss: 48.7212, Recon: 0.7222, KL: 48.0092, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7179, Val Loss: 48.7002, Recon: 0.7138, KL: 48.0041, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7137, Val Loss: 48.7081, Recon: 0.7111, KL: 48.0027, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7194, Val Loss: 48.7174, Recon: 0.7101, KL: 48.0094, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7056, Val Loss: 48.7372, Recon: 0.6956, KL: 48.0100, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7059, Val Loss: 48.7026, Recon: 0.7002, KL: 48.0057, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7086, Val Loss: 48.6979, Recon: 0.7033, KL: 48.0053, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7067, Val Loss: 48.7054, Recon: 0.7023, KL: 48.0044, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.6945, Val Loss: 48.6840, Recon: 0.6897, KL: 48.0047, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6893, Val Loss: 48.6866, Recon: 0.6854, KL: 48.0038, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6874, Val Loss: 48.6882, Recon: 0.6841, KL: 48.0033, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6922, Val Loss: 48.6956, Recon: 0.6880, KL: 48.0042, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6902, Val Loss: 48.6853, Recon: 0.6879, KL: 48.0023, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7014, Val Loss: 48.7024, Recon: 0.6929, KL: 48.0085, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6873, Val Loss: 48.7003, Recon: 0.6837, KL: 48.0036, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6856, Val Loss: 48.6801, Recon: 0.6814, KL: 48.0043, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6890, Val Loss: 48.6840, Recon: 0.6860, KL: 48.0030, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6925, Val Loss: 48.6887, Recon: 0.6895, KL: 48.0030, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6928, Val Loss: 48.6879, Recon: 0.6884, KL: 48.0044, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6980, Val Loss: 48.6893, Recon: 0.6928, KL: 48.0052, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6812, Val Loss: 48.6812, Recon: 0.6789, KL: 48.0023, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6915, Val Loss: 48.7080, Recon: 0.6798, KL: 48.0118, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6832, Val Loss: 48.6686, Recon: 0.6808, KL: 48.0023, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6782, Val Loss: 48.6762, Recon: 0.6740, KL: 48.0043, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6775, Val Loss: 48.6827, Recon: 0.6740, KL: 48.0035, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6813, Val Loss: 48.6824, Recon: 0.6784, KL: 48.0029, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6751, Val Loss: 48.6813, Recon: 0.6727, KL: 48.0024, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6712, Val Loss: 48.6755, Recon: 0.6673, KL: 48.0039, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6882, Val Loss: 48.7001, Recon: 0.6811, KL: 48.0072, KL_weight: 4.8000
Saved model 9 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_8.pt
Training bootstrap model 10/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9339, Val Loss: 0.7136, Recon: 0.9339, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6830, Val Loss: 4.6315, Recon: 0.8159, KL: 3.8671, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4508, Val Loss: 9.4076, Recon: 0.7941, KL: 8.6567, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2272, Val Loss: 14.2043, Recon: 0.7740, KL: 13.4532, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0032, Val Loss: 18.9870, Recon: 0.7582, KL: 18.2450, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8156, Val Loss: 23.7855, Recon: 0.7628, KL: 23.0528, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.5978, Val Loss: 28.5697, Recon: 0.7504, KL: 27.8474, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3975, Val Loss: 33.3821, Recon: 0.7516, KL: 32.6460, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2239, Val Loss: 38.1819, Recon: 0.7684, KL: 37.4554, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9789, Val Loss: 42.9627, Recon: 0.7335, KL: 42.2454, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7903, Val Loss: 47.7812, Recon: 0.7448, KL: 47.0456, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7442, Val Loss: 48.7493, Recon: 0.7388, KL: 48.0055, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7536, Val Loss: 48.7381, Recon: 0.7455, KL: 48.0082, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7354, Val Loss: 48.7182, Recon: 0.7288, KL: 48.0065, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7276, Val Loss: 48.7316, Recon: 0.7234, KL: 48.0042, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7362, Val Loss: 48.7291, Recon: 0.7297, KL: 48.0065, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7186, Val Loss: 48.7156, Recon: 0.7158, KL: 48.0028, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7265, Val Loss: 48.7341, Recon: 0.7201, KL: 48.0063, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7170, Val Loss: 48.7145, Recon: 0.7123, KL: 48.0047, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7176, Val Loss: 48.7192, Recon: 0.7134, KL: 48.0042, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7155, Val Loss: 48.7217, Recon: 0.7108, KL: 48.0047, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7080, Val Loss: 48.7002, Recon: 0.7049, KL: 48.0031, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7146, Val Loss: 48.7079, Recon: 0.7067, KL: 48.0079, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7085, Val Loss: 48.7064, Recon: 0.7046, KL: 48.0039, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7080, Val Loss: 48.7156, Recon: 0.7031, KL: 48.0049, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7055, Val Loss: 48.6991, Recon: 0.7019, KL: 48.0036, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7027, Val Loss: 48.6994, Recon: 0.6991, KL: 48.0035, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7022, Val Loss: 48.7029, Recon: 0.6987, KL: 48.0035, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.6968, Val Loss: 48.6946, Recon: 0.6927, KL: 48.0041, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.6972, Val Loss: 48.6917, Recon: 0.6940, KL: 48.0032, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.6949, Val Loss: 48.7259, Recon: 0.6904, KL: 48.0045, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6859, Val Loss: 48.6887, Recon: 0.6828, KL: 48.0031, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6879, Val Loss: 48.7001, Recon: 0.6839, KL: 48.0040, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6869, Val Loss: 48.6839, Recon: 0.6841, KL: 48.0029, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6845, Val Loss: 48.6890, Recon: 0.6816, KL: 48.0028, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6867, Val Loss: 48.6807, Recon: 0.6829, KL: 48.0038, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6883, Val Loss: 48.6921, Recon: 0.6847, KL: 48.0036, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6895, Val Loss: 48.6942, Recon: 0.6858, KL: 48.0036, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6777, Val Loss: 48.6832, Recon: 0.6759, KL: 48.0018, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6810, Val Loss: 48.6901, Recon: 0.6763, KL: 48.0047, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6888, Val Loss: 48.6955, Recon: 0.6837, KL: 48.0051, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6823, Val Loss: 48.6698, Recon: 0.6779, KL: 48.0044, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6925, Val Loss: 48.6821, Recon: 0.6849, KL: 48.0075, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6834, Val Loss: 48.6743, Recon: 0.6811, KL: 48.0023, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6951, Val Loss: 48.7051, Recon: 0.6898, KL: 48.0053, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6797, Val Loss: 48.6762, Recon: 0.6758, KL: 48.0039, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6737, Val Loss: 48.6834, Recon: 0.6711, KL: 48.0026, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6785, Val Loss: 48.6900, Recon: 0.6757, KL: 48.0028, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6748, Val Loss: 48.6841, Recon: 0.6733, KL: 48.0015, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6772, Val Loss: 48.6664, Recon: 0.6737, KL: 48.0035, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6790, Val Loss: 48.6963, Recon: 0.6767, KL: 48.0022, KL_weight: 4.8000
Saved model 10 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_9.pt
Training bootstrap model 11/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 1.0130, Val Loss: 0.8243, Recon: 1.0130, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6960, Val Loss: 4.6460, Recon: 0.8256, KL: 3.8704, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4618, Val Loss: 9.4127, Recon: 0.8059, KL: 8.6560, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2468, Val Loss: 14.2166, Recon: 0.7886, KL: 13.4582, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0296, Val Loss: 18.9904, Recon: 0.7747, KL: 18.2549, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8267, Val Loss: 23.7979, Recon: 0.7776, KL: 23.0491, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6342, Val Loss: 28.6122, Recon: 0.7812, KL: 27.8531, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4141, Val Loss: 33.3762, Recon: 0.7681, KL: 32.6460, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2248, Val Loss: 38.1810, Recon: 0.7730, KL: 37.4518, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0116, Val Loss: 42.9933, Recon: 0.7643, KL: 42.2473, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8111, Val Loss: 47.7958, Recon: 0.7641, KL: 47.0471, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7663, Val Loss: 48.7367, Recon: 0.7597, KL: 48.0065, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7603, Val Loss: 48.7215, Recon: 0.7558, KL: 48.0046, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7519, Val Loss: 48.7299, Recon: 0.7477, KL: 48.0042, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7641, Val Loss: 48.7397, Recon: 0.7561, KL: 48.0080, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7427, Val Loss: 48.7371, Recon: 0.7395, KL: 48.0032, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7447, Val Loss: 48.7310, Recon: 0.7413, KL: 48.0034, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7425, Val Loss: 48.7200, Recon: 0.7389, KL: 48.0036, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7418, Val Loss: 48.7162, Recon: 0.7391, KL: 48.0027, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7483, Val Loss: 48.7312, Recon: 0.7401, KL: 48.0082, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7403, Val Loss: 48.7321, Recon: 0.7347, KL: 48.0056, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7366, Val Loss: 48.7147, Recon: 0.7343, KL: 48.0023, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7283, Val Loss: 48.7168, Recon: 0.7265, KL: 48.0018, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7463, Val Loss: 48.7223, Recon: 0.7386, KL: 48.0077, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7402, Val Loss: 48.7171, Recon: 0.7327, KL: 48.0074, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7413, Val Loss: 48.7226, Recon: 0.7362, KL: 48.0052, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7346, Val Loss: 48.7163, Recon: 0.7305, KL: 48.0041, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7386, Val Loss: 48.7124, Recon: 0.7369, KL: 48.0018, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7391, Val Loss: 48.7179, Recon: 0.7349, KL: 48.0042, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7347, Val Loss: 48.7233, Recon: 0.7295, KL: 48.0052, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7330, Val Loss: 48.6977, Recon: 0.7306, KL: 48.0024, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7294, Val Loss: 48.7057, Recon: 0.7274, KL: 48.0020, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7307, Val Loss: 48.7104, Recon: 0.7280, KL: 48.0027, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7303, Val Loss: 48.7043, Recon: 0.7258, KL: 48.0045, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7225, Val Loss: 48.6921, Recon: 0.7210, KL: 48.0015, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7188, Val Loss: 48.7065, Recon: 0.7174, KL: 48.0014, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7395, Val Loss: 48.7233, Recon: 0.7323, KL: 48.0071, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7286, Val Loss: 48.7169, Recon: 0.7246, KL: 48.0040, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7218, Val Loss: 48.7037, Recon: 0.7181, KL: 48.0037, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7220, Val Loss: 48.7032, Recon: 0.7196, KL: 48.0024, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7199, Val Loss: 48.7065, Recon: 0.7175, KL: 48.0024, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7229, Val Loss: 48.6979, Recon: 0.7206, KL: 48.0024, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7263, Val Loss: 48.7048, Recon: 0.7182, KL: 48.0081, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7311, Val Loss: 48.7023, Recon: 0.7272, KL: 48.0039, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7215, Val Loss: 48.7189, Recon: 0.7157, KL: 48.0059, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7148, Val Loss: 48.7083, Recon: 0.7117, KL: 48.0031, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7171, Val Loss: 48.6991, Recon: 0.7149, KL: 48.0022, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7216, Val Loss: 48.7009, Recon: 0.7184, KL: 48.0032, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7263, Val Loss: 48.7031, Recon: 0.7199, KL: 48.0064, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7103, Val Loss: 48.7017, Recon: 0.7070, KL: 48.0033, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.7160, Val Loss: 48.6996, Recon: 0.7133, KL: 48.0027, KL_weight: 4.8000
Saved model 11 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_10.pt
Training bootstrap model 12/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9679, Val Loss: 0.7708, Recon: 0.9679, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7137, Val Loss: 4.6528, Recon: 0.8378, KL: 3.8759, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4802, Val Loss: 9.4345, Recon: 0.8163, KL: 8.6639, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2530, Val Loss: 14.2223, Recon: 0.8000, KL: 13.4530, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0458, Val Loss: 19.0264, Recon: 0.7834, KL: 18.2624, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8165, Val Loss: 23.7915, Recon: 0.7679, KL: 23.0486, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6196, Val Loss: 28.5811, Recon: 0.7687, KL: 27.8509, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4229, Val Loss: 33.4004, Recon: 0.7740, KL: 32.6489, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2070, Val Loss: 38.1880, Recon: 0.7614, KL: 37.4457, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9998, Val Loss: 42.9790, Recon: 0.7539, KL: 42.2460, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8032, Val Loss: 47.7752, Recon: 0.7570, KL: 47.0462, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7656, Val Loss: 48.7291, Recon: 0.7593, KL: 48.0064, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7760, Val Loss: 48.7340, Recon: 0.7645, KL: 48.0115, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7548, Val Loss: 48.7453, Recon: 0.7510, KL: 48.0038, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7429, Val Loss: 48.7258, Recon: 0.7383, KL: 48.0046, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7321, Val Loss: 48.7317, Recon: 0.7292, KL: 48.0029, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7491, Val Loss: 48.7143, Recon: 0.7421, KL: 48.0070, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7386, Val Loss: 48.7138, Recon: 0.7345, KL: 48.0041, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7384, Val Loss: 48.7519, Recon: 0.7345, KL: 48.0039, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7457, Val Loss: 48.7486, Recon: 0.7355, KL: 48.0101, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7543, Val Loss: 48.7463, Recon: 0.7450, KL: 48.0093, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7418, Val Loss: 48.7143, Recon: 0.7323, KL: 48.0095, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7591, Val Loss: 48.7366, Recon: 0.7444, KL: 48.0147, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7350, Val Loss: 48.7262, Recon: 0.7316, KL: 48.0034, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7364, Val Loss: 48.7226, Recon: 0.7255, KL: 48.0109, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7253, Val Loss: 48.7219, Recon: 0.7194, KL: 48.0059, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7403, Val Loss: 48.7205, Recon: 0.7374, KL: 48.0030, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7321, Val Loss: 48.7136, Recon: 0.7269, KL: 48.0051, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7201, Val Loss: 48.7105, Recon: 0.7152, KL: 48.0049, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7236, Val Loss: 48.7111, Recon: 0.7198, KL: 48.0038, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7261, Val Loss: 48.7193, Recon: 0.7191, KL: 48.0070, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7077, Val Loss: 48.7111, Recon: 0.7026, KL: 48.0051, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7191, Val Loss: 48.6922, Recon: 0.7103, KL: 48.0089, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7082, Val Loss: 48.6875, Recon: 0.7044, KL: 48.0037, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7024, Val Loss: 48.6900, Recon: 0.6994, KL: 48.0031, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7018, Val Loss: 48.6896, Recon: 0.6977, KL: 48.0041, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6984, Val Loss: 48.7052, Recon: 0.6951, KL: 48.0033, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7298, Val Loss: 48.6952, Recon: 0.7271, KL: 48.0027, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7149, Val Loss: 48.7042, Recon: 0.7074, KL: 48.0074, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7051, Val Loss: 48.7085, Recon: 0.7012, KL: 48.0040, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7124, Val Loss: 48.7021, Recon: 0.7084, KL: 48.0039, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6935, Val Loss: 48.6906, Recon: 0.6903, KL: 48.0032, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6952, Val Loss: 48.6918, Recon: 0.6928, KL: 48.0024, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6895, Val Loss: 48.6872, Recon: 0.6858, KL: 48.0037, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6938, Val Loss: 48.6849, Recon: 0.6901, KL: 48.0037, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6919, Val Loss: 48.6916, Recon: 0.6893, KL: 48.0026, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6905, Val Loss: 48.6745, Recon: 0.6871, KL: 48.0035, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7042, Val Loss: 48.6945, Recon: 0.6897, KL: 48.0145, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6930, Val Loss: 48.6820, Recon: 0.6899, KL: 48.0031, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6893, Val Loss: 48.6828, Recon: 0.6873, KL: 48.0021, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6881, Val Loss: 48.6823, Recon: 0.6843, KL: 48.0038, KL_weight: 4.8000
Saved model 12 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_11.pt
Training bootstrap model 13/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9733, Val Loss: 0.7258, Recon: 0.9733, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7157, Val Loss: 4.6258, Recon: 0.8395, KL: 3.8762, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4628, Val Loss: 9.3878, Recon: 0.8080, KL: 8.6547, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2525, Val Loss: 14.1969, Recon: 0.7948, KL: 13.4577, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0377, Val Loss: 19.0403, Recon: 0.7836, KL: 18.2541, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8174, Val Loss: 23.7761, Recon: 0.7683, KL: 23.0491, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6091, Val Loss: 28.5827, Recon: 0.7635, KL: 27.8456, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4124, Val Loss: 33.3964, Recon: 0.7648, KL: 32.6477, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2017, Val Loss: 38.1742, Recon: 0.7557, KL: 37.4460, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0096, Val Loss: 42.9647, Recon: 0.7635, KL: 42.2461, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8077, Val Loss: 47.7970, Recon: 0.7605, KL: 47.0472, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7659, Val Loss: 48.7192, Recon: 0.7593, KL: 48.0066, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7573, Val Loss: 48.7239, Recon: 0.7522, KL: 48.0052, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7493, Val Loss: 48.7227, Recon: 0.7463, KL: 48.0030, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7472, Val Loss: 48.7238, Recon: 0.7439, KL: 48.0034, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7479, Val Loss: 48.7334, Recon: 0.7439, KL: 48.0040, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7793, Val Loss: 48.7419, Recon: 0.7650, KL: 48.0143, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7594, Val Loss: 48.7241, Recon: 0.7476, KL: 48.0118, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7426, Val Loss: 48.7263, Recon: 0.7408, KL: 48.0018, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7476, Val Loss: 48.7142, Recon: 0.7355, KL: 48.0121, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7457, Val Loss: 48.7204, Recon: 0.7418, KL: 48.0039, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7397, Val Loss: 48.7215, Recon: 0.7339, KL: 48.0058, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7485, Val Loss: 48.7217, Recon: 0.7444, KL: 48.0041, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7337, Val Loss: 48.7162, Recon: 0.7316, KL: 48.0021, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7511, Val Loss: 48.7288, Recon: 0.7433, KL: 48.0078, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7306, Val Loss: 48.7098, Recon: 0.7278, KL: 48.0029, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7378, Val Loss: 48.7154, Recon: 0.7351, KL: 48.0026, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7421, Val Loss: 48.7309, Recon: 0.7373, KL: 48.0048, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7226, Val Loss: 48.7233, Recon: 0.7207, KL: 48.0019, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7214, Val Loss: 48.7162, Recon: 0.7190, KL: 48.0024, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7309, Val Loss: 48.7237, Recon: 0.7285, KL: 48.0025, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7285, Val Loss: 48.6932, Recon: 0.7254, KL: 48.0031, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7197, Val Loss: 48.6947, Recon: 0.7149, KL: 48.0048, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7163, Val Loss: 48.6942, Recon: 0.7140, KL: 48.0023, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7095, Val Loss: 48.6952, Recon: 0.7067, KL: 48.0027, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7086, Val Loss: 48.6899, Recon: 0.7053, KL: 48.0033, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7103, Val Loss: 48.6921, Recon: 0.7077, KL: 48.0026, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7016, Val Loss: 48.7008, Recon: 0.6992, KL: 48.0024, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7046, Val Loss: 48.6838, Recon: 0.7020, KL: 48.0026, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7176, Val Loss: 48.6912, Recon: 0.7066, KL: 48.0110, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7079, Val Loss: 48.6849, Recon: 0.7040, KL: 48.0038, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7031, Val Loss: 48.6776, Recon: 0.7011, KL: 48.0021, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7122, Val Loss: 48.6862, Recon: 0.7085, KL: 48.0037, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7008, Val Loss: 48.6733, Recon: 0.6964, KL: 48.0044, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7079, Val Loss: 48.6885, Recon: 0.7053, KL: 48.0026, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7198, Val Loss: 48.6844, Recon: 0.7172, KL: 48.0027, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6998, Val Loss: 48.6848, Recon: 0.6969, KL: 48.0029, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7076, Val Loss: 48.6895, Recon: 0.6984, KL: 48.0092, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6972, Val Loss: 48.6849, Recon: 0.6943, KL: 48.0029, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6916, Val Loss: 48.6702, Recon: 0.6885, KL: 48.0031, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.7166, Val Loss: 48.6995, Recon: 0.7074, KL: 48.0092, KL_weight: 4.8000
Saved model 13 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_12.pt
Training bootstrap model 14/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9675, Val Loss: 0.7355, Recon: 0.9675, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6927, Val Loss: 4.6434, Recon: 0.8181, KL: 3.8746, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4480, Val Loss: 9.4177, Recon: 0.7909, KL: 8.6571, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2383, Val Loss: 14.2129, Recon: 0.7809, KL: 13.4574, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0307, Val Loss: 18.9890, Recon: 0.7766, KL: 18.2541, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8110, Val Loss: 23.7872, Recon: 0.7607, KL: 23.0503, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6267, Val Loss: 28.5821, Recon: 0.7758, KL: 27.8509, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4052, Val Loss: 33.3756, Recon: 0.7572, KL: 32.6480, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2083, Val Loss: 38.1881, Recon: 0.7560, KL: 37.4523, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9999, Val Loss: 42.9644, Recon: 0.7510, KL: 42.2489, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8042, Val Loss: 47.7708, Recon: 0.7576, KL: 47.0466, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7565, Val Loss: 48.7177, Recon: 0.7492, KL: 48.0073, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7590, Val Loss: 48.7398, Recon: 0.7500, KL: 48.0090, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7755, Val Loss: 48.7534, Recon: 0.7549, KL: 48.0206, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7570, Val Loss: 48.7173, Recon: 0.7466, KL: 48.0104, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7420, Val Loss: 48.7186, Recon: 0.7374, KL: 48.0046, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7312, Val Loss: 48.7145, Recon: 0.7271, KL: 48.0041, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7202, Val Loss: 48.7098, Recon: 0.7179, KL: 48.0023, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7403, Val Loss: 48.7458, Recon: 0.7339, KL: 48.0064, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7305, Val Loss: 48.7312, Recon: 0.7262, KL: 48.0043, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7337, Val Loss: 48.7248, Recon: 0.7264, KL: 48.0074, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7227, Val Loss: 48.7147, Recon: 0.7177, KL: 48.0050, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7344, Val Loss: 48.7111, Recon: 0.7237, KL: 48.0107, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7246, Val Loss: 48.7134, Recon: 0.7130, KL: 48.0116, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7070, Val Loss: 48.6969, Recon: 0.7024, KL: 48.0046, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7074, Val Loss: 48.6967, Recon: 0.7028, KL: 48.0046, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7108, Val Loss: 48.6944, Recon: 0.7053, KL: 48.0055, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7071, Val Loss: 48.7003, Recon: 0.7006, KL: 48.0065, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7024, Val Loss: 48.7003, Recon: 0.6944, KL: 48.0079, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7055, Val Loss: 48.6932, Recon: 0.7003, KL: 48.0052, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7135, Val Loss: 48.7034, Recon: 0.7065, KL: 48.0070, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7008, Val Loss: 48.6829, Recon: 0.6973, KL: 48.0035, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6991, Val Loss: 48.6773, Recon: 0.6948, KL: 48.0043, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6939, Val Loss: 48.6901, Recon: 0.6907, KL: 48.0032, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6955, Val Loss: 48.6986, Recon: 0.6883, KL: 48.0072, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6905, Val Loss: 48.6856, Recon: 0.6857, KL: 48.0047, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6919, Val Loss: 48.6821, Recon: 0.6885, KL: 48.0034, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6851, Val Loss: 48.6810, Recon: 0.6819, KL: 48.0032, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6910, Val Loss: 48.6851, Recon: 0.6829, KL: 48.0081, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7064, Val Loss: 48.6827, Recon: 0.6918, KL: 48.0147, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6921, Val Loss: 48.6884, Recon: 0.6875, KL: 48.0046, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6909, Val Loss: 48.6910, Recon: 0.6864, KL: 48.0045, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6893, Val Loss: 48.6756, Recon: 0.6845, KL: 48.0047, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6847, Val Loss: 48.6718, Recon: 0.6805, KL: 48.0041, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6881, Val Loss: 48.6733, Recon: 0.6824, KL: 48.0057, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6872, Val Loss: 48.6672, Recon: 0.6811, KL: 48.0060, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6807, Val Loss: 48.6880, Recon: 0.6759, KL: 48.0048, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6886, Val Loss: 48.6781, Recon: 0.6819, KL: 48.0067, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6804, Val Loss: 48.6784, Recon: 0.6752, KL: 48.0052, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6808, Val Loss: 48.6667, Recon: 0.6758, KL: 48.0051, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6971, Val Loss: 48.6749, Recon: 0.6916, KL: 48.0055, KL_weight: 4.8000
Saved model 14 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_13.pt
Training bootstrap model 15/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 1.0064, Val Loss: 0.8365, Recon: 1.0064, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7006, Val Loss: 4.6526, Recon: 0.8312, KL: 3.8694, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4652, Val Loss: 9.4359, Recon: 0.8070, KL: 8.6583, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2311, Val Loss: 14.2070, Recon: 0.7805, KL: 13.4506, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0324, Val Loss: 19.0054, Recon: 0.7804, KL: 18.2521, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8196, Val Loss: 23.7837, Recon: 0.7700, KL: 23.0496, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6283, Val Loss: 28.6070, Recon: 0.7775, KL: 27.8508, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4166, Val Loss: 33.4093, Recon: 0.7681, KL: 32.6485, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2084, Val Loss: 38.1794, Recon: 0.7621, KL: 37.4463, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9977, Val Loss: 42.9869, Recon: 0.7509, KL: 42.2468, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7951, Val Loss: 47.7730, Recon: 0.7471, KL: 47.0480, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7655, Val Loss: 48.7471, Recon: 0.7540, KL: 48.0115, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7497, Val Loss: 48.7490, Recon: 0.7434, KL: 48.0064, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7348, Val Loss: 48.7250, Recon: 0.7304, KL: 48.0043, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7450, Val Loss: 48.7329, Recon: 0.7395, KL: 48.0054, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7417, Val Loss: 48.7170, Recon: 0.7352, KL: 48.0065, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7306, Val Loss: 48.7308, Recon: 0.7248, KL: 48.0059, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7208, Val Loss: 48.7279, Recon: 0.7185, KL: 48.0023, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7266, Val Loss: 48.7189, Recon: 0.7228, KL: 48.0037, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7334, Val Loss: 48.7228, Recon: 0.7257, KL: 48.0077, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7239, Val Loss: 48.7352, Recon: 0.7172, KL: 48.0067, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7272, Val Loss: 48.7274, Recon: 0.7236, KL: 48.0036, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7291, Val Loss: 48.7038, Recon: 0.7235, KL: 48.0055, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7274, Val Loss: 48.7206, Recon: 0.7213, KL: 48.0061, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7263, Val Loss: 48.7186, Recon: 0.7226, KL: 48.0037, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7162, Val Loss: 48.7123, Recon: 0.7101, KL: 48.0061, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7107, Val Loss: 48.6963, Recon: 0.7080, KL: 48.0027, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7101, Val Loss: 48.7129, Recon: 0.7065, KL: 48.0036, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7059, Val Loss: 48.7020, Recon: 0.7021, KL: 48.0038, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.6992, Val Loss: 48.6963, Recon: 0.6969, KL: 48.0023, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7195, Val Loss: 48.7187, Recon: 0.7067, KL: 48.0127, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7029, Val Loss: 48.6962, Recon: 0.6989, KL: 48.0040, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7080, Val Loss: 48.6970, Recon: 0.7031, KL: 48.0049, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7040, Val Loss: 48.6999, Recon: 0.6946, KL: 48.0094, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6963, Val Loss: 48.6822, Recon: 0.6934, KL: 48.0029, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6972, Val Loss: 48.6976, Recon: 0.6918, KL: 48.0054, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6889, Val Loss: 48.6830, Recon: 0.6848, KL: 48.0041, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6868, Val Loss: 48.6782, Recon: 0.6827, KL: 48.0041, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7112, Val Loss: 48.7061, Recon: 0.6961, KL: 48.0150, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6907, Val Loss: 48.6864, Recon: 0.6875, KL: 48.0031, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6899, Val Loss: 48.6742, Recon: 0.6866, KL: 48.0032, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6862, Val Loss: 48.6834, Recon: 0.6827, KL: 48.0035, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6842, Val Loss: 48.6770, Recon: 0.6821, KL: 48.0021, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6817, Val Loss: 48.6768, Recon: 0.6804, KL: 48.0014, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6894, Val Loss: 48.6919, Recon: 0.6851, KL: 48.0043, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6770, Val Loss: 48.6832, Recon: 0.6743, KL: 48.0027, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7019, Val Loss: 48.6977, Recon: 0.6925, KL: 48.0094, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7151, Val Loss: 48.6943, Recon: 0.6981, KL: 48.0170, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6773, Val Loss: 48.6717, Recon: 0.6738, KL: 48.0035, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6825, Val Loss: 48.6747, Recon: 0.6806, KL: 48.0019, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6778, Val Loss: 48.6811, Recon: 0.6734, KL: 48.0044, KL_weight: 4.8000
Saved model 15 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_14.pt
Training bootstrap model 16/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9796, Val Loss: 0.7613, Recon: 0.9796, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7000, Val Loss: 4.6299, Recon: 0.8295, KL: 3.8704, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4440, Val Loss: 9.4279, Recon: 0.7880, KL: 8.6561, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2283, Val Loss: 14.1886, Recon: 0.7760, KL: 13.4523, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0100, Val Loss: 18.9943, Recon: 0.7620, KL: 18.2480, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8125, Val Loss: 23.7981, Recon: 0.7619, KL: 23.0507, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6130, Val Loss: 28.5783, Recon: 0.7634, KL: 27.8497, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4039, Val Loss: 33.3838, Recon: 0.7553, KL: 32.6486, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2001, Val Loss: 38.1683, Recon: 0.7548, KL: 37.4453, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0068, Val Loss: 42.9805, Recon: 0.7514, KL: 42.2554, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7938, Val Loss: 47.7741, Recon: 0.7495, KL: 47.0443, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7366, Val Loss: 48.7321, Recon: 0.7314, KL: 48.0052, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7428, Val Loss: 48.7385, Recon: 0.7356, KL: 48.0071, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7452, Val Loss: 48.7249, Recon: 0.7389, KL: 48.0063, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7422, Val Loss: 48.7261, Recon: 0.7343, KL: 48.0079, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7408, Val Loss: 48.7220, Recon: 0.7341, KL: 48.0067, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7401, Val Loss: 48.7343, Recon: 0.7330, KL: 48.0071, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7238, Val Loss: 48.7304, Recon: 0.7212, KL: 48.0025, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7333, Val Loss: 48.7200, Recon: 0.7285, KL: 48.0048, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7313, Val Loss: 48.7197, Recon: 0.7250, KL: 48.0063, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7360, Val Loss: 48.7161, Recon: 0.7321, KL: 48.0040, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7368, Val Loss: 48.7327, Recon: 0.7295, KL: 48.0073, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7155, Val Loss: 48.7091, Recon: 0.7134, KL: 48.0021, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7255, Val Loss: 48.7042, Recon: 0.7210, KL: 48.0045, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7197, Val Loss: 48.7035, Recon: 0.7169, KL: 48.0028, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7219, Val Loss: 48.7062, Recon: 0.7202, KL: 48.0018, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7334, Val Loss: 48.7236, Recon: 0.7265, KL: 48.0069, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7161, Val Loss: 48.7075, Recon: 0.7135, KL: 48.0026, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7172, Val Loss: 48.7250, Recon: 0.7151, KL: 48.0021, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7152, Val Loss: 48.7175, Recon: 0.7123, KL: 48.0029, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7186, Val Loss: 48.7276, Recon: 0.7144, KL: 48.0042, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7137, Val Loss: 48.6989, Recon: 0.7074, KL: 48.0062, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7172, Val Loss: 48.7104, Recon: 0.7110, KL: 48.0062, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7140, Val Loss: 48.7087, Recon: 0.7115, KL: 48.0025, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7258, Val Loss: 48.7163, Recon: 0.7162, KL: 48.0096, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7333, Val Loss: 48.7119, Recon: 0.7271, KL: 48.0061, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7092, Val Loss: 48.7109, Recon: 0.7076, KL: 48.0016, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7164, Val Loss: 48.7248, Recon: 0.7089, KL: 48.0075, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7097, Val Loss: 48.6998, Recon: 0.7066, KL: 48.0031, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7123, Val Loss: 48.7082, Recon: 0.7070, KL: 48.0053, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7035, Val Loss: 48.7098, Recon: 0.7001, KL: 48.0034, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7011, Val Loss: 48.6966, Recon: 0.6981, KL: 48.0030, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7036, Val Loss: 48.6916, Recon: 0.7012, KL: 48.0024, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7161, Val Loss: 48.6926, Recon: 0.7090, KL: 48.0071, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6989, Val Loss: 48.6936, Recon: 0.6963, KL: 48.0026, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7116, Val Loss: 48.7183, Recon: 0.7059, KL: 48.0057, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7031, Val Loss: 48.6946, Recon: 0.7004, KL: 48.0027, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6979, Val Loss: 48.6887, Recon: 0.6940, KL: 48.0039, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7034, Val Loss: 48.6930, Recon: 0.6932, KL: 48.0102, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6951, Val Loss: 48.6902, Recon: 0.6913, KL: 48.0038, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6927, Val Loss: 48.6851, Recon: 0.6913, KL: 48.0014, KL_weight: 4.8000
Saved model 16 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_15.pt
Training bootstrap model 17/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9918, Val Loss: 0.7241, Recon: 0.9918, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7123, Val Loss: 4.6338, Recon: 0.8396, KL: 3.8727, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4892, Val Loss: 9.4289, Recon: 0.8152, KL: 8.6740, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2526, Val Loss: 14.2038, Recon: 0.8009, KL: 13.4517, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0313, Val Loss: 18.9784, Recon: 0.7837, KL: 18.2475, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8328, Val Loss: 23.7942, Recon: 0.7782, KL: 23.0546, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6382, Val Loss: 28.5834, Recon: 0.7867, KL: 27.8516, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4127, Val Loss: 33.3766, Recon: 0.7652, KL: 32.6475, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2134, Val Loss: 38.1862, Recon: 0.7676, KL: 37.4457, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0149, Val Loss: 42.9825, Recon: 0.7651, KL: 42.2498, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7957, Val Loss: 47.7960, Recon: 0.7521, KL: 47.0436, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7608, Val Loss: 48.7227, Recon: 0.7542, KL: 48.0066, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7771, Val Loss: 48.7398, Recon: 0.7645, KL: 48.0126, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7677, Val Loss: 48.7652, Recon: 0.7601, KL: 48.0077, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7639, Val Loss: 48.7571, Recon: 0.7462, KL: 48.0178, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7548, Val Loss: 48.7684, Recon: 0.7478, KL: 48.0070, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7429, Val Loss: 48.7386, Recon: 0.7388, KL: 48.0041, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7461, Val Loss: 48.7300, Recon: 0.7409, KL: 48.0053, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7403, Val Loss: 48.7158, Recon: 0.7354, KL: 48.0049, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7471, Val Loss: 48.7053, Recon: 0.7406, KL: 48.0065, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7549, Val Loss: 48.7011, Recon: 0.7486, KL: 48.0064, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7333, Val Loss: 48.7302, Recon: 0.7297, KL: 48.0035, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7593, Val Loss: 48.7216, Recon: 0.7526, KL: 48.0068, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7432, Val Loss: 48.7133, Recon: 0.7394, KL: 48.0037, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7382, Val Loss: 48.7261, Recon: 0.7338, KL: 48.0044, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7318, Val Loss: 48.7172, Recon: 0.7282, KL: 48.0036, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7248, Val Loss: 48.7121, Recon: 0.7200, KL: 48.0049, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7363, Val Loss: 48.7216, Recon: 0.7330, KL: 48.0033, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7414, Val Loss: 48.7191, Recon: 0.7320, KL: 48.0094, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7372, Val Loss: 48.7338, Recon: 0.7277, KL: 48.0095, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7304, Val Loss: 48.7058, Recon: 0.7280, KL: 48.0024, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7275, Val Loss: 48.7155, Recon: 0.7240, KL: 48.0035, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7249, Val Loss: 48.7146, Recon: 0.7228, KL: 48.0022, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7232, Val Loss: 48.7053, Recon: 0.7207, KL: 48.0025, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7221, Val Loss: 48.7076, Recon: 0.7187, KL: 48.0034, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7291, Val Loss: 48.7150, Recon: 0.7278, KL: 48.0013, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7271, Val Loss: 48.7054, Recon: 0.7251, KL: 48.0021, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7264, Val Loss: 48.7081, Recon: 0.7226, KL: 48.0038, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7294, Val Loss: 48.7129, Recon: 0.7237, KL: 48.0057, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7386, Val Loss: 48.7098, Recon: 0.7224, KL: 48.0161, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7187, Val Loss: 48.7044, Recon: 0.7171, KL: 48.0016, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7447, Val Loss: 48.7107, Recon: 0.7263, KL: 48.0184, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7197, Val Loss: 48.7054, Recon: 0.7169, KL: 48.0028, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7256, Val Loss: 48.7063, Recon: 0.7222, KL: 48.0034, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7154, Val Loss: 48.7045, Recon: 0.7140, KL: 48.0014, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7170, Val Loss: 48.7079, Recon: 0.7137, KL: 48.0033, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7113, Val Loss: 48.7106, Recon: 0.7091, KL: 48.0022, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7220, Val Loss: 48.7052, Recon: 0.7197, KL: 48.0022, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7102, Val Loss: 48.6956, Recon: 0.7069, KL: 48.0033, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7209, Val Loss: 48.7039, Recon: 0.7170, KL: 48.0040, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.7218, Val Loss: 48.7037, Recon: 0.7187, KL: 48.0031, KL_weight: 4.8000
Saved model 17 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_16.pt
Training bootstrap model 18/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9776, Val Loss: 0.7379, Recon: 0.9776, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7107, Val Loss: 4.6569, Recon: 0.8396, KL: 3.8711, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4571, Val Loss: 9.4186, Recon: 0.7993, KL: 8.6578, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2491, Val Loss: 14.2115, Recon: 0.7948, KL: 13.4543, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0266, Val Loss: 18.9903, Recon: 0.7734, KL: 18.2532, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8219, Val Loss: 23.7826, Recon: 0.7752, KL: 23.0467, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6250, Val Loss: 28.6003, Recon: 0.7778, KL: 27.8472, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4204, Val Loss: 33.4007, Recon: 0.7704, KL: 32.6501, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1951, Val Loss: 38.1880, Recon: 0.7492, KL: 37.4459, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0275, Val Loss: 42.9876, Recon: 0.7662, KL: 42.2612, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8237, Val Loss: 47.7948, Recon: 0.7668, KL: 47.0570, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7446, Val Loss: 48.7217, Recon: 0.7392, KL: 48.0054, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7490, Val Loss: 48.7144, Recon: 0.7426, KL: 48.0063, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7546, Val Loss: 48.7423, Recon: 0.7483, KL: 48.0063, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7451, Val Loss: 48.7183, Recon: 0.7429, KL: 48.0022, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7393, Val Loss: 48.7151, Recon: 0.7375, KL: 48.0018, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7311, Val Loss: 48.7218, Recon: 0.7278, KL: 48.0033, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7470, Val Loss: 48.7272, Recon: 0.7396, KL: 48.0074, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7245, Val Loss: 48.7299, Recon: 0.7225, KL: 48.0020, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7336, Val Loss: 48.7419, Recon: 0.7278, KL: 48.0058, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7298, Val Loss: 48.7068, Recon: 0.7271, KL: 48.0026, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7273, Val Loss: 48.7140, Recon: 0.7217, KL: 48.0056, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7320, Val Loss: 48.7133, Recon: 0.7281, KL: 48.0039, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7276, Val Loss: 48.7111, Recon: 0.7231, KL: 48.0046, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7351, Val Loss: 48.7150, Recon: 0.7250, KL: 48.0101, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7286, Val Loss: 48.7150, Recon: 0.7239, KL: 48.0047, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7158, Val Loss: 48.7187, Recon: 0.7131, KL: 48.0028, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7352, Val Loss: 48.7086, Recon: 0.7177, KL: 48.0175, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7436, Val Loss: 48.7229, Recon: 0.7299, KL: 48.0136, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7152, Val Loss: 48.6996, Recon: 0.7114, KL: 48.0039, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7124, Val Loss: 48.6989, Recon: 0.7053, KL: 48.0071, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7045, Val Loss: 48.6824, Recon: 0.7000, KL: 48.0046, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7110, Val Loss: 48.6920, Recon: 0.7080, KL: 48.0030, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7029, Val Loss: 48.6883, Recon: 0.6991, KL: 48.0038, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6910, Val Loss: 48.6780, Recon: 0.6878, KL: 48.0031, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6985, Val Loss: 48.6929, Recon: 0.6948, KL: 48.0038, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6952, Val Loss: 48.6925, Recon: 0.6930, KL: 48.0022, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6992, Val Loss: 48.6800, Recon: 0.6908, KL: 48.0084, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6978, Val Loss: 48.6799, Recon: 0.6939, KL: 48.0040, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6949, Val Loss: 48.6860, Recon: 0.6903, KL: 48.0047, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6904, Val Loss: 48.6735, Recon: 0.6862, KL: 48.0043, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6946, Val Loss: 48.6820, Recon: 0.6911, KL: 48.0035, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6984, Val Loss: 48.6962, Recon: 0.6921, KL: 48.0063, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6971, Val Loss: 48.6778, Recon: 0.6933, KL: 48.0038, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6845, Val Loss: 48.6777, Recon: 0.6820, KL: 48.0025, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6950, Val Loss: 48.6793, Recon: 0.6903, KL: 48.0047, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6849, Val Loss: 48.6757, Recon: 0.6816, KL: 48.0034, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6918, Val Loss: 48.6764, Recon: 0.6857, KL: 48.0061, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6862, Val Loss: 48.6734, Recon: 0.6827, KL: 48.0035, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6793, Val Loss: 48.6732, Recon: 0.6760, KL: 48.0033, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6946, Val Loss: 48.6760, Recon: 0.6930, KL: 48.0016, KL_weight: 4.8000
Saved model 18 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_17.pt
Training bootstrap model 19/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9523, Val Loss: 0.7293, Recon: 0.9523, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6797, Val Loss: 4.6299, Recon: 0.8176, KL: 3.8621, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4483, Val Loss: 9.4193, Recon: 0.7940, KL: 8.6543, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2213, Val Loss: 14.2227, Recon: 0.7713, KL: 13.4500, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0171, Val Loss: 19.0091, Recon: 0.7676, KL: 18.2495, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8021, Val Loss: 23.7989, Recon: 0.7515, KL: 23.0505, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6081, Val Loss: 28.6025, Recon: 0.7558, KL: 27.8523, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3890, Val Loss: 33.3944, Recon: 0.7419, KL: 32.6471, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1895, Val Loss: 38.1743, Recon: 0.7434, KL: 37.4461, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9929, Val Loss: 42.9724, Recon: 0.7433, KL: 42.2495, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7951, Val Loss: 47.7667, Recon: 0.7475, KL: 47.0476, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7458, Val Loss: 48.7539, Recon: 0.7380, KL: 48.0078, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7323, Val Loss: 48.7251, Recon: 0.7274, KL: 48.0049, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7577, Val Loss: 48.7334, Recon: 0.7400, KL: 48.0177, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7355, Val Loss: 48.7112, Recon: 0.7325, KL: 48.0029, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7424, Val Loss: 48.7203, Recon: 0.7369, KL: 48.0055, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7272, Val Loss: 48.7350, Recon: 0.7212, KL: 48.0060, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7236, Val Loss: 48.7179, Recon: 0.7190, KL: 48.0046, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7166, Val Loss: 48.7264, Recon: 0.7136, KL: 48.0030, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7188, Val Loss: 48.7431, Recon: 0.7144, KL: 48.0044, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7114, Val Loss: 48.7145, Recon: 0.7089, KL: 48.0025, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7299, Val Loss: 48.7235, Recon: 0.7222, KL: 48.0076, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7106, Val Loss: 48.7166, Recon: 0.7075, KL: 48.0032, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7204, Val Loss: 48.7259, Recon: 0.7134, KL: 48.0071, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7048, Val Loss: 48.6985, Recon: 0.7018, KL: 48.0030, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7131, Val Loss: 48.7192, Recon: 0.7110, KL: 48.0021, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7233, Val Loss: 48.7152, Recon: 0.7134, KL: 48.0099, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7019, Val Loss: 48.6963, Recon: 0.6989, KL: 48.0031, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7060, Val Loss: 48.7179, Recon: 0.7010, KL: 48.0050, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7018, Val Loss: 48.7133, Recon: 0.6984, KL: 48.0033, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7100, Val Loss: 48.6861, Recon: 0.7045, KL: 48.0056, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6934, Val Loss: 48.7011, Recon: 0.6896, KL: 48.0038, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6975, Val Loss: 48.6813, Recon: 0.6951, KL: 48.0024, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6923, Val Loss: 48.7006, Recon: 0.6890, KL: 48.0033, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6971, Val Loss: 48.6997, Recon: 0.6952, KL: 48.0020, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6971, Val Loss: 48.6882, Recon: 0.6923, KL: 48.0047, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6966, Val Loss: 48.6968, Recon: 0.6926, KL: 48.0040, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6942, Val Loss: 48.6900, Recon: 0.6923, KL: 48.0019, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6881, Val Loss: 48.6837, Recon: 0.6856, KL: 48.0025, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6859, Val Loss: 48.6984, Recon: 0.6824, KL: 48.0035, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6940, Val Loss: 48.6921, Recon: 0.6891, KL: 48.0049, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6847, Val Loss: 48.6953, Recon: 0.6823, KL: 48.0024, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6990, Val Loss: 48.6868, Recon: 0.6955, KL: 48.0036, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6843, Val Loss: 48.6751, Recon: 0.6815, KL: 48.0027, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6842, Val Loss: 48.6809, Recon: 0.6823, KL: 48.0019, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6856, Val Loss: 48.6832, Recon: 0.6821, KL: 48.0035, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6800, Val Loss: 48.6807, Recon: 0.6751, KL: 48.0050, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6935, Val Loss: 48.6858, Recon: 0.6900, KL: 48.0036, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6784, Val Loss: 48.6775, Recon: 0.6748, KL: 48.0036, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6767, Val Loss: 48.6711, Recon: 0.6747, KL: 48.0020, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6845, Val Loss: 48.6728, Recon: 0.6815, KL: 48.0030, KL_weight: 4.8000
Saved model 19 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_18.pt
Training bootstrap model 20/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9145, Val Loss: 0.7074, Recon: 0.9145, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6868, Val Loss: 4.6370, Recon: 0.8184, KL: 3.8684, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4524, Val Loss: 9.4186, Recon: 0.7912, KL: 8.6612, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2292, Val Loss: 14.1957, Recon: 0.7760, KL: 13.4531, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0092, Val Loss: 18.9967, Recon: 0.7609, KL: 18.2484, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8128, Val Loss: 23.8069, Recon: 0.7622, KL: 23.0507, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.5958, Val Loss: 28.5730, Recon: 0.7502, KL: 27.8455, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3977, Val Loss: 33.3799, Recon: 0.7491, KL: 32.6487, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1998, Val Loss: 38.2019, Recon: 0.7512, KL: 37.4486, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9894, Val Loss: 42.9775, Recon: 0.7445, KL: 42.2449, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8060, Val Loss: 47.7738, Recon: 0.7616, KL: 47.0444, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7578, Val Loss: 48.7287, Recon: 0.7519, KL: 48.0060, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7725, Val Loss: 48.7366, Recon: 0.7565, KL: 48.0160, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7398, Val Loss: 48.7274, Recon: 0.7354, KL: 48.0044, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7422, Val Loss: 48.7336, Recon: 0.7342, KL: 48.0080, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7437, Val Loss: 48.7308, Recon: 0.7360, KL: 48.0077, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7335, Val Loss: 48.7177, Recon: 0.7271, KL: 48.0064, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7413, Val Loss: 48.7190, Recon: 0.7331, KL: 48.0082, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7174, Val Loss: 48.7133, Recon: 0.7137, KL: 48.0038, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7236, Val Loss: 48.7126, Recon: 0.7179, KL: 48.0057, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7151, Val Loss: 48.7231, Recon: 0.7121, KL: 48.0030, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7176, Val Loss: 48.7091, Recon: 0.7141, KL: 48.0036, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7567, Val Loss: 48.7120, Recon: 0.7359, KL: 48.0208, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7340, Val Loss: 48.7377, Recon: 0.7229, KL: 48.0111, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7165, Val Loss: 48.7030, Recon: 0.7113, KL: 48.0052, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7190, Val Loss: 48.6899, Recon: 0.7149, KL: 48.0041, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7011, Val Loss: 48.7033, Recon: 0.6979, KL: 48.0032, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7049, Val Loss: 48.6981, Recon: 0.7008, KL: 48.0041, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7055, Val Loss: 48.7159, Recon: 0.7020, KL: 48.0035, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7054, Val Loss: 48.7034, Recon: 0.7015, KL: 48.0040, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7105, Val Loss: 48.6888, Recon: 0.7053, KL: 48.0052, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7068, Val Loss: 48.6973, Recon: 0.7025, KL: 48.0043, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7010, Val Loss: 48.7018, Recon: 0.6938, KL: 48.0072, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7001, Val Loss: 48.6854, Recon: 0.6939, KL: 48.0062, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7075, Val Loss: 48.6994, Recon: 0.7004, KL: 48.0071, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6953, Val Loss: 48.6999, Recon: 0.6909, KL: 48.0044, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7063, Val Loss: 48.7188, Recon: 0.7007, KL: 48.0056, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7080, Val Loss: 48.7018, Recon: 0.7020, KL: 48.0060, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7086, Val Loss: 48.6880, Recon: 0.7050, KL: 48.0036, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7046, Val Loss: 48.6890, Recon: 0.7008, KL: 48.0037, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6916, Val Loss: 48.6911, Recon: 0.6888, KL: 48.0028, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6969, Val Loss: 48.6978, Recon: 0.6941, KL: 48.0028, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6976, Val Loss: 48.6989, Recon: 0.6899, KL: 48.0077, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7029, Val Loss: 48.6937, Recon: 0.6956, KL: 48.0073, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6835, Val Loss: 48.6853, Recon: 0.6813, KL: 48.0022, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6919, Val Loss: 48.6784, Recon: 0.6878, KL: 48.0041, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7012, Val Loss: 48.6819, Recon: 0.6958, KL: 48.0054, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6856, Val Loss: 48.6676, Recon: 0.6818, KL: 48.0038, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6850, Val Loss: 48.6825, Recon: 0.6826, KL: 48.0024, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6872, Val Loss: 48.6744, Recon: 0.6855, KL: 48.0017, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6787, Val Loss: 48.6885, Recon: 0.6763, KL: 48.0024, KL_weight: 4.8000
Saved model 20 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_19.pt
Training bootstrap model 21/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9525, Val Loss: 0.7256, Recon: 0.9525, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6937, Val Loss: 4.6401, Recon: 0.8244, KL: 3.8693, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4496, Val Loss: 9.4136, Recon: 0.7928, KL: 8.6568, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2372, Val Loss: 14.2102, Recon: 0.7804, KL: 13.4569, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0164, Val Loss: 18.9900, Recon: 0.7639, KL: 18.2525, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8077, Val Loss: 23.7897, Recon: 0.7539, KL: 23.0538, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6211, Val Loss: 28.5812, Recon: 0.7672, KL: 27.8540, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3956, Val Loss: 33.3773, Recon: 0.7493, KL: 32.6463, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2004, Val Loss: 38.1840, Recon: 0.7510, KL: 37.4494, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9837, Val Loss: 42.9597, Recon: 0.7392, KL: 42.2445, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7935, Val Loss: 47.7830, Recon: 0.7453, KL: 47.0482, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7635, Val Loss: 48.7506, Recon: 0.7467, KL: 48.0169, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7499, Val Loss: 48.7502, Recon: 0.7343, KL: 48.0156, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7515, Val Loss: 48.7268, Recon: 0.7381, KL: 48.0134, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7334, Val Loss: 48.7198, Recon: 0.7289, KL: 48.0045, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7244, Val Loss: 48.7116, Recon: 0.7192, KL: 48.0052, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7344, Val Loss: 48.7319, Recon: 0.7267, KL: 48.0076, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7382, Val Loss: 48.7422, Recon: 0.7311, KL: 48.0071, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7239, Val Loss: 48.7134, Recon: 0.7208, KL: 48.0031, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7190, Val Loss: 48.7332, Recon: 0.7162, KL: 48.0028, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7303, Val Loss: 48.7329, Recon: 0.7228, KL: 48.0075, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7277, Val Loss: 48.7149, Recon: 0.7235, KL: 48.0041, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7281, Val Loss: 48.7546, Recon: 0.7217, KL: 48.0064, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7159, Val Loss: 48.7072, Recon: 0.7133, KL: 48.0027, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7424, Val Loss: 48.7184, Recon: 0.7338, KL: 48.0086, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7223, Val Loss: 48.7272, Recon: 0.7193, KL: 48.0030, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7209, Val Loss: 48.7228, Recon: 0.7167, KL: 48.0041, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7197, Val Loss: 48.7276, Recon: 0.7157, KL: 48.0040, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7187, Val Loss: 48.7147, Recon: 0.7153, KL: 48.0034, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7092, Val Loss: 48.7121, Recon: 0.7080, KL: 48.0012, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7128, Val Loss: 48.7015, Recon: 0.7095, KL: 48.0032, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7182, Val Loss: 48.7094, Recon: 0.7133, KL: 48.0049, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7162, Val Loss: 48.7107, Recon: 0.7103, KL: 48.0060, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7169, Val Loss: 48.7245, Recon: 0.7044, KL: 48.0125, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7093, Val Loss: 48.7045, Recon: 0.7072, KL: 48.0021, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7085, Val Loss: 48.6990, Recon: 0.7042, KL: 48.0043, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7314, Val Loss: 48.7212, Recon: 0.7266, KL: 48.0048, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7109, Val Loss: 48.7176, Recon: 0.7027, KL: 48.0081, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7006, Val Loss: 48.6987, Recon: 0.6974, KL: 48.0032, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7061, Val Loss: 48.7062, Recon: 0.7009, KL: 48.0051, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7074, Val Loss: 48.7025, Recon: 0.7030, KL: 48.0044, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7107, Val Loss: 48.7082, Recon: 0.7065, KL: 48.0042, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6961, Val Loss: 48.6994, Recon: 0.6927, KL: 48.0035, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6913, Val Loss: 48.6822, Recon: 0.6892, KL: 48.0021, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6895, Val Loss: 48.6831, Recon: 0.6878, KL: 48.0016, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7094, Val Loss: 48.6990, Recon: 0.7036, KL: 48.0058, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7053, Val Loss: 48.7054, Recon: 0.6929, KL: 48.0124, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6825, Val Loss: 48.6832, Recon: 0.6810, KL: 48.0015, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6900, Val Loss: 48.6818, Recon: 0.6871, KL: 48.0029, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6820, Val Loss: 48.6761, Recon: 0.6809, KL: 48.0011, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6951, Val Loss: 48.7078, Recon: 0.6892, KL: 48.0059, KL_weight: 4.8000
Saved model 21 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_20.pt
Training bootstrap model 22/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9750, Val Loss: 0.7570, Recon: 0.9750, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6919, Val Loss: 4.6327, Recon: 0.8205, KL: 3.8714, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4412, Val Loss: 9.4127, Recon: 0.7851, KL: 8.6561, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2275, Val Loss: 14.2137, Recon: 0.7720, KL: 13.4555, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0074, Val Loss: 18.9902, Recon: 0.7573, KL: 18.2501, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.7928, Val Loss: 23.8018, Recon: 0.7429, KL: 23.0499, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6179, Val Loss: 28.5848, Recon: 0.7613, KL: 27.8566, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3911, Val Loss: 33.3992, Recon: 0.7397, KL: 32.6513, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1839, Val Loss: 38.1702, Recon: 0.7382, KL: 37.4457, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9706, Val Loss: 42.9542, Recon: 0.7271, KL: 42.2435, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7753, Val Loss: 47.7674, Recon: 0.7307, KL: 47.0445, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7459, Val Loss: 48.7408, Recon: 0.7389, KL: 48.0070, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7511, Val Loss: 48.7127, Recon: 0.7476, KL: 48.0035, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7264, Val Loss: 48.7196, Recon: 0.7238, KL: 48.0026, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7309, Val Loss: 48.7182, Recon: 0.7241, KL: 48.0067, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7555, Val Loss: 48.7192, Recon: 0.7419, KL: 48.0136, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7678, Val Loss: 48.7199, Recon: 0.7471, KL: 48.0207, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7291, Val Loss: 48.7175, Recon: 0.7249, KL: 48.0042, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7222, Val Loss: 48.7086, Recon: 0.7188, KL: 48.0033, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7147, Val Loss: 48.7102, Recon: 0.7117, KL: 48.0030, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7093, Val Loss: 48.7042, Recon: 0.7076, KL: 48.0017, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7223, Val Loss: 48.7173, Recon: 0.7177, KL: 48.0047, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7036, Val Loss: 48.7050, Recon: 0.7024, KL: 48.0013, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7164, Val Loss: 48.7251, Recon: 0.7083, KL: 48.0081, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7245, Val Loss: 48.7096, Recon: 0.7169, KL: 48.0077, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7083, Val Loss: 48.7012, Recon: 0.7056, KL: 48.0027, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7105, Val Loss: 48.7037, Recon: 0.7071, KL: 48.0034, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7228, Val Loss: 48.7142, Recon: 0.7194, KL: 48.0034, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.6981, Val Loss: 48.7022, Recon: 0.6959, KL: 48.0022, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7072, Val Loss: 48.7333, Recon: 0.7026, KL: 48.0046, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7044, Val Loss: 48.7001, Recon: 0.7010, KL: 48.0034, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7137, Val Loss: 48.7110, Recon: 0.7038, KL: 48.0099, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6953, Val Loss: 48.7096, Recon: 0.6925, KL: 48.0028, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7016, Val Loss: 48.7015, Recon: 0.6982, KL: 48.0034, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7013, Val Loss: 48.7016, Recon: 0.6989, KL: 48.0024, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6949, Val Loss: 48.6995, Recon: 0.6925, KL: 48.0025, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7062, Val Loss: 48.6952, Recon: 0.6982, KL: 48.0080, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6958, Val Loss: 48.7160, Recon: 0.6936, KL: 48.0022, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6960, Val Loss: 48.7003, Recon: 0.6914, KL: 48.0046, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6927, Val Loss: 48.6850, Recon: 0.6900, KL: 48.0027, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6981, Val Loss: 48.7015, Recon: 0.6915, KL: 48.0066, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6934, Val Loss: 48.6887, Recon: 0.6912, KL: 48.0022, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6912, Val Loss: 48.6940, Recon: 0.6859, KL: 48.0053, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6889, Val Loss: 48.6956, Recon: 0.6831, KL: 48.0059, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6828, Val Loss: 48.6904, Recon: 0.6809, KL: 48.0019, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6883, Val Loss: 48.6766, Recon: 0.6843, KL: 48.0040, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6870, Val Loss: 48.6778, Recon: 0.6807, KL: 48.0064, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6876, Val Loss: 48.7106, Recon: 0.6794, KL: 48.0082, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6880, Val Loss: 48.6933, Recon: 0.6826, KL: 48.0053, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6843, Val Loss: 48.6829, Recon: 0.6752, KL: 48.0091, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6806, Val Loss: 48.6909, Recon: 0.6773, KL: 48.0034, KL_weight: 4.8000
Saved model 22 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_21.pt
Training bootstrap model 23/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9661, Val Loss: 0.7340, Recon: 0.9661, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7075, Val Loss: 4.6313, Recon: 0.8338, KL: 3.8737, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4647, Val Loss: 9.4128, Recon: 0.8046, KL: 8.6601, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2402, Val Loss: 14.2017, Recon: 0.7886, KL: 13.4516, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0273, Val Loss: 19.0039, Recon: 0.7777, KL: 18.2497, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8576, Val Loss: 23.8106, Recon: 0.7907, KL: 23.0669, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6088, Val Loss: 28.5855, Recon: 0.7612, KL: 27.8477, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4129, Val Loss: 33.3774, Recon: 0.7682, KL: 32.6446, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2192, Val Loss: 38.1838, Recon: 0.7674, KL: 37.4518, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0127, Val Loss: 42.9859, Recon: 0.7616, KL: 42.2511, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8407, Val Loss: 47.8372, Recon: 0.7747, KL: 47.0659, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7615, Val Loss: 48.7460, Recon: 0.7502, KL: 48.0113, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7486, Val Loss: 48.7149, Recon: 0.7448, KL: 48.0038, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7445, Val Loss: 48.7178, Recon: 0.7405, KL: 48.0041, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7528, Val Loss: 48.7186, Recon: 0.7467, KL: 48.0061, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7446, Val Loss: 48.7210, Recon: 0.7376, KL: 48.0070, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7380, Val Loss: 48.7191, Recon: 0.7332, KL: 48.0048, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7304, Val Loss: 48.7005, Recon: 0.7262, KL: 48.0041, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7394, Val Loss: 48.7231, Recon: 0.7337, KL: 48.0057, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7294, Val Loss: 48.7115, Recon: 0.7253, KL: 48.0041, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7202, Val Loss: 48.7063, Recon: 0.7154, KL: 48.0047, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7255, Val Loss: 48.7293, Recon: 0.7165, KL: 48.0089, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7269, Val Loss: 48.7011, Recon: 0.7196, KL: 48.0073, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7217, Val Loss: 48.7096, Recon: 0.7164, KL: 48.0053, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7245, Val Loss: 48.7076, Recon: 0.7175, KL: 48.0070, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7162, Val Loss: 48.7027, Recon: 0.7108, KL: 48.0054, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7187, Val Loss: 48.7014, Recon: 0.7129, KL: 48.0058, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7163, Val Loss: 48.7148, Recon: 0.7118, KL: 48.0045, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7107, Val Loss: 48.6946, Recon: 0.7066, KL: 48.0041, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7128, Val Loss: 48.7226, Recon: 0.7033, KL: 48.0095, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7131, Val Loss: 48.7021, Recon: 0.7087, KL: 48.0044, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7081, Val Loss: 48.6893, Recon: 0.7048, KL: 48.0033, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7084, Val Loss: 48.6996, Recon: 0.7034, KL: 48.0050, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7116, Val Loss: 48.7049, Recon: 0.7030, KL: 48.0086, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7125, Val Loss: 48.6855, Recon: 0.7055, KL: 48.0070, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6989, Val Loss: 48.6780, Recon: 0.6967, KL: 48.0023, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6936, Val Loss: 48.6877, Recon: 0.6907, KL: 48.0029, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6980, Val Loss: 48.6775, Recon: 0.6943, KL: 48.0037, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6985, Val Loss: 48.6801, Recon: 0.6930, KL: 48.0054, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6955, Val Loss: 48.6904, Recon: 0.6928, KL: 48.0027, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7048, Val Loss: 48.6971, Recon: 0.6989, KL: 48.0058, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6995, Val Loss: 48.6790, Recon: 0.6963, KL: 48.0032, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6994, Val Loss: 48.6972, Recon: 0.6958, KL: 48.0035, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6937, Val Loss: 48.6756, Recon: 0.6902, KL: 48.0035, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6865, Val Loss: 48.6811, Recon: 0.6829, KL: 48.0035, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6896, Val Loss: 48.6845, Recon: 0.6868, KL: 48.0028, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6867, Val Loss: 48.6773, Recon: 0.6821, KL: 48.0046, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7015, Val Loss: 48.6758, Recon: 0.6935, KL: 48.0080, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6920, Val Loss: 48.6850, Recon: 0.6878, KL: 48.0042, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6983, Val Loss: 48.6882, Recon: 0.6921, KL: 48.0062, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6857, Val Loss: 48.6789, Recon: 0.6823, KL: 48.0034, KL_weight: 4.8000
Saved model 23 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_22.pt
Training bootstrap model 24/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9655, Val Loss: 0.7446, Recon: 0.9655, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6992, Val Loss: 4.6477, Recon: 0.8235, KL: 3.8757, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4519, Val Loss: 9.4029, Recon: 0.7967, KL: 8.6553, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2267, Val Loss: 14.1860, Recon: 0.7753, KL: 13.4514, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0315, Val Loss: 19.0034, Recon: 0.7807, KL: 18.2508, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8186, Val Loss: 23.7751, Recon: 0.7671, KL: 23.0515, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.5987, Val Loss: 28.5844, Recon: 0.7521, KL: 27.8466, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3993, Val Loss: 33.3838, Recon: 0.7535, KL: 32.6459, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1948, Val Loss: 38.1624, Recon: 0.7492, KL: 37.4456, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0173, Val Loss: 42.9732, Recon: 0.7581, KL: 42.2592, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8087, Val Loss: 47.7788, Recon: 0.7604, KL: 47.0483, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7492, Val Loss: 48.7206, Recon: 0.7445, KL: 48.0047, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7531, Val Loss: 48.7196, Recon: 0.7480, KL: 48.0052, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7347, Val Loss: 48.7256, Recon: 0.7319, KL: 48.0028, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7428, Val Loss: 48.7370, Recon: 0.7394, KL: 48.0034, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7276, Val Loss: 48.7172, Recon: 0.7247, KL: 48.0030, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7346, Val Loss: 48.7451, Recon: 0.7281, KL: 48.0065, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7359, Val Loss: 48.7320, Recon: 0.7309, KL: 48.0051, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7246, Val Loss: 48.7061, Recon: 0.7220, KL: 48.0026, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7254, Val Loss: 48.7149, Recon: 0.7203, KL: 48.0051, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7254, Val Loss: 48.7120, Recon: 0.7233, KL: 48.0022, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7416, Val Loss: 48.7053, Recon: 0.7389, KL: 48.0028, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7299, Val Loss: 48.7156, Recon: 0.7250, KL: 48.0049, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7146, Val Loss: 48.7035, Recon: 0.7125, KL: 48.0021, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7279, Val Loss: 48.7046, Recon: 0.7216, KL: 48.0064, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7172, Val Loss: 48.7005, Recon: 0.7129, KL: 48.0044, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7138, Val Loss: 48.7146, Recon: 0.7080, KL: 48.0058, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7056, Val Loss: 48.6999, Recon: 0.7025, KL: 48.0031, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7093, Val Loss: 48.6909, Recon: 0.7057, KL: 48.0036, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.6989, Val Loss: 48.6884, Recon: 0.6955, KL: 48.0034, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7093, Val Loss: 48.7056, Recon: 0.7004, KL: 48.0089, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7013, Val Loss: 48.6896, Recon: 0.6981, KL: 48.0032, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7059, Val Loss: 48.7024, Recon: 0.7004, KL: 48.0056, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7004, Val Loss: 48.6880, Recon: 0.6977, KL: 48.0027, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7048, Val Loss: 48.6981, Recon: 0.7016, KL: 48.0033, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6962, Val Loss: 48.6881, Recon: 0.6935, KL: 48.0027, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7746, Val Loss: 48.7014, Recon: 0.7021, KL: 48.0725, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7092, Val Loss: 48.7010, Recon: 0.7048, KL: 48.0044, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6961, Val Loss: 48.6747, Recon: 0.6930, KL: 48.0032, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6979, Val Loss: 48.6907, Recon: 0.6942, KL: 48.0037, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6916, Val Loss: 48.6956, Recon: 0.6887, KL: 48.0029, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6894, Val Loss: 48.6727, Recon: 0.6866, KL: 48.0027, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7001, Val Loss: 48.6755, Recon: 0.6870, KL: 48.0131, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6922, Val Loss: 48.6733, Recon: 0.6890, KL: 48.0031, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6971, Val Loss: 48.6803, Recon: 0.6927, KL: 48.0044, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6943, Val Loss: 48.6703, Recon: 0.6922, KL: 48.0021, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6814, Val Loss: 48.6793, Recon: 0.6790, KL: 48.0024, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6779, Val Loss: 48.6759, Recon: 0.6758, KL: 48.0022, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6882, Val Loss: 48.6731, Recon: 0.6844, KL: 48.0038, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6818, Val Loss: 48.6908, Recon: 0.6787, KL: 48.0031, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6822, Val Loss: 48.6748, Recon: 0.6790, KL: 48.0032, KL_weight: 4.8000
Saved model 24 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_23.pt
Training bootstrap model 25/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9294, Val Loss: 0.7201, Recon: 0.9294, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6750, Val Loss: 4.6537, Recon: 0.8098, KL: 3.8652, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4391, Val Loss: 9.4275, Recon: 0.7829, KL: 8.6563, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2279, Val Loss: 14.1866, Recon: 0.7772, KL: 13.4507, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0218, Val Loss: 18.9968, Recon: 0.7692, KL: 18.2525, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8151, Val Loss: 23.7754, Recon: 0.7676, KL: 23.0475, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6000, Val Loss: 28.5878, Recon: 0.7513, KL: 27.8487, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4013, Val Loss: 33.3972, Recon: 0.7547, KL: 32.6466, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2038, Val Loss: 38.1918, Recon: 0.7539, KL: 37.4499, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0136, Val Loss: 43.0019, Recon: 0.7536, KL: 42.2600, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8071, Val Loss: 47.7843, Recon: 0.7545, KL: 47.0526, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7364, Val Loss: 48.7246, Recon: 0.7332, KL: 48.0032, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7426, Val Loss: 48.7210, Recon: 0.7333, KL: 48.0093, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7484, Val Loss: 48.7324, Recon: 0.7433, KL: 48.0051, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7401, Val Loss: 48.7207, Recon: 0.7349, KL: 48.0052, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7473, Val Loss: 48.7335, Recon: 0.7253, KL: 48.0220, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7395, Val Loss: 48.7263, Recon: 0.7330, KL: 48.0065, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7343, Val Loss: 48.7176, Recon: 0.7296, KL: 48.0047, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7344, Val Loss: 48.7328, Recon: 0.7307, KL: 48.0038, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7195, Val Loss: 48.7333, Recon: 0.7180, KL: 48.0016, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7219, Val Loss: 48.7208, Recon: 0.7187, KL: 48.0032, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7200, Val Loss: 48.7241, Recon: 0.7168, KL: 48.0033, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7213, Val Loss: 48.7200, Recon: 0.7190, KL: 48.0023, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7441, Val Loss: 48.7128, Recon: 0.7180, KL: 48.0261, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7240, Val Loss: 48.7155, Recon: 0.7199, KL: 48.0041, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7183, Val Loss: 48.7039, Recon: 0.7152, KL: 48.0032, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7360, Val Loss: 48.7268, Recon: 0.7062, KL: 48.0298, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7416, Val Loss: 48.7199, Recon: 0.7368, KL: 48.0048, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7133, Val Loss: 48.7024, Recon: 0.7097, KL: 48.0036, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7111, Val Loss: 48.7029, Recon: 0.7063, KL: 48.0049, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7063, Val Loss: 48.6819, Recon: 0.7016, KL: 48.0046, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6975, Val Loss: 48.6926, Recon: 0.6940, KL: 48.0035, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7023, Val Loss: 48.6917, Recon: 0.6983, KL: 48.0040, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6854, Val Loss: 48.7004, Recon: 0.6837, KL: 48.0017, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6960, Val Loss: 48.6922, Recon: 0.6914, KL: 48.0046, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7009, Val Loss: 48.6829, Recon: 0.6961, KL: 48.0048, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6984, Val Loss: 48.6892, Recon: 0.6948, KL: 48.0036, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6980, Val Loss: 48.6905, Recon: 0.6926, KL: 48.0053, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6842, Val Loss: 48.6756, Recon: 0.6821, KL: 48.0021, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6955, Val Loss: 48.6963, Recon: 0.6903, KL: 48.0052, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7167, Val Loss: 48.6995, Recon: 0.7054, KL: 48.0113, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6887, Val Loss: 48.6805, Recon: 0.6840, KL: 48.0047, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6866, Val Loss: 48.6837, Recon: 0.6826, KL: 48.0039, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6961, Val Loss: 48.6858, Recon: 0.6905, KL: 48.0056, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6933, Val Loss: 48.6767, Recon: 0.6895, KL: 48.0038, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6859, Val Loss: 48.6736, Recon: 0.6822, KL: 48.0037, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6904, Val Loss: 48.6792, Recon: 0.6882, KL: 48.0021, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6763, Val Loss: 48.6666, Recon: 0.6745, KL: 48.0018, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6827, Val Loss: 48.6640, Recon: 0.6802, KL: 48.0025, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6822, Val Loss: 48.6835, Recon: 0.6777, KL: 48.0045, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6769, Val Loss: 48.6708, Recon: 0.6749, KL: 48.0021, KL_weight: 4.8000
Saved model 25 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_24.pt
Training bootstrap model 26/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9398, Val Loss: 0.7149, Recon: 0.9398, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6748, Val Loss: 4.6295, Recon: 0.8083, KL: 3.8665, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4406, Val Loss: 9.4006, Recon: 0.7868, KL: 8.6538, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2162, Val Loss: 14.2089, Recon: 0.7646, KL: 13.4516, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0095, Val Loss: 18.9939, Recon: 0.7602, KL: 18.2492, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8005, Val Loss: 23.7782, Recon: 0.7533, KL: 23.0472, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6042, Val Loss: 28.5872, Recon: 0.7529, KL: 27.8514, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3854, Val Loss: 33.3683, Recon: 0.7408, KL: 32.6446, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1970, Val Loss: 38.1839, Recon: 0.7434, KL: 37.4536, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9992, Val Loss: 42.9873, Recon: 0.7525, KL: 42.2467, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7923, Val Loss: 47.7830, Recon: 0.7432, KL: 47.0491, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7378, Val Loss: 48.7314, Recon: 0.7342, KL: 48.0036, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7445, Val Loss: 48.7233, Recon: 0.7384, KL: 48.0061, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7423, Val Loss: 48.7266, Recon: 0.7366, KL: 48.0056, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7410, Val Loss: 48.7104, Recon: 0.7377, KL: 48.0033, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7355, Val Loss: 48.7091, Recon: 0.7300, KL: 48.0055, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7278, Val Loss: 48.7059, Recon: 0.7253, KL: 48.0025, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7166, Val Loss: 48.7161, Recon: 0.7147, KL: 48.0019, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7197, Val Loss: 48.7114, Recon: 0.7143, KL: 48.0054, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7236, Val Loss: 48.7034, Recon: 0.7210, KL: 48.0026, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7135, Val Loss: 48.7120, Recon: 0.7110, KL: 48.0025, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7190, Val Loss: 48.7032, Recon: 0.7119, KL: 48.0070, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7242, Val Loss: 48.7274, Recon: 0.7159, KL: 48.0083, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7099, Val Loss: 48.7179, Recon: 0.7073, KL: 48.0026, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7183, Val Loss: 48.7057, Recon: 0.7127, KL: 48.0056, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7293, Val Loss: 48.7167, Recon: 0.7193, KL: 48.0100, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7037, Val Loss: 48.7157, Recon: 0.7008, KL: 48.0029, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7085, Val Loss: 48.7055, Recon: 0.7046, KL: 48.0039, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7111, Val Loss: 48.7054, Recon: 0.7044, KL: 48.0067, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7000, Val Loss: 48.7043, Recon: 0.6962, KL: 48.0038, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.6892, Val Loss: 48.7085, Recon: 0.6866, KL: 48.0025, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7148, Val Loss: 48.7061, Recon: 0.7109, KL: 48.0038, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7002, Val Loss: 48.6935, Recon: 0.6985, KL: 48.0017, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6929, Val Loss: 48.6932, Recon: 0.6898, KL: 48.0032, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6936, Val Loss: 48.6885, Recon: 0.6917, KL: 48.0019, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6988, Val Loss: 48.6953, Recon: 0.6935, KL: 48.0053, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6899, Val Loss: 48.6992, Recon: 0.6878, KL: 48.0020, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6856, Val Loss: 48.6858, Recon: 0.6837, KL: 48.0020, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6842, Val Loss: 48.6918, Recon: 0.6817, KL: 48.0025, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6927, Val Loss: 48.6884, Recon: 0.6883, KL: 48.0044, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6828, Val Loss: 48.6838, Recon: 0.6781, KL: 48.0047, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6870, Val Loss: 48.6817, Recon: 0.6840, KL: 48.0030, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6934, Val Loss: 48.6864, Recon: 0.6897, KL: 48.0037, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6776, Val Loss: 48.6803, Recon: 0.6758, KL: 48.0018, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6854, Val Loss: 48.6791, Recon: 0.6825, KL: 48.0028, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6779, Val Loss: 48.6904, Recon: 0.6747, KL: 48.0032, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6808, Val Loss: 48.6967, Recon: 0.6743, KL: 48.0065, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6862, Val Loss: 48.6917, Recon: 0.6775, KL: 48.0087, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6818, Val Loss: 48.6825, Recon: 0.6765, KL: 48.0052, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6719, Val Loss: 48.6723, Recon: 0.6698, KL: 48.0021, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6925, Val Loss: 48.7019, Recon: 0.6845, KL: 48.0080, KL_weight: 4.8000
Saved model 26 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_25.pt
Training bootstrap model 27/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9577, Val Loss: 0.7261, Recon: 0.9577, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6958, Val Loss: 4.6299, Recon: 0.8263, KL: 3.8696, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4633, Val Loss: 9.4274, Recon: 0.8065, KL: 8.6569, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2474, Val Loss: 14.2126, Recon: 0.7931, KL: 13.4543, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0210, Val Loss: 18.9864, Recon: 0.7718, KL: 18.2492, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8379, Val Loss: 23.8027, Recon: 0.7839, KL: 23.0540, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6029, Val Loss: 28.5890, Recon: 0.7560, KL: 27.8470, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4155, Val Loss: 33.3975, Recon: 0.7660, KL: 32.6495, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2117, Val Loss: 38.1822, Recon: 0.7646, KL: 37.4471, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0004, Val Loss: 42.9745, Recon: 0.7544, KL: 42.2461, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7988, Val Loss: 47.7767, Recon: 0.7490, KL: 47.0498, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7623, Val Loss: 48.7608, Recon: 0.7535, KL: 48.0088, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7513, Val Loss: 48.7487, Recon: 0.7432, KL: 48.0081, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7407, Val Loss: 48.7312, Recon: 0.7367, KL: 48.0040, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7437, Val Loss: 48.7349, Recon: 0.7405, KL: 48.0032, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7469, Val Loss: 48.7171, Recon: 0.7384, KL: 48.0085, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7549, Val Loss: 48.7222, Recon: 0.7492, KL: 48.0057, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7335, Val Loss: 48.7407, Recon: 0.7314, KL: 48.0021, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7345, Val Loss: 48.7228, Recon: 0.7302, KL: 48.0043, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7366, Val Loss: 48.7103, Recon: 0.7332, KL: 48.0034, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7341, Val Loss: 48.7472, Recon: 0.7301, KL: 48.0040, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7250, Val Loss: 48.7206, Recon: 0.7222, KL: 48.0027, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7263, Val Loss: 48.7097, Recon: 0.7225, KL: 48.0038, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7176, Val Loss: 48.7204, Recon: 0.7142, KL: 48.0034, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7257, Val Loss: 48.7106, Recon: 0.7223, KL: 48.0034, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7233, Val Loss: 48.6985, Recon: 0.7202, KL: 48.0031, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7238, Val Loss: 48.7305, Recon: 0.7199, KL: 48.0039, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7168, Val Loss: 48.7145, Recon: 0.7120, KL: 48.0048, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7171, Val Loss: 48.7008, Recon: 0.7148, KL: 48.0023, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7114, Val Loss: 48.6958, Recon: 0.7084, KL: 48.0030, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7174, Val Loss: 48.7049, Recon: 0.7140, KL: 48.0034, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7104, Val Loss: 48.7040, Recon: 0.7065, KL: 48.0039, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7080, Val Loss: 48.7133, Recon: 0.7045, KL: 48.0035, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7170, Val Loss: 48.6956, Recon: 0.7112, KL: 48.0058, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7061, Val Loss: 48.6893, Recon: 0.7030, KL: 48.0031, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6983, Val Loss: 48.6972, Recon: 0.6931, KL: 48.0052, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7127, Val Loss: 48.7007, Recon: 0.7043, KL: 48.0084, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7068, Val Loss: 48.7074, Recon: 0.7001, KL: 48.0067, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7076, Val Loss: 48.7203, Recon: 0.7019, KL: 48.0057, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6975, Val Loss: 48.6815, Recon: 0.6949, KL: 48.0026, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6939, Val Loss: 48.6856, Recon: 0.6889, KL: 48.0049, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6888, Val Loss: 48.6798, Recon: 0.6868, KL: 48.0020, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6902, Val Loss: 48.6813, Recon: 0.6856, KL: 48.0046, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6862, Val Loss: 48.6875, Recon: 0.6830, KL: 48.0032, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6859, Val Loss: 48.6824, Recon: 0.6829, KL: 48.0031, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6882, Val Loss: 48.6772, Recon: 0.6838, KL: 48.0044, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6930, Val Loss: 48.6822, Recon: 0.6897, KL: 48.0033, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6893, Val Loss: 48.6769, Recon: 0.6852, KL: 48.0041, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6854, Val Loss: 48.6749, Recon: 0.6828, KL: 48.0026, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7022, Val Loss: 48.6902, Recon: 0.6959, KL: 48.0063, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6956, Val Loss: 48.6748, Recon: 0.6911, KL: 48.0045, KL_weight: 4.8000
Saved model 27 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_26.pt
Training bootstrap model 28/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9639, Val Loss: 0.7431, Recon: 0.9639, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6874, Val Loss: 4.6397, Recon: 0.8183, KL: 3.8691, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4494, Val Loss: 9.4338, Recon: 0.7915, KL: 8.6580, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2402, Val Loss: 14.2428, Recon: 0.7869, KL: 13.4533, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0352, Val Loss: 18.9941, Recon: 0.7818, KL: 18.2533, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8209, Val Loss: 23.7896, Recon: 0.7709, KL: 23.0499, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.5943, Val Loss: 28.5776, Recon: 0.7467, KL: 27.8476, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4060, Val Loss: 33.3698, Recon: 0.7579, KL: 32.6481, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2045, Val Loss: 38.1810, Recon: 0.7545, KL: 37.4500, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0111, Val Loss: 43.0124, Recon: 0.7518, KL: 42.2594, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8231, Val Loss: 47.7947, Recon: 0.7640, KL: 47.0591, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7476, Val Loss: 48.7388, Recon: 0.7433, KL: 48.0043, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7427, Val Loss: 48.7382, Recon: 0.7327, KL: 48.0100, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7349, Val Loss: 48.7137, Recon: 0.7310, KL: 48.0040, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7342, Val Loss: 48.7201, Recon: 0.7284, KL: 48.0058, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7252, Val Loss: 48.7221, Recon: 0.7205, KL: 48.0047, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7302, Val Loss: 48.7151, Recon: 0.7224, KL: 48.0078, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7158, Val Loss: 48.7273, Recon: 0.7124, KL: 48.0034, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7379, Val Loss: 48.7248, Recon: 0.7288, KL: 48.0091, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7206, Val Loss: 48.7142, Recon: 0.7170, KL: 48.0036, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7449, Val Loss: 48.7138, Recon: 0.7343, KL: 48.0106, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7304, Val Loss: 48.7143, Recon: 0.7252, KL: 48.0052, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7180, Val Loss: 48.7408, Recon: 0.7110, KL: 48.0070, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7095, Val Loss: 48.7247, Recon: 0.7045, KL: 48.0050, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7211, Val Loss: 48.7211, Recon: 0.7124, KL: 48.0086, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7103, Val Loss: 48.7306, Recon: 0.7068, KL: 48.0035, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7072, Val Loss: 48.7303, Recon: 0.7033, KL: 48.0038, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7034, Val Loss: 48.7071, Recon: 0.6999, KL: 48.0035, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7091, Val Loss: 48.7251, Recon: 0.7017, KL: 48.0074, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7075, Val Loss: 48.7084, Recon: 0.6988, KL: 48.0088, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7214, Val Loss: 48.6933, Recon: 0.7139, KL: 48.0075, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6933, Val Loss: 48.7064, Recon: 0.6899, KL: 48.0034, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6889, Val Loss: 48.7004, Recon: 0.6857, KL: 48.0032, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7024, Val Loss: 48.7036, Recon: 0.6994, KL: 48.0030, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6999, Val Loss: 48.6868, Recon: 0.6929, KL: 48.0071, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6923, Val Loss: 48.6992, Recon: 0.6897, KL: 48.0026, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6906, Val Loss: 48.7054, Recon: 0.6831, KL: 48.0075, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6979, Val Loss: 48.6908, Recon: 0.6906, KL: 48.0073, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6869, Val Loss: 48.6811, Recon: 0.6847, KL: 48.0022, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6897, Val Loss: 48.6825, Recon: 0.6850, KL: 48.0047, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6938, Val Loss: 48.6868, Recon: 0.6868, KL: 48.0070, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6987, Val Loss: 48.6840, Recon: 0.6933, KL: 48.0054, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6957, Val Loss: 48.6944, Recon: 0.6888, KL: 48.0069, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6963, Val Loss: 48.6931, Recon: 0.6928, KL: 48.0035, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6821, Val Loss: 48.6771, Recon: 0.6787, KL: 48.0034, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6819, Val Loss: 48.6854, Recon: 0.6793, KL: 48.0026, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6818, Val Loss: 48.6866, Recon: 0.6778, KL: 48.0040, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6884, Val Loss: 48.6873, Recon: 0.6813, KL: 48.0071, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6760, Val Loss: 48.6853, Recon: 0.6733, KL: 48.0027, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6904, Val Loss: 48.6751, Recon: 0.6847, KL: 48.0057, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6885, Val Loss: 48.6857, Recon: 0.6849, KL: 48.0035, KL_weight: 4.8000
Saved model 28 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_27.pt
Training bootstrap model 29/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9579, Val Loss: 0.7357, Recon: 0.9579, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6854, Val Loss: 4.6195, Recon: 0.8165, KL: 3.8689, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4477, Val Loss: 9.4159, Recon: 0.7915, KL: 8.6561, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2248, Val Loss: 14.1957, Recon: 0.7745, KL: 13.4503, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0094, Val Loss: 19.0011, Recon: 0.7606, KL: 18.2488, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8101, Val Loss: 23.7942, Recon: 0.7623, KL: 23.0478, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.5936, Val Loss: 28.5689, Recon: 0.7470, KL: 27.8466, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3923, Val Loss: 33.3713, Recon: 0.7463, KL: 32.6459, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2026, Val Loss: 38.1791, Recon: 0.7532, KL: 37.4494, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0038, Val Loss: 42.9866, Recon: 0.7536, KL: 42.2502, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7965, Val Loss: 47.7841, Recon: 0.7496, KL: 47.0470, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7412, Val Loss: 48.7236, Recon: 0.7365, KL: 48.0047, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7437, Val Loss: 48.7347, Recon: 0.7375, KL: 48.0062, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7354, Val Loss: 48.7239, Recon: 0.7320, KL: 48.0034, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7261, Val Loss: 48.7150, Recon: 0.7236, KL: 48.0024, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7277, Val Loss: 48.7313, Recon: 0.7199, KL: 48.0078, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7201, Val Loss: 48.7061, Recon: 0.7163, KL: 48.0038, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7294, Val Loss: 48.7254, Recon: 0.7250, KL: 48.0044, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7311, Val Loss: 48.7136, Recon: 0.7251, KL: 48.0060, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7255, Val Loss: 48.7148, Recon: 0.7223, KL: 48.0033, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7243, Val Loss: 48.7079, Recon: 0.7203, KL: 48.0040, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7162, Val Loss: 48.7184, Recon: 0.7145, KL: 48.0017, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7264, Val Loss: 48.7157, Recon: 0.7190, KL: 48.0074, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7340, Val Loss: 48.7271, Recon: 0.7235, KL: 48.0106, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7454, Val Loss: 48.7215, Recon: 0.7318, KL: 48.0136, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7295, Val Loss: 48.7129, Recon: 0.7211, KL: 48.0084, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7208, Val Loss: 48.7078, Recon: 0.7154, KL: 48.0054, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7154, Val Loss: 48.7047, Recon: 0.7126, KL: 48.0028, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7195, Val Loss: 48.7099, Recon: 0.7172, KL: 48.0024, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7198, Val Loss: 48.7100, Recon: 0.7150, KL: 48.0048, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7167, Val Loss: 48.7049, Recon: 0.7125, KL: 48.0042, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7124, Val Loss: 48.7086, Recon: 0.7104, KL: 48.0020, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7257, Val Loss: 48.7042, Recon: 0.7231, KL: 48.0026, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7151, Val Loss: 48.7079, Recon: 0.7097, KL: 48.0054, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7146, Val Loss: 48.7067, Recon: 0.7061, KL: 48.0085, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7171, Val Loss: 48.7223, Recon: 0.7126, KL: 48.0045, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7021, Val Loss: 48.7006, Recon: 0.6991, KL: 48.0030, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7007, Val Loss: 48.6855, Recon: 0.6964, KL: 48.0043, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6940, Val Loss: 48.6892, Recon: 0.6908, KL: 48.0032, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6928, Val Loss: 48.6893, Recon: 0.6888, KL: 48.0040, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6921, Val Loss: 48.6964, Recon: 0.6876, KL: 48.0045, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6996, Val Loss: 48.6839, Recon: 0.6929, KL: 48.0068, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6883, Val Loss: 48.6915, Recon: 0.6847, KL: 48.0036, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6914, Val Loss: 48.6858, Recon: 0.6831, KL: 48.0083, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6922, Val Loss: 48.6812, Recon: 0.6877, KL: 48.0045, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6964, Val Loss: 48.6905, Recon: 0.6929, KL: 48.0035, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6880, Val Loss: 48.6812, Recon: 0.6851, KL: 48.0029, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6960, Val Loss: 48.6756, Recon: 0.6916, KL: 48.0044, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6842, Val Loss: 48.6846, Recon: 0.6798, KL: 48.0044, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6792, Val Loss: 48.6922, Recon: 0.6747, KL: 48.0045, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6870, Val Loss: 48.6693, Recon: 0.6813, KL: 48.0057, KL_weight: 4.8000
Saved model 29 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_28.pt
Training bootstrap model 30/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9814, Val Loss: 0.7774, Recon: 0.9814, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6900, Val Loss: 4.6173, Recon: 0.8242, KL: 3.8658, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4593, Val Loss: 9.4319, Recon: 0.8016, KL: 8.6577, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2419, Val Loss: 14.2085, Recon: 0.7906, KL: 13.4514, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0232, Val Loss: 19.0236, Recon: 0.7724, KL: 18.2507, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8342, Val Loss: 23.8234, Recon: 0.7772, KL: 23.0570, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6202, Val Loss: 28.5940, Recon: 0.7707, KL: 27.8495, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4043, Val Loss: 33.3882, Recon: 0.7589, KL: 32.6454, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2039, Val Loss: 38.1781, Recon: 0.7558, KL: 37.4481, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9928, Val Loss: 42.9678, Recon: 0.7487, KL: 42.2442, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8046, Val Loss: 47.8010, Recon: 0.7579, KL: 47.0467, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7584, Val Loss: 48.7428, Recon: 0.7493, KL: 48.0091, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7550, Val Loss: 48.7277, Recon: 0.7500, KL: 48.0050, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7426, Val Loss: 48.7331, Recon: 0.7395, KL: 48.0032, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7476, Val Loss: 48.7230, Recon: 0.7414, KL: 48.0062, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7439, Val Loss: 48.7187, Recon: 0.7381, KL: 48.0059, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7460, Val Loss: 48.7268, Recon: 0.7375, KL: 48.0085, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7422, Val Loss: 48.7220, Recon: 0.7348, KL: 48.0074, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7298, Val Loss: 48.7309, Recon: 0.7260, KL: 48.0038, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7356, Val Loss: 48.7354, Recon: 0.7326, KL: 48.0030, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7712, Val Loss: 48.7415, Recon: 0.7433, KL: 48.0279, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7300, Val Loss: 48.7194, Recon: 0.7257, KL: 48.0043, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7272, Val Loss: 48.7163, Recon: 0.7232, KL: 48.0041, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7330, Val Loss: 48.7165, Recon: 0.7277, KL: 48.0053, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7280, Val Loss: 48.7191, Recon: 0.7230, KL: 48.0051, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7317, Val Loss: 48.7476, Recon: 0.7286, KL: 48.0031, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7184, Val Loss: 48.7151, Recon: 0.7139, KL: 48.0045, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7222, Val Loss: 48.7089, Recon: 0.7158, KL: 48.0064, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7225, Val Loss: 48.7027, Recon: 0.7187, KL: 48.0039, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7164, Val Loss: 48.7259, Recon: 0.7131, KL: 48.0032, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7251, Val Loss: 48.7403, Recon: 0.7188, KL: 48.0063, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7221, Val Loss: 48.7251, Recon: 0.7156, KL: 48.0065, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7148, Val Loss: 48.7124, Recon: 0.7091, KL: 48.0057, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7100, Val Loss: 48.7008, Recon: 0.7030, KL: 48.0070, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7152, Val Loss: 48.7082, Recon: 0.7100, KL: 48.0052, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7097, Val Loss: 48.6991, Recon: 0.7039, KL: 48.0058, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7156, Val Loss: 48.7080, Recon: 0.7064, KL: 48.0092, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7102, Val Loss: 48.7114, Recon: 0.7069, KL: 48.0033, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7041, Val Loss: 48.7088, Recon: 0.6997, KL: 48.0043, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7022, Val Loss: 48.6910, Recon: 0.6972, KL: 48.0050, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7177, Val Loss: 48.6918, Recon: 0.7102, KL: 48.0075, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6977, Val Loss: 48.7020, Recon: 0.6950, KL: 48.0027, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7187, Val Loss: 48.6929, Recon: 0.7029, KL: 48.0157, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7013, Val Loss: 48.7109, Recon: 0.6953, KL: 48.0060, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6964, Val Loss: 48.6965, Recon: 0.6927, KL: 48.0037, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7040, Val Loss: 48.6873, Recon: 0.6944, KL: 48.0096, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6920, Val Loss: 48.6868, Recon: 0.6890, KL: 48.0030, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6924, Val Loss: 48.6958, Recon: 0.6880, KL: 48.0044, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6863, Val Loss: 48.6822, Recon: 0.6843, KL: 48.0020, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6961, Val Loss: 48.6850, Recon: 0.6931, KL: 48.0031, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6948, Val Loss: 48.6773, Recon: 0.6888, KL: 48.0060, KL_weight: 4.8000
Saved model 30 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_29.pt
Training bootstrap model 31/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 1.0153, Val Loss: 0.7645, Recon: 1.0153, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6968, Val Loss: 4.6515, Recon: 0.8240, KL: 3.8728, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4551, Val Loss: 9.4345, Recon: 0.8007, KL: 8.6545, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2383, Val Loss: 14.1996, Recon: 0.7865, KL: 13.4519, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0237, Val Loss: 19.0002, Recon: 0.7744, KL: 18.2493, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8374, Val Loss: 23.8036, Recon: 0.7784, KL: 23.0590, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.5975, Val Loss: 28.6084, Recon: 0.7489, KL: 27.8486, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4061, Val Loss: 33.3869, Recon: 0.7590, KL: 32.6471, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2171, Val Loss: 38.1998, Recon: 0.7678, KL: 37.4493, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9996, Val Loss: 43.0407, Recon: 0.7503, KL: 42.2493, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8005, Val Loss: 47.7880, Recon: 0.7517, KL: 47.0488, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7499, Val Loss: 48.7386, Recon: 0.7456, KL: 48.0042, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7375, Val Loss: 48.7337, Recon: 0.7329, KL: 48.0047, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7389, Val Loss: 48.7360, Recon: 0.7330, KL: 48.0059, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7429, Val Loss: 48.7383, Recon: 0.7315, KL: 48.0114, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7433, Val Loss: 48.7368, Recon: 0.7386, KL: 48.0046, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7305, Val Loss: 48.7183, Recon: 0.7279, KL: 48.0026, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7494, Val Loss: 48.7459, Recon: 0.7243, KL: 48.0251, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7239, Val Loss: 48.7185, Recon: 0.7192, KL: 48.0047, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7297, Val Loss: 48.7153, Recon: 0.7270, KL: 48.0028, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7176, Val Loss: 48.7283, Recon: 0.7139, KL: 48.0036, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7258, Val Loss: 48.7104, Recon: 0.7206, KL: 48.0052, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7271, Val Loss: 48.7277, Recon: 0.7225, KL: 48.0046, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7376, Val Loss: 48.7163, Recon: 0.7358, KL: 48.0018, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7159, Val Loss: 48.7263, Recon: 0.7126, KL: 48.0033, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7251, Val Loss: 48.7321, Recon: 0.7208, KL: 48.0043, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7273, Val Loss: 48.7216, Recon: 0.7205, KL: 48.0068, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7162, Val Loss: 48.7122, Recon: 0.7108, KL: 48.0054, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7138, Val Loss: 48.7131, Recon: 0.7105, KL: 48.0034, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7223, Val Loss: 48.7001, Recon: 0.7150, KL: 48.0073, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7098, Val Loss: 48.7019, Recon: 0.7070, KL: 48.0028, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7082, Val Loss: 48.7045, Recon: 0.7062, KL: 48.0020, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7011, Val Loss: 48.6974, Recon: 0.6984, KL: 48.0028, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6936, Val Loss: 48.6857, Recon: 0.6909, KL: 48.0028, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7023, Val Loss: 48.6945, Recon: 0.6949, KL: 48.0074, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7131, Val Loss: 48.6921, Recon: 0.7067, KL: 48.0064, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6906, Val Loss: 48.6830, Recon: 0.6883, KL: 48.0023, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6896, Val Loss: 48.7080, Recon: 0.6864, KL: 48.0031, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6910, Val Loss: 48.6825, Recon: 0.6883, KL: 48.0027, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6928, Val Loss: 48.6808, Recon: 0.6903, KL: 48.0025, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6874, Val Loss: 48.6797, Recon: 0.6828, KL: 48.0046, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6867, Val Loss: 48.6833, Recon: 0.6833, KL: 48.0034, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6799, Val Loss: 48.6728, Recon: 0.6768, KL: 48.0030, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6845, Val Loss: 48.6898, Recon: 0.6806, KL: 48.0039, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6837, Val Loss: 48.6743, Recon: 0.6797, KL: 48.0040, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6888, Val Loss: 48.6827, Recon: 0.6848, KL: 48.0040, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6801, Val Loss: 48.6750, Recon: 0.6776, KL: 48.0025, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6735, Val Loss: 48.6692, Recon: 0.6715, KL: 48.0020, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6740, Val Loss: 48.6921, Recon: 0.6713, KL: 48.0027, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7695, Val Loss: 48.6968, Recon: 0.6824, KL: 48.0871, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6835, Val Loss: 48.6937, Recon: 0.6819, KL: 48.0016, KL_weight: 4.8000
Saved model 31 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_30.pt
Training bootstrap model 32/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9567, Val Loss: 0.7575, Recon: 0.9567, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6959, Val Loss: 4.6332, Recon: 0.8260, KL: 3.8699, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4451, Val Loss: 9.4107, Recon: 0.7906, KL: 8.6545, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2347, Val Loss: 14.2122, Recon: 0.7810, KL: 13.4537, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0193, Val Loss: 18.9923, Recon: 0.7660, KL: 18.2533, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8198, Val Loss: 23.7831, Recon: 0.7712, KL: 23.0487, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6067, Val Loss: 28.5808, Recon: 0.7596, KL: 27.8470, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4185, Val Loss: 33.3878, Recon: 0.7632, KL: 32.6552, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2040, Val Loss: 38.2005, Recon: 0.7513, KL: 37.4527, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9902, Val Loss: 42.9601, Recon: 0.7444, KL: 42.2458, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8034, Val Loss: 47.7887, Recon: 0.7563, KL: 47.0471, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7618, Val Loss: 48.7264, Recon: 0.7565, KL: 48.0052, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7531, Val Loss: 48.7422, Recon: 0.7442, KL: 48.0089, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7425, Val Loss: 48.7403, Recon: 0.7385, KL: 48.0040, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7478, Val Loss: 48.7385, Recon: 0.7399, KL: 48.0079, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7337, Val Loss: 48.7177, Recon: 0.7309, KL: 48.0028, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7451, Val Loss: 48.7298, Recon: 0.7405, KL: 48.0046, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7382, Val Loss: 48.7174, Recon: 0.7345, KL: 48.0037, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7361, Val Loss: 48.7361, Recon: 0.7316, KL: 48.0046, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7263, Val Loss: 48.7377, Recon: 0.7244, KL: 48.0019, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7254, Val Loss: 48.7475, Recon: 0.7219, KL: 48.0035, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7291, Val Loss: 48.7299, Recon: 0.7210, KL: 48.0082, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7488, Val Loss: 48.7118, Recon: 0.7278, KL: 48.0210, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7239, Val Loss: 48.7066, Recon: 0.7204, KL: 48.0035, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7351, Val Loss: 48.7115, Recon: 0.7287, KL: 48.0064, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7300, Val Loss: 48.7131, Recon: 0.7261, KL: 48.0039, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7253, Val Loss: 48.7113, Recon: 0.7201, KL: 48.0052, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7213, Val Loss: 48.6957, Recon: 0.7187, KL: 48.0026, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7174, Val Loss: 48.6981, Recon: 0.7142, KL: 48.0032, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7200, Val Loss: 48.7044, Recon: 0.7165, KL: 48.0035, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7104, Val Loss: 48.7279, Recon: 0.7071, KL: 48.0033, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7238, Val Loss: 48.7130, Recon: 0.7163, KL: 48.0075, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7109, Val Loss: 48.6993, Recon: 0.7063, KL: 48.0045, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7234, Val Loss: 48.7113, Recon: 0.7166, KL: 48.0068, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6963, Val Loss: 48.6836, Recon: 0.6910, KL: 48.0052, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6915, Val Loss: 48.6837, Recon: 0.6885, KL: 48.0031, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7028, Val Loss: 48.6886, Recon: 0.6967, KL: 48.0061, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6962, Val Loss: 48.6743, Recon: 0.6927, KL: 48.0035, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7082, Val Loss: 48.6820, Recon: 0.7033, KL: 48.0049, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7005, Val Loss: 48.7043, Recon: 0.6953, KL: 48.0053, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6891, Val Loss: 48.6816, Recon: 0.6853, KL: 48.0038, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6955, Val Loss: 48.6890, Recon: 0.6925, KL: 48.0030, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6954, Val Loss: 48.6882, Recon: 0.6879, KL: 48.0075, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7016, Val Loss: 48.6843, Recon: 0.6936, KL: 48.0080, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6931, Val Loss: 48.6771, Recon: 0.6881, KL: 48.0050, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6869, Val Loss: 48.6820, Recon: 0.6830, KL: 48.0040, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6814, Val Loss: 48.6682, Recon: 0.6783, KL: 48.0031, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6891, Val Loss: 48.6788, Recon: 0.6843, KL: 48.0048, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6824, Val Loss: 48.6805, Recon: 0.6798, KL: 48.0026, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6734, Val Loss: 48.6752, Recon: 0.6704, KL: 48.0030, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6843, Val Loss: 48.6716, Recon: 0.6809, KL: 48.0033, KL_weight: 4.8000
Saved model 32 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_31.pt
Training bootstrap model 33/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9259, Val Loss: 0.7105, Recon: 0.9259, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6902, Val Loss: 4.6368, Recon: 0.8245, KL: 3.8657, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4429, Val Loss: 9.4125, Recon: 0.7883, KL: 8.6546, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2296, Val Loss: 14.1893, Recon: 0.7806, KL: 13.4490, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0151, Val Loss: 18.9907, Recon: 0.7623, KL: 18.2527, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8323, Val Loss: 23.7868, Recon: 0.7735, KL: 23.0588, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6088, Val Loss: 28.5823, Recon: 0.7586, KL: 27.8502, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3956, Val Loss: 33.3802, Recon: 0.7489, KL: 32.6467, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1873, Val Loss: 38.1679, Recon: 0.7418, KL: 37.4455, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9908, Val Loss: 42.9997, Recon: 0.7415, KL: 42.2493, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7828, Val Loss: 47.7701, Recon: 0.7373, KL: 47.0454, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7534, Val Loss: 48.7467, Recon: 0.7464, KL: 48.0070, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7346, Val Loss: 48.7218, Recon: 0.7313, KL: 48.0033, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7302, Val Loss: 48.7277, Recon: 0.7257, KL: 48.0045, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7625, Val Loss: 48.7552, Recon: 0.7366, KL: 48.0259, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7369, Val Loss: 48.7232, Recon: 0.7280, KL: 48.0089, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7280, Val Loss: 48.7207, Recon: 0.7229, KL: 48.0052, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7263, Val Loss: 48.7342, Recon: 0.7189, KL: 48.0074, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7169, Val Loss: 48.7424, Recon: 0.7135, KL: 48.0034, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7236, Val Loss: 48.7381, Recon: 0.7181, KL: 48.0054, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7107, Val Loss: 48.7002, Recon: 0.7077, KL: 48.0029, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7148, Val Loss: 48.7060, Recon: 0.7115, KL: 48.0033, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7140, Val Loss: 48.7154, Recon: 0.7097, KL: 48.0043, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7098, Val Loss: 48.7109, Recon: 0.7055, KL: 48.0043, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7145, Val Loss: 48.7092, Recon: 0.7096, KL: 48.0050, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7109, Val Loss: 48.6929, Recon: 0.7038, KL: 48.0070, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7090, Val Loss: 48.6980, Recon: 0.7036, KL: 48.0054, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7008, Val Loss: 48.6834, Recon: 0.6946, KL: 48.0061, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7061, Val Loss: 48.6943, Recon: 0.7012, KL: 48.0049, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7084, Val Loss: 48.6996, Recon: 0.7020, KL: 48.0064, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7016, Val Loss: 48.6868, Recon: 0.6968, KL: 48.0048, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6945, Val Loss: 48.7193, Recon: 0.6920, KL: 48.0025, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6964, Val Loss: 48.6814, Recon: 0.6930, KL: 48.0033, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7087, Val Loss: 48.6982, Recon: 0.7001, KL: 48.0087, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6984, Val Loss: 48.6987, Recon: 0.6941, KL: 48.0043, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6981, Val Loss: 48.6911, Recon: 0.6953, KL: 48.0027, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6982, Val Loss: 48.6896, Recon: 0.6903, KL: 48.0079, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6846, Val Loss: 48.6787, Recon: 0.6817, KL: 48.0029, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7004, Val Loss: 48.6984, Recon: 0.6934, KL: 48.0070, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6804, Val Loss: 48.6832, Recon: 0.6773, KL: 48.0031, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6870, Val Loss: 48.6892, Recon: 0.6837, KL: 48.0032, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6961, Val Loss: 48.6775, Recon: 0.6881, KL: 48.0080, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6841, Val Loss: 48.6830, Recon: 0.6806, KL: 48.0035, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6996, Val Loss: 48.6806, Recon: 0.6937, KL: 48.0059, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6826, Val Loss: 48.6746, Recon: 0.6791, KL: 48.0036, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6805, Val Loss: 48.6726, Recon: 0.6756, KL: 48.0050, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6782, Val Loss: 48.6753, Recon: 0.6748, KL: 48.0033, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6827, Val Loss: 48.6700, Recon: 0.6754, KL: 48.0073, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6861, Val Loss: 48.6809, Recon: 0.6838, KL: 48.0023, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6827, Val Loss: 48.6733, Recon: 0.6785, KL: 48.0042, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6875, Val Loss: 48.6765, Recon: 0.6824, KL: 48.0051, KL_weight: 4.8000
Saved model 33 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_32.pt
Training bootstrap model 34/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9785, Val Loss: 0.7593, Recon: 0.9785, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7547, Val Loss: 4.6775, Recon: 0.8589, KL: 3.8957, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4901, Val Loss: 9.4381, Recon: 0.8289, KL: 8.6612, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2557, Val Loss: 14.2248, Recon: 0.7967, KL: 13.4590, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0384, Val Loss: 19.0163, Recon: 0.7898, KL: 18.2487, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8314, Val Loss: 23.8009, Recon: 0.7762, KL: 23.0552, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6178, Val Loss: 28.5878, Recon: 0.7712, KL: 27.8467, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4217, Val Loss: 33.3727, Recon: 0.7709, KL: 32.6508, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2113, Val Loss: 38.1774, Recon: 0.7659, KL: 37.4454, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0041, Val Loss: 42.9821, Recon: 0.7597, KL: 42.2444, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8083, Val Loss: 47.7826, Recon: 0.7567, KL: 47.0515, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7602, Val Loss: 48.7213, Recon: 0.7547, KL: 48.0055, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7557, Val Loss: 48.7396, Recon: 0.7510, KL: 48.0048, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7674, Val Loss: 48.7491, Recon: 0.7529, KL: 48.0145, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7422, Val Loss: 48.7260, Recon: 0.7376, KL: 48.0046, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7567, Val Loss: 48.7376, Recon: 0.7432, KL: 48.0136, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7352, Val Loss: 48.7334, Recon: 0.7317, KL: 48.0035, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7521, Val Loss: 48.7262, Recon: 0.7483, KL: 48.0038, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7423, Val Loss: 48.7299, Recon: 0.7358, KL: 48.0065, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7350, Val Loss: 48.7188, Recon: 0.7284, KL: 48.0066, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7264, Val Loss: 48.7113, Recon: 0.7198, KL: 48.0067, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7252, Val Loss: 48.7136, Recon: 0.7213, KL: 48.0040, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7247, Val Loss: 48.7175, Recon: 0.7202, KL: 48.0045, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7277, Val Loss: 48.7265, Recon: 0.7235, KL: 48.0041, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7213, Val Loss: 48.7166, Recon: 0.7178, KL: 48.0035, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7226, Val Loss: 48.7260, Recon: 0.7191, KL: 48.0035, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7285, Val Loss: 48.7213, Recon: 0.7247, KL: 48.0038, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7270, Val Loss: 48.7101, Recon: 0.7223, KL: 48.0046, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7190, Val Loss: 48.7166, Recon: 0.7158, KL: 48.0031, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7218, Val Loss: 48.7129, Recon: 0.7113, KL: 48.0105, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7216, Val Loss: 48.7093, Recon: 0.7148, KL: 48.0068, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7149, Val Loss: 48.7109, Recon: 0.7112, KL: 48.0037, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7121, Val Loss: 48.7055, Recon: 0.7074, KL: 48.0047, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7173, Val Loss: 48.7060, Recon: 0.7162, KL: 48.0011, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7169, Val Loss: 48.7017, Recon: 0.7146, KL: 48.0023, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7110, Val Loss: 48.7051, Recon: 0.7092, KL: 48.0019, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7208, Val Loss: 48.7261, Recon: 0.7026, KL: 48.0182, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7042, Val Loss: 48.7096, Recon: 0.7024, KL: 48.0018, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7029, Val Loss: 48.7171, Recon: 0.7004, KL: 48.0025, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7294, Val Loss: 48.7259, Recon: 0.7144, KL: 48.0150, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7056, Val Loss: 48.7099, Recon: 0.7014, KL: 48.0042, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6975, Val Loss: 48.6989, Recon: 0.6959, KL: 48.0016, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7025, Val Loss: 48.7015, Recon: 0.6984, KL: 48.0041, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7023, Val Loss: 48.6943, Recon: 0.6998, KL: 48.0025, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7048, Val Loss: 48.6967, Recon: 0.7033, KL: 48.0015, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7026, Val Loss: 48.7133, Recon: 0.6950, KL: 48.0075, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6969, Val Loss: 48.7038, Recon: 0.6940, KL: 48.0029, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6991, Val Loss: 48.6923, Recon: 0.6921, KL: 48.0070, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6957, Val Loss: 48.6841, Recon: 0.6894, KL: 48.0063, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7029, Val Loss: 48.7012, Recon: 0.6981, KL: 48.0048, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6902, Val Loss: 48.6847, Recon: 0.6870, KL: 48.0032, KL_weight: 4.8000
Saved model 34 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_33.pt
Training bootstrap model 35/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9992, Val Loss: 0.7464, Recon: 0.9992, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6986, Val Loss: 4.6401, Recon: 0.8290, KL: 3.8696, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4703, Val Loss: 9.4209, Recon: 0.8067, KL: 8.6636, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2544, Val Loss: 14.1924, Recon: 0.8006, KL: 13.4539, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0355, Val Loss: 18.9949, Recon: 0.7804, KL: 18.2550, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8302, Val Loss: 23.8037, Recon: 0.7722, KL: 23.0581, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6391, Val Loss: 28.5829, Recon: 0.7807, KL: 27.8584, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4172, Val Loss: 33.3837, Recon: 0.7635, KL: 32.6537, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2103, Val Loss: 38.1759, Recon: 0.7626, KL: 37.4477, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9957, Val Loss: 42.9819, Recon: 0.7515, KL: 42.2442, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7993, Val Loss: 47.7655, Recon: 0.7551, KL: 47.0442, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7749, Val Loss: 48.7331, Recon: 0.7699, KL: 48.0050, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7664, Val Loss: 48.7259, Recon: 0.7568, KL: 48.0097, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7497, Val Loss: 48.7257, Recon: 0.7454, KL: 48.0043, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7470, Val Loss: 48.7278, Recon: 0.7425, KL: 48.0045, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7653, Val Loss: 48.7431, Recon: 0.7576, KL: 48.0077, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7483, Val Loss: 48.7198, Recon: 0.7405, KL: 48.0078, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7463, Val Loss: 48.7398, Recon: 0.7355, KL: 48.0108, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7319, Val Loss: 48.7023, Recon: 0.7291, KL: 48.0027, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7311, Val Loss: 48.7035, Recon: 0.7274, KL: 48.0038, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7320, Val Loss: 48.7270, Recon: 0.7259, KL: 48.0061, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7234, Val Loss: 48.7002, Recon: 0.7211, KL: 48.0024, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7184, Val Loss: 48.7056, Recon: 0.7153, KL: 48.0031, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7311, Val Loss: 48.7197, Recon: 0.7269, KL: 48.0042, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7240, Val Loss: 48.6942, Recon: 0.7192, KL: 48.0048, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7250, Val Loss: 48.7043, Recon: 0.7220, KL: 48.0029, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7125, Val Loss: 48.7048, Recon: 0.7077, KL: 48.0048, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7160, Val Loss: 48.6950, Recon: 0.7106, KL: 48.0054, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7080, Val Loss: 48.6977, Recon: 0.7040, KL: 48.0040, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7171, Val Loss: 48.6937, Recon: 0.7103, KL: 48.0069, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7061, Val Loss: 48.6847, Recon: 0.7026, KL: 48.0035, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7016, Val Loss: 48.6846, Recon: 0.6980, KL: 48.0037, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7012, Val Loss: 48.6831, Recon: 0.6975, KL: 48.0036, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7193, Val Loss: 48.6972, Recon: 0.7133, KL: 48.0059, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7132, Val Loss: 48.6883, Recon: 0.7039, KL: 48.0094, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7110, Val Loss: 48.6872, Recon: 0.7043, KL: 48.0068, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6976, Val Loss: 48.7021, Recon: 0.6939, KL: 48.0037, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7053, Val Loss: 48.6927, Recon: 0.7030, KL: 48.0023, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6995, Val Loss: 48.6897, Recon: 0.6964, KL: 48.0031, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7167, Val Loss: 48.6936, Recon: 0.7132, KL: 48.0036, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6930, Val Loss: 48.6778, Recon: 0.6912, KL: 48.0018, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7011, Val Loss: 48.6904, Recon: 0.6962, KL: 48.0049, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7065, Val Loss: 48.7027, Recon: 0.6971, KL: 48.0093, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7009, Val Loss: 48.6835, Recon: 0.6959, KL: 48.0050, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6945, Val Loss: 48.6744, Recon: 0.6905, KL: 48.0040, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7109, Val Loss: 48.6962, Recon: 0.7032, KL: 48.0077, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6921, Val Loss: 48.6735, Recon: 0.6884, KL: 48.0038, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6889, Val Loss: 48.6681, Recon: 0.6863, KL: 48.0026, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6900, Val Loss: 48.6723, Recon: 0.6866, KL: 48.0034, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6905, Val Loss: 48.6750, Recon: 0.6864, KL: 48.0041, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6944, Val Loss: 48.6852, Recon: 0.6884, KL: 48.0060, KL_weight: 4.8000
Saved model 35 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_34.pt
Training bootstrap model 36/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9353, Val Loss: 0.7152, Recon: 0.9353, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6944, Val Loss: 4.6460, Recon: 0.8247, KL: 3.8697, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4674, Val Loss: 9.4121, Recon: 0.8022, KL: 8.6652, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2507, Val Loss: 14.1924, Recon: 0.7975, KL: 13.4532, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0362, Val Loss: 19.0221, Recon: 0.7855, KL: 18.2507, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8149, Val Loss: 23.7985, Recon: 0.7686, KL: 23.0463, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6373, Val Loss: 28.5966, Recon: 0.7813, KL: 27.8561, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4053, Val Loss: 33.3906, Recon: 0.7583, KL: 32.6470, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2068, Val Loss: 38.1950, Recon: 0.7615, KL: 37.4454, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0061, Val Loss: 42.9825, Recon: 0.7527, KL: 42.2534, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7920, Val Loss: 47.7765, Recon: 0.7486, KL: 47.0434, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7515, Val Loss: 48.7385, Recon: 0.7462, KL: 48.0052, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7416, Val Loss: 48.7373, Recon: 0.7395, KL: 48.0021, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7466, Val Loss: 48.7213, Recon: 0.7414, KL: 48.0052, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7477, Val Loss: 48.7395, Recon: 0.7414, KL: 48.0062, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7587, Val Loss: 48.7417, Recon: 0.7434, KL: 48.0153, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7698, Val Loss: 48.7315, Recon: 0.7454, KL: 48.0244, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7383, Val Loss: 48.7212, Recon: 0.7337, KL: 48.0046, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7393, Val Loss: 48.7255, Recon: 0.7343, KL: 48.0050, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7516, Val Loss: 48.7345, Recon: 0.7342, KL: 48.0173, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7386, Val Loss: 48.7109, Recon: 0.7268, KL: 48.0118, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7233, Val Loss: 48.7144, Recon: 0.7193, KL: 48.0040, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7213, Val Loss: 48.7108, Recon: 0.7195, KL: 48.0019, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7129, Val Loss: 48.6973, Recon: 0.7096, KL: 48.0033, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7088, Val Loss: 48.6974, Recon: 0.7056, KL: 48.0032, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7126, Val Loss: 48.7010, Recon: 0.7074, KL: 48.0051, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7152, Val Loss: 48.6972, Recon: 0.7132, KL: 48.0020, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7132, Val Loss: 48.7048, Recon: 0.7093, KL: 48.0040, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7048, Val Loss: 48.6922, Recon: 0.6938, KL: 48.0110, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7027, Val Loss: 48.7075, Recon: 0.6997, KL: 48.0031, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7131, Val Loss: 48.6894, Recon: 0.7073, KL: 48.0058, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6990, Val Loss: 48.6895, Recon: 0.6960, KL: 48.0030, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6995, Val Loss: 48.6892, Recon: 0.6942, KL: 48.0053, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7020, Val Loss: 48.6943, Recon: 0.6977, KL: 48.0043, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6935, Val Loss: 48.6849, Recon: 0.6910, KL: 48.0026, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6976, Val Loss: 48.6810, Recon: 0.6935, KL: 48.0042, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6958, Val Loss: 48.7226, Recon: 0.6907, KL: 48.0051, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6923, Val Loss: 48.6848, Recon: 0.6893, KL: 48.0030, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6887, Val Loss: 48.6732, Recon: 0.6863, KL: 48.0024, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6918, Val Loss: 48.6804, Recon: 0.6880, KL: 48.0037, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7009, Val Loss: 48.6900, Recon: 0.6976, KL: 48.0033, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6943, Val Loss: 48.6942, Recon: 0.6890, KL: 48.0052, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6907, Val Loss: 48.6832, Recon: 0.6838, KL: 48.0069, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6963, Val Loss: 48.6858, Recon: 0.6924, KL: 48.0038, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6878, Val Loss: 48.6736, Recon: 0.6840, KL: 48.0038, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6849, Val Loss: 48.6784, Recon: 0.6819, KL: 48.0030, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6853, Val Loss: 48.6755, Recon: 0.6833, KL: 48.0020, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6762, Val Loss: 48.6757, Recon: 0.6746, KL: 48.0016, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6780, Val Loss: 48.6706, Recon: 0.6753, KL: 48.0027, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6807, Val Loss: 48.6752, Recon: 0.6773, KL: 48.0034, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6844, Val Loss: 48.6689, Recon: 0.6825, KL: 48.0019, KL_weight: 4.8000
Saved model 36 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_35.pt
Training bootstrap model 37/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9856, Val Loss: 0.7433, Recon: 0.9856, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7030, Val Loss: 4.6384, Recon: 0.8308, KL: 3.8722, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4604, Val Loss: 9.4103, Recon: 0.8041, KL: 8.6563, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2513, Val Loss: 14.2321, Recon: 0.7937, KL: 13.4576, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0193, Val Loss: 19.0060, Recon: 0.7702, KL: 18.2491, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8450, Val Loss: 23.8045, Recon: 0.7810, KL: 23.0640, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6185, Val Loss: 28.5802, Recon: 0.7676, KL: 27.8509, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4165, Val Loss: 33.3894, Recon: 0.7684, KL: 32.6481, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2088, Val Loss: 38.1775, Recon: 0.7614, KL: 37.4474, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0043, Val Loss: 42.9708, Recon: 0.7572, KL: 42.2471, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7884, Val Loss: 47.7468, Recon: 0.7440, KL: 47.0444, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7558, Val Loss: 48.7266, Recon: 0.7515, KL: 48.0043, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7453, Val Loss: 48.7326, Recon: 0.7412, KL: 48.0042, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7490, Val Loss: 48.7219, Recon: 0.7430, KL: 48.0060, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.8069, Val Loss: 48.7513, Recon: 0.7806, KL: 48.0263, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7499, Val Loss: 48.7142, Recon: 0.7465, KL: 48.0034, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7390, Val Loss: 48.7037, Recon: 0.7361, KL: 48.0030, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7492, Val Loss: 48.7203, Recon: 0.7422, KL: 48.0070, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7387, Val Loss: 48.7268, Recon: 0.7364, KL: 48.0023, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7371, Val Loss: 48.7004, Recon: 0.7307, KL: 48.0064, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7284, Val Loss: 48.7078, Recon: 0.7258, KL: 48.0026, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7340, Val Loss: 48.7126, Recon: 0.7307, KL: 48.0032, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7433, Val Loss: 48.7068, Recon: 0.7400, KL: 48.0033, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7255, Val Loss: 48.7033, Recon: 0.7220, KL: 48.0036, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7355, Val Loss: 48.7035, Recon: 0.7298, KL: 48.0057, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7259, Val Loss: 48.7051, Recon: 0.7224, KL: 48.0035, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7207, Val Loss: 48.6943, Recon: 0.7184, KL: 48.0023, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7107, Val Loss: 48.6994, Recon: 0.7065, KL: 48.0041, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7138, Val Loss: 48.6922, Recon: 0.7110, KL: 48.0028, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7306, Val Loss: 48.7009, Recon: 0.7277, KL: 48.0029, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7145, Val Loss: 48.7032, Recon: 0.7104, KL: 48.0041, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7177, Val Loss: 48.7118, Recon: 0.7068, KL: 48.0109, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7187, Val Loss: 48.7082, Recon: 0.7079, KL: 48.0108, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7045, Val Loss: 48.6817, Recon: 0.6999, KL: 48.0046, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6992, Val Loss: 48.7070, Recon: 0.6968, KL: 48.0024, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7002, Val Loss: 48.6832, Recon: 0.6978, KL: 48.0024, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6953, Val Loss: 48.6785, Recon: 0.6925, KL: 48.0028, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6977, Val Loss: 48.7137, Recon: 0.6938, KL: 48.0040, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6988, Val Loss: 48.6879, Recon: 0.6936, KL: 48.0052, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7155, Val Loss: 48.6878, Recon: 0.7107, KL: 48.0049, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6937, Val Loss: 48.6747, Recon: 0.6907, KL: 48.0030, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6965, Val Loss: 48.6829, Recon: 0.6918, KL: 48.0047, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6954, Val Loss: 48.6742, Recon: 0.6888, KL: 48.0066, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7037, Val Loss: 48.6773, Recon: 0.6999, KL: 48.0038, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6961, Val Loss: 48.6736, Recon: 0.6916, KL: 48.0045, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6998, Val Loss: 48.6788, Recon: 0.6962, KL: 48.0036, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6961, Val Loss: 48.6888, Recon: 0.6906, KL: 48.0055, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6872, Val Loss: 48.6718, Recon: 0.6838, KL: 48.0034, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6871, Val Loss: 48.6706, Recon: 0.6853, KL: 48.0018, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7098, Val Loss: 48.6845, Recon: 0.7031, KL: 48.0067, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6921, Val Loss: 48.6750, Recon: 0.6836, KL: 48.0085, KL_weight: 4.8000
Saved model 37 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_36.pt
Training bootstrap model 38/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9583, Val Loss: 0.7519, Recon: 0.9583, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6864, Val Loss: 4.6496, Recon: 0.8216, KL: 3.8649, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4512, Val Loss: 9.4313, Recon: 0.7955, KL: 8.6556, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2410, Val Loss: 14.2084, Recon: 0.7838, KL: 13.4572, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0219, Val Loss: 18.9884, Recon: 0.7695, KL: 18.2524, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8046, Val Loss: 23.7794, Recon: 0.7551, KL: 23.0495, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6153, Val Loss: 28.5905, Recon: 0.7660, KL: 27.8493, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3998, Val Loss: 33.3753, Recon: 0.7496, KL: 32.6502, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2091, Val Loss: 38.1912, Recon: 0.7560, KL: 37.4531, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9982, Val Loss: 42.9849, Recon: 0.7489, KL: 42.2493, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7854, Val Loss: 47.7572, Recon: 0.7413, KL: 47.0441, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7509, Val Loss: 48.7243, Recon: 0.7468, KL: 48.0041, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7497, Val Loss: 48.7414, Recon: 0.7434, KL: 48.0063, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7368, Val Loss: 48.7561, Recon: 0.7316, KL: 48.0052, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7303, Val Loss: 48.7151, Recon: 0.7268, KL: 48.0035, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7330, Val Loss: 48.7408, Recon: 0.7256, KL: 48.0074, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7237, Val Loss: 48.7280, Recon: 0.7206, KL: 48.0031, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7260, Val Loss: 48.7143, Recon: 0.7203, KL: 48.0057, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7239, Val Loss: 48.7044, Recon: 0.7191, KL: 48.0049, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7162, Val Loss: 48.7177, Recon: 0.7123, KL: 48.0039, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7148, Val Loss: 48.7251, Recon: 0.7106, KL: 48.0042, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7110, Val Loss: 48.7141, Recon: 0.7086, KL: 48.0023, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7133, Val Loss: 48.7118, Recon: 0.7090, KL: 48.0042, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7146, Val Loss: 48.6919, Recon: 0.7083, KL: 48.0063, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7083, Val Loss: 48.7067, Recon: 0.7039, KL: 48.0045, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7119, Val Loss: 48.7091, Recon: 0.6964, KL: 48.0155, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.6983, Val Loss: 48.6906, Recon: 0.6949, KL: 48.0034, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7065, Val Loss: 48.7019, Recon: 0.7013, KL: 48.0052, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7039, Val Loss: 48.6849, Recon: 0.6992, KL: 48.0047, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.6926, Val Loss: 48.7121, Recon: 0.6870, KL: 48.0056, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.6961, Val Loss: 48.6931, Recon: 0.6912, KL: 48.0049, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7119, Val Loss: 48.6935, Recon: 0.6977, KL: 48.0142, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6910, Val Loss: 48.6921, Recon: 0.6875, KL: 48.0035, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6897, Val Loss: 48.6850, Recon: 0.6859, KL: 48.0037, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6889, Val Loss: 48.6851, Recon: 0.6846, KL: 48.0043, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6957, Val Loss: 48.7126, Recon: 0.6830, KL: 48.0126, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6913, Val Loss: 48.6803, Recon: 0.6894, KL: 48.0019, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6869, Val Loss: 48.6810, Recon: 0.6819, KL: 48.0050, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6846, Val Loss: 48.6934, Recon: 0.6786, KL: 48.0060, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6935, Val Loss: 48.6862, Recon: 0.6873, KL: 48.0062, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6837, Val Loss: 48.6939, Recon: 0.6805, KL: 48.0032, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6805, Val Loss: 48.6894, Recon: 0.6771, KL: 48.0034, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6866, Val Loss: 48.6740, Recon: 0.6829, KL: 48.0038, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6894, Val Loss: 48.6791, Recon: 0.6857, KL: 48.0037, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6838, Val Loss: 48.6806, Recon: 0.6797, KL: 48.0042, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6768, Val Loss: 48.6761, Recon: 0.6742, KL: 48.0026, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6746, Val Loss: 48.6758, Recon: 0.6728, KL: 48.0018, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7268, Val Loss: 48.7035, Recon: 0.6929, KL: 48.0339, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6984, Val Loss: 48.6835, Recon: 0.6907, KL: 48.0078, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6896, Val Loss: 48.6744, Recon: 0.6834, KL: 48.0062, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6811, Val Loss: 48.6807, Recon: 0.6760, KL: 48.0051, KL_weight: 4.8000
Saved model 38 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_37.pt
Training bootstrap model 39/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9622, Val Loss: 0.7117, Recon: 0.9622, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7142, Val Loss: 4.6281, Recon: 0.8424, KL: 3.8718, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4734, Val Loss: 9.4220, Recon: 0.8088, KL: 8.6646, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2463, Val Loss: 14.2075, Recon: 0.7932, KL: 13.4531, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0299, Val Loss: 18.9930, Recon: 0.7791, KL: 18.2509, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8352, Val Loss: 23.7766, Recon: 0.7845, KL: 23.0507, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6126, Val Loss: 28.5796, Recon: 0.7628, KL: 27.8498, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4124, Val Loss: 33.3895, Recon: 0.7634, KL: 32.6489, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2032, Val Loss: 38.1822, Recon: 0.7561, KL: 37.4471, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0127, Val Loss: 42.9678, Recon: 0.7681, KL: 42.2446, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8102, Val Loss: 47.7728, Recon: 0.7606, KL: 47.0496, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7526, Val Loss: 48.7260, Recon: 0.7504, KL: 48.0022, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7782, Val Loss: 48.7227, Recon: 0.7531, KL: 48.0250, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7637, Val Loss: 48.7285, Recon: 0.7518, KL: 48.0119, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7605, Val Loss: 48.7216, Recon: 0.7556, KL: 48.0049, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7500, Val Loss: 48.7343, Recon: 0.7437, KL: 48.0063, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7700, Val Loss: 48.7501, Recon: 0.7619, KL: 48.0081, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7450, Val Loss: 48.7241, Recon: 0.7395, KL: 48.0054, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7389, Val Loss: 48.7213, Recon: 0.7334, KL: 48.0054, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7336, Val Loss: 48.7110, Recon: 0.7307, KL: 48.0030, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7299, Val Loss: 48.7159, Recon: 0.7263, KL: 48.0036, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7345, Val Loss: 48.7100, Recon: 0.7294, KL: 48.0051, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7296, Val Loss: 48.7089, Recon: 0.7240, KL: 48.0056, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7185, Val Loss: 48.7084, Recon: 0.7164, KL: 48.0021, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7207, Val Loss: 48.7053, Recon: 0.7177, KL: 48.0031, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7240, Val Loss: 48.7046, Recon: 0.7184, KL: 48.0056, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7351, Val Loss: 48.7164, Recon: 0.7239, KL: 48.0112, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7105, Val Loss: 48.7012, Recon: 0.7083, KL: 48.0022, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7320, Val Loss: 48.7126, Recon: 0.7237, KL: 48.0083, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7154, Val Loss: 48.6998, Recon: 0.7065, KL: 48.0089, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7106, Val Loss: 48.6943, Recon: 0.7074, KL: 48.0032, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7062, Val Loss: 48.6865, Recon: 0.7026, KL: 48.0035, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7117, Val Loss: 48.6979, Recon: 0.7073, KL: 48.0045, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6990, Val Loss: 48.6924, Recon: 0.6952, KL: 48.0038, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7063, Val Loss: 48.7076, Recon: 0.7019, KL: 48.0044, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7008, Val Loss: 48.6921, Recon: 0.6982, KL: 48.0026, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7100, Val Loss: 48.6877, Recon: 0.7069, KL: 48.0031, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6979, Val Loss: 48.6867, Recon: 0.6932, KL: 48.0046, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7007, Val Loss: 48.6899, Recon: 0.6958, KL: 48.0049, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6960, Val Loss: 48.6911, Recon: 0.6928, KL: 48.0031, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7000, Val Loss: 48.6781, Recon: 0.6974, KL: 48.0026, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7007, Val Loss: 48.6875, Recon: 0.6970, KL: 48.0037, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7068, Val Loss: 48.6741, Recon: 0.6993, KL: 48.0076, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6943, Val Loss: 48.6834, Recon: 0.6920, KL: 48.0023, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6919, Val Loss: 48.6758, Recon: 0.6899, KL: 48.0020, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6935, Val Loss: 48.6858, Recon: 0.6871, KL: 48.0064, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6991, Val Loss: 48.6905, Recon: 0.6922, KL: 48.0068, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6943, Val Loss: 48.6902, Recon: 0.6895, KL: 48.0048, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6888, Val Loss: 48.6832, Recon: 0.6855, KL: 48.0032, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6838, Val Loss: 48.6766, Recon: 0.6810, KL: 48.0028, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6842, Val Loss: 48.6769, Recon: 0.6807, KL: 48.0035, KL_weight: 4.8000
Saved model 39 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_38.pt
Training bootstrap model 40/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9784, Val Loss: 0.7607, Recon: 0.9784, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6954, Val Loss: 4.6408, Recon: 0.8260, KL: 3.8693, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4613, Val Loss: 9.4166, Recon: 0.8029, KL: 8.6585, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2487, Val Loss: 14.2183, Recon: 0.7922, KL: 13.4565, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0425, Val Loss: 19.0185, Recon: 0.7837, KL: 18.2588, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8122, Val Loss: 23.7904, Recon: 0.7628, KL: 23.0494, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6080, Val Loss: 28.6083, Recon: 0.7601, KL: 27.8479, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4198, Val Loss: 33.3798, Recon: 0.7637, KL: 32.6561, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2135, Val Loss: 38.1847, Recon: 0.7646, KL: 37.4488, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9910, Val Loss: 42.9673, Recon: 0.7485, KL: 42.2425, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7954, Val Loss: 47.7700, Recon: 0.7494, KL: 47.0461, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7502, Val Loss: 48.7295, Recon: 0.7435, KL: 48.0067, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7586, Val Loss: 48.7269, Recon: 0.7512, KL: 48.0074, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7664, Val Loss: 48.7349, Recon: 0.7602, KL: 48.0062, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7482, Val Loss: 48.7257, Recon: 0.7409, KL: 48.0074, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7348, Val Loss: 48.7106, Recon: 0.7258, KL: 48.0090, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7347, Val Loss: 48.7176, Recon: 0.7294, KL: 48.0053, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7394, Val Loss: 48.7184, Recon: 0.7308, KL: 48.0085, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7231, Val Loss: 48.7025, Recon: 0.7198, KL: 48.0033, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7131, Val Loss: 48.6983, Recon: 0.7090, KL: 48.0040, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7132, Val Loss: 48.7059, Recon: 0.7089, KL: 48.0044, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7235, Val Loss: 48.7126, Recon: 0.7194, KL: 48.0041, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7150, Val Loss: 48.6991, Recon: 0.7110, KL: 48.0040, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.6992, Val Loss: 48.6937, Recon: 0.6962, KL: 48.0030, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7115, Val Loss: 48.7070, Recon: 0.7047, KL: 48.0068, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7131, Val Loss: 48.7155, Recon: 0.7085, KL: 48.0047, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7252, Val Loss: 48.7024, Recon: 0.7200, KL: 48.0052, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7004, Val Loss: 48.6901, Recon: 0.6980, KL: 48.0024, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7095, Val Loss: 48.6916, Recon: 0.7027, KL: 48.0068, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7011, Val Loss: 48.6859, Recon: 0.6979, KL: 48.0032, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7094, Val Loss: 48.6941, Recon: 0.7034, KL: 48.0060, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7045, Val Loss: 48.6906, Recon: 0.6979, KL: 48.0066, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7148, Val Loss: 48.7021, Recon: 0.7087, KL: 48.0061, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6935, Val Loss: 48.6858, Recon: 0.6895, KL: 48.0040, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6973, Val Loss: 48.6941, Recon: 0.6903, KL: 48.0070, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6952, Val Loss: 48.6887, Recon: 0.6913, KL: 48.0039, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6947, Val Loss: 48.6811, Recon: 0.6908, KL: 48.0039, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6938, Val Loss: 48.6799, Recon: 0.6868, KL: 48.0070, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7000, Val Loss: 48.6837, Recon: 0.6956, KL: 48.0045, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7015, Val Loss: 48.7115, Recon: 0.6983, KL: 48.0033, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6991, Val Loss: 48.6831, Recon: 0.6937, KL: 48.0054, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6997, Val Loss: 48.6823, Recon: 0.6916, KL: 48.0081, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6889, Val Loss: 48.6855, Recon: 0.6861, KL: 48.0028, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6916, Val Loss: 48.6929, Recon: 0.6881, KL: 48.0035, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6933, Val Loss: 48.6853, Recon: 0.6889, KL: 48.0044, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6830, Val Loss: 48.6837, Recon: 0.6806, KL: 48.0024, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6990, Val Loss: 48.7039, Recon: 0.6912, KL: 48.0078, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6869, Val Loss: 48.6780, Recon: 0.6845, KL: 48.0024, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6827, Val Loss: 48.6744, Recon: 0.6798, KL: 48.0029, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6862, Val Loss: 48.6735, Recon: 0.6825, KL: 48.0037, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6817, Val Loss: 48.6747, Recon: 0.6788, KL: 48.0029, KL_weight: 4.8000
Saved model 40 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_39.pt
Training bootstrap model 41/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 1.0249, Val Loss: 0.8548, Recon: 1.0249, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7195, Val Loss: 4.6379, Recon: 0.8455, KL: 3.8740, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4620, Val Loss: 9.4334, Recon: 0.8047, KL: 8.6573, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2473, Val Loss: 14.2159, Recon: 0.7950, KL: 13.4523, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0375, Val Loss: 19.0269, Recon: 0.7869, KL: 18.2506, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8376, Val Loss: 23.8057, Recon: 0.7869, KL: 23.0507, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6287, Val Loss: 28.5965, Recon: 0.7789, KL: 27.8497, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4204, Val Loss: 33.3921, Recon: 0.7750, KL: 32.6454, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2165, Val Loss: 38.1694, Recon: 0.7702, KL: 37.4464, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0299, Val Loss: 42.9909, Recon: 0.7807, KL: 42.2492, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8104, Val Loss: 47.7758, Recon: 0.7632, KL: 47.0472, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7739, Val Loss: 48.7722, Recon: 0.7640, KL: 48.0099, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7754, Val Loss: 48.7552, Recon: 0.7660, KL: 48.0094, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7641, Val Loss: 48.7348, Recon: 0.7567, KL: 48.0073, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7592, Val Loss: 48.7279, Recon: 0.7548, KL: 48.0044, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7663, Val Loss: 48.7529, Recon: 0.7559, KL: 48.0104, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7538, Val Loss: 48.7264, Recon: 0.7469, KL: 48.0069, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.8182, Val Loss: 48.7527, Recon: 0.7521, KL: 48.0661, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7628, Val Loss: 48.7289, Recon: 0.7527, KL: 48.0101, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7479, Val Loss: 48.7244, Recon: 0.7425, KL: 48.0053, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7508, Val Loss: 48.7111, Recon: 0.7456, KL: 48.0052, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7462, Val Loss: 48.7333, Recon: 0.7428, KL: 48.0034, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7378, Val Loss: 48.7117, Recon: 0.7335, KL: 48.0043, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7357, Val Loss: 48.7165, Recon: 0.7273, KL: 48.0084, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7443, Val Loss: 48.7108, Recon: 0.7365, KL: 48.0078, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7419, Val Loss: 48.7163, Recon: 0.7385, KL: 48.0034, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7314, Val Loss: 48.7040, Recon: 0.7261, KL: 48.0054, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7330, Val Loss: 48.7156, Recon: 0.7268, KL: 48.0062, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7224, Val Loss: 48.7103, Recon: 0.7186, KL: 48.0039, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7204, Val Loss: 48.7078, Recon: 0.7153, KL: 48.0051, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7201, Val Loss: 48.7104, Recon: 0.7159, KL: 48.0043, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7266, Val Loss: 48.7116, Recon: 0.7203, KL: 48.0062, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7255, Val Loss: 48.6978, Recon: 0.7165, KL: 48.0090, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7173, Val Loss: 48.6863, Recon: 0.7127, KL: 48.0046, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7078, Val Loss: 48.6872, Recon: 0.7055, KL: 48.0023, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7120, Val Loss: 48.6846, Recon: 0.7080, KL: 48.0040, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7105, Val Loss: 48.7017, Recon: 0.7054, KL: 48.0051, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7190, Val Loss: 48.6912, Recon: 0.7138, KL: 48.0052, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7082, Val Loss: 48.6843, Recon: 0.7027, KL: 48.0055, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7092, Val Loss: 48.6918, Recon: 0.7042, KL: 48.0050, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7216, Val Loss: 48.6923, Recon: 0.7126, KL: 48.0090, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7120, Val Loss: 48.6833, Recon: 0.7068, KL: 48.0052, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7041, Val Loss: 48.6856, Recon: 0.6994, KL: 48.0046, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6975, Val Loss: 48.6751, Recon: 0.6944, KL: 48.0031, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6952, Val Loss: 48.6814, Recon: 0.6921, KL: 48.0031, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6980, Val Loss: 48.6826, Recon: 0.6940, KL: 48.0039, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6979, Val Loss: 48.6811, Recon: 0.6965, KL: 48.0014, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6859, Val Loss: 48.6759, Recon: 0.6837, KL: 48.0023, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7003, Val Loss: 48.6863, Recon: 0.6939, KL: 48.0065, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6987, Val Loss: 48.6815, Recon: 0.6896, KL: 48.0091, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6889, Val Loss: 48.6679, Recon: 0.6848, KL: 48.0041, KL_weight: 4.8000
Saved model 41 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_40.pt
Training bootstrap model 42/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9237, Val Loss: 0.7099, Recon: 0.9237, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6801, Val Loss: 4.6497, Recon: 0.8105, KL: 3.8696, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4405, Val Loss: 9.4205, Recon: 0.7856, KL: 8.6549, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2453, Val Loss: 14.2184, Recon: 0.7827, KL: 13.4626, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0265, Val Loss: 18.9965, Recon: 0.7753, KL: 18.2512, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8062, Val Loss: 23.8022, Recon: 0.7580, KL: 23.0482, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6481, Val Loss: 28.6003, Recon: 0.7691, KL: 27.8790, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4161, Val Loss: 33.4006, Recon: 0.7575, KL: 32.6586, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1951, Val Loss: 38.1776, Recon: 0.7478, KL: 37.4473, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0084, Val Loss: 42.9910, Recon: 0.7594, KL: 42.2490, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8063, Val Loss: 47.7744, Recon: 0.7560, KL: 47.0503, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7498, Val Loss: 48.7352, Recon: 0.7433, KL: 48.0065, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7550, Val Loss: 48.7218, Recon: 0.7430, KL: 48.0120, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7465, Val Loss: 48.7598, Recon: 0.7366, KL: 48.0099, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7484, Val Loss: 48.7426, Recon: 0.7374, KL: 48.0110, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7589, Val Loss: 48.7370, Recon: 0.7543, KL: 48.0046, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7347, Val Loss: 48.7297, Recon: 0.7267, KL: 48.0079, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7456, Val Loss: 48.7279, Recon: 0.7390, KL: 48.0066, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7306, Val Loss: 48.7324, Recon: 0.7236, KL: 48.0070, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7319, Val Loss: 48.7123, Recon: 0.7251, KL: 48.0068, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7233, Val Loss: 48.7097, Recon: 0.7174, KL: 48.0059, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7200, Val Loss: 48.7418, Recon: 0.7161, KL: 48.0039, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7147, Val Loss: 48.7051, Recon: 0.7121, KL: 48.0026, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7136, Val Loss: 48.7236, Recon: 0.7109, KL: 48.0026, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7108, Val Loss: 48.7240, Recon: 0.7081, KL: 48.0027, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7336, Val Loss: 48.7264, Recon: 0.7278, KL: 48.0058, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7236, Val Loss: 48.7274, Recon: 0.7146, KL: 48.0090, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7090, Val Loss: 48.7026, Recon: 0.7056, KL: 48.0034, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7231, Val Loss: 48.7017, Recon: 0.7178, KL: 48.0053, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7083, Val Loss: 48.6955, Recon: 0.7037, KL: 48.0047, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7038, Val Loss: 48.6938, Recon: 0.6983, KL: 48.0055, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7003, Val Loss: 48.7068, Recon: 0.6971, KL: 48.0033, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6979, Val Loss: 48.6890, Recon: 0.6948, KL: 48.0030, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7069, Val Loss: 48.6813, Recon: 0.7016, KL: 48.0053, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7004, Val Loss: 48.6920, Recon: 0.6958, KL: 48.0046, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7008, Val Loss: 48.6914, Recon: 0.6962, KL: 48.0046, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7222, Val Loss: 48.6977, Recon: 0.7093, KL: 48.0130, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7026, Val Loss: 48.6997, Recon: 0.6969, KL: 48.0057, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6962, Val Loss: 48.6845, Recon: 0.6937, KL: 48.0025, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6974, Val Loss: 48.6979, Recon: 0.6915, KL: 48.0059, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6933, Val Loss: 48.6925, Recon: 0.6898, KL: 48.0036, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6901, Val Loss: 48.6782, Recon: 0.6860, KL: 48.0041, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6946, Val Loss: 48.6854, Recon: 0.6916, KL: 48.0030, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6882, Val Loss: 48.6822, Recon: 0.6843, KL: 48.0039, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6810, Val Loss: 48.6740, Recon: 0.6782, KL: 48.0028, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6813, Val Loss: 48.6942, Recon: 0.6786, KL: 48.0027, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6896, Val Loss: 48.6721, Recon: 0.6854, KL: 48.0042, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6896, Val Loss: 48.6835, Recon: 0.6869, KL: 48.0027, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6899, Val Loss: 48.6826, Recon: 0.6841, KL: 48.0059, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6781, Val Loss: 48.6787, Recon: 0.6761, KL: 48.0020, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6836, Val Loss: 48.6747, Recon: 0.6808, KL: 48.0028, KL_weight: 4.8000
Saved model 42 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_41.pt
Training bootstrap model 43/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9442, Val Loss: 0.7129, Recon: 0.9442, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6850, Val Loss: 4.6260, Recon: 0.8178, KL: 3.8672, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4577, Val Loss: 9.4033, Recon: 0.8018, KL: 8.6559, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2403, Val Loss: 14.1962, Recon: 0.7885, KL: 13.4518, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0232, Val Loss: 18.9970, Recon: 0.7761, KL: 18.2470, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8313, Val Loss: 23.7769, Recon: 0.7778, KL: 23.0535, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6342, Val Loss: 28.5796, Recon: 0.7768, KL: 27.8574, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4077, Val Loss: 33.3928, Recon: 0.7613, KL: 32.6464, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2084, Val Loss: 38.1690, Recon: 0.7612, KL: 37.4472, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0032, Val Loss: 42.9691, Recon: 0.7554, KL: 42.2478, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8010, Val Loss: 47.7899, Recon: 0.7524, KL: 47.0486, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7596, Val Loss: 48.7429, Recon: 0.7534, KL: 48.0062, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7490, Val Loss: 48.7322, Recon: 0.7420, KL: 48.0070, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7466, Val Loss: 48.7296, Recon: 0.7403, KL: 48.0063, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7606, Val Loss: 48.7460, Recon: 0.7442, KL: 48.0164, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7581, Val Loss: 48.7278, Recon: 0.7455, KL: 48.0126, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7442, Val Loss: 48.7505, Recon: 0.7368, KL: 48.0074, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7347, Val Loss: 48.7231, Recon: 0.7302, KL: 48.0044, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7253, Val Loss: 48.7318, Recon: 0.7183, KL: 48.0070, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7317, Val Loss: 48.7215, Recon: 0.7294, KL: 48.0024, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7246, Val Loss: 48.7225, Recon: 0.7225, KL: 48.0020, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7399, Val Loss: 48.7202, Recon: 0.7349, KL: 48.0051, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7333, Val Loss: 48.7272, Recon: 0.7245, KL: 48.0088, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7525, Val Loss: 48.7367, Recon: 0.7410, KL: 48.0115, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7341, Val Loss: 48.7297, Recon: 0.7280, KL: 48.0061, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7247, Val Loss: 48.7313, Recon: 0.7182, KL: 48.0065, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7272, Val Loss: 48.7083, Recon: 0.7189, KL: 48.0083, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7276, Val Loss: 48.7336, Recon: 0.7257, KL: 48.0019, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7321, Val Loss: 48.7141, Recon: 0.7257, KL: 48.0064, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7215, Val Loss: 48.7092, Recon: 0.7190, KL: 48.0025, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7209, Val Loss: 48.7146, Recon: 0.7186, KL: 48.0023, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7217, Val Loss: 48.7118, Recon: 0.7177, KL: 48.0041, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7235, Val Loss: 48.7049, Recon: 0.7200, KL: 48.0035, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7163, Val Loss: 48.7084, Recon: 0.7127, KL: 48.0035, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7222, Val Loss: 48.7124, Recon: 0.7186, KL: 48.0036, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7149, Val Loss: 48.7043, Recon: 0.7108, KL: 48.0041, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7154, Val Loss: 48.7109, Recon: 0.7108, KL: 48.0046, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7044, Val Loss: 48.6918, Recon: 0.7026, KL: 48.0018, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7029, Val Loss: 48.6991, Recon: 0.6987, KL: 48.0042, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7017, Val Loss: 48.6880, Recon: 0.7002, KL: 48.0015, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7215, Val Loss: 48.6940, Recon: 0.7156, KL: 48.0059, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7112, Val Loss: 48.6845, Recon: 0.7041, KL: 48.0071, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6950, Val Loss: 48.6882, Recon: 0.6930, KL: 48.0020, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7054, Val Loss: 48.6840, Recon: 0.7012, KL: 48.0042, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6979, Val Loss: 48.6807, Recon: 0.6933, KL: 48.0046, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6928, Val Loss: 48.6865, Recon: 0.6895, KL: 48.0033, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7007, Val Loss: 48.6761, Recon: 0.6862, KL: 48.0146, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6902, Val Loss: 48.6824, Recon: 0.6878, KL: 48.0024, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6835, Val Loss: 48.6805, Recon: 0.6789, KL: 48.0047, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6823, Val Loss: 48.6753, Recon: 0.6801, KL: 48.0022, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6909, Val Loss: 48.6721, Recon: 0.6891, KL: 48.0018, KL_weight: 4.8000
Saved model 43 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_42.pt
Training bootstrap model 44/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9508, Val Loss: 0.7452, Recon: 0.9508, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6891, Val Loss: 4.6443, Recon: 0.8136, KL: 3.8755, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4473, Val Loss: 9.4159, Recon: 0.7923, KL: 8.6550, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2224, Val Loss: 14.2022, Recon: 0.7706, KL: 13.4518, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0086, Val Loss: 18.9916, Recon: 0.7595, KL: 18.2492, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8178, Val Loss: 23.8183, Recon: 0.7621, KL: 23.0557, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6032, Val Loss: 28.5852, Recon: 0.7560, KL: 27.8472, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4008, Val Loss: 33.3707, Recon: 0.7543, KL: 32.6465, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1961, Val Loss: 38.1864, Recon: 0.7489, KL: 37.4472, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0384, Val Loss: 42.9897, Recon: 0.7555, KL: 42.2829, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7884, Val Loss: 47.7844, Recon: 0.7391, KL: 47.0493, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7458, Val Loss: 48.7314, Recon: 0.7399, KL: 48.0059, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7409, Val Loss: 48.7412, Recon: 0.7328, KL: 48.0081, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7337, Val Loss: 48.7384, Recon: 0.7274, KL: 48.0062, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7276, Val Loss: 48.7157, Recon: 0.7240, KL: 48.0036, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7391, Val Loss: 48.7194, Recon: 0.7327, KL: 48.0064, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7286, Val Loss: 48.7199, Recon: 0.7242, KL: 48.0044, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7255, Val Loss: 48.7180, Recon: 0.7215, KL: 48.0040, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7241, Val Loss: 48.7282, Recon: 0.7205, KL: 48.0035, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7146, Val Loss: 48.7254, Recon: 0.7117, KL: 48.0029, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7285, Val Loss: 48.7152, Recon: 0.7243, KL: 48.0042, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7495, Val Loss: 48.7304, Recon: 0.7463, KL: 48.0032, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7416, Val Loss: 48.7186, Recon: 0.7357, KL: 48.0059, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7241, Val Loss: 48.7119, Recon: 0.7198, KL: 48.0043, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7131, Val Loss: 48.7095, Recon: 0.7096, KL: 48.0035, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7100, Val Loss: 48.7010, Recon: 0.7031, KL: 48.0069, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7072, Val Loss: 48.6967, Recon: 0.7031, KL: 48.0041, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7188, Val Loss: 48.6962, Recon: 0.7148, KL: 48.0040, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7064, Val Loss: 48.7062, Recon: 0.7005, KL: 48.0059, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7467, Val Loss: 48.6998, Recon: 0.7037, KL: 48.0430, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7072, Val Loss: 48.6949, Recon: 0.7014, KL: 48.0058, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6903, Val Loss: 48.6904, Recon: 0.6872, KL: 48.0031, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6865, Val Loss: 48.6969, Recon: 0.6841, KL: 48.0024, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6886, Val Loss: 48.6853, Recon: 0.6859, KL: 48.0028, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7145, Val Loss: 48.7057, Recon: 0.7011, KL: 48.0133, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6857, Val Loss: 48.6822, Recon: 0.6833, KL: 48.0024, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6860, Val Loss: 48.6743, Recon: 0.6825, KL: 48.0035, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6841, Val Loss: 48.6847, Recon: 0.6808, KL: 48.0033, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6961, Val Loss: 48.6855, Recon: 0.6918, KL: 48.0043, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6848, Val Loss: 48.6749, Recon: 0.6817, KL: 48.0031, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6823, Val Loss: 48.6722, Recon: 0.6790, KL: 48.0033, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7028, Val Loss: 48.6918, Recon: 0.6890, KL: 48.0138, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6802, Val Loss: 48.6758, Recon: 0.6791, KL: 48.0011, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6825, Val Loss: 48.6857, Recon: 0.6794, KL: 48.0031, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6949, Val Loss: 48.6866, Recon: 0.6882, KL: 48.0067, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6864, Val Loss: 48.6855, Recon: 0.6821, KL: 48.0043, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6817, Val Loss: 48.6788, Recon: 0.6787, KL: 48.0030, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6949, Val Loss: 48.6939, Recon: 0.6869, KL: 48.0081, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6761, Val Loss: 48.6744, Recon: 0.6745, KL: 48.0016, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6841, Val Loss: 48.6763, Recon: 0.6788, KL: 48.0053, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6752, Val Loss: 48.6750, Recon: 0.6701, KL: 48.0050, KL_weight: 4.8000
Saved model 44 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_43.pt
Training bootstrap model 45/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9575, Val Loss: 0.7268, Recon: 0.9575, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7015, Val Loss: 4.6487, Recon: 0.8281, KL: 3.8734, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4625, Val Loss: 9.4104, Recon: 0.8054, KL: 8.6571, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2430, Val Loss: 14.2202, Recon: 0.7834, KL: 13.4596, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0173, Val Loss: 19.0039, Recon: 0.7631, KL: 18.2542, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8145, Val Loss: 23.7945, Recon: 0.7652, KL: 23.0492, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6117, Val Loss: 28.5789, Recon: 0.7615, KL: 27.8502, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4039, Val Loss: 33.3792, Recon: 0.7549, KL: 32.6489, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2030, Val Loss: 38.1922, Recon: 0.7557, KL: 37.4473, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9880, Val Loss: 42.9678, Recon: 0.7435, KL: 42.2446, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8204, Val Loss: 47.7784, Recon: 0.7688, KL: 47.0516, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7584, Val Loss: 48.7223, Recon: 0.7460, KL: 48.0124, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7314, Val Loss: 48.7271, Recon: 0.7281, KL: 48.0032, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7573, Val Loss: 48.7320, Recon: 0.7415, KL: 48.0158, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7388, Val Loss: 48.7469, Recon: 0.7291, KL: 48.0098, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7376, Val Loss: 48.7155, Recon: 0.7348, KL: 48.0027, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7346, Val Loss: 48.7244, Recon: 0.7310, KL: 48.0036, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7287, Val Loss: 48.7221, Recon: 0.7235, KL: 48.0053, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7213, Val Loss: 48.7286, Recon: 0.7182, KL: 48.0031, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7134, Val Loss: 48.7053, Recon: 0.7093, KL: 48.0041, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7211, Val Loss: 48.7158, Recon: 0.7176, KL: 48.0035, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7246, Val Loss: 48.7209, Recon: 0.7199, KL: 48.0047, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7278, Val Loss: 48.7115, Recon: 0.7214, KL: 48.0064, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7435, Val Loss: 48.7128, Recon: 0.7185, KL: 48.0250, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7228, Val Loss: 48.7045, Recon: 0.7180, KL: 48.0048, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7128, Val Loss: 48.7174, Recon: 0.7096, KL: 48.0032, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7140, Val Loss: 48.7079, Recon: 0.7118, KL: 48.0022, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7294, Val Loss: 48.7259, Recon: 0.7186, KL: 48.0108, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7173, Val Loss: 48.7112, Recon: 0.7122, KL: 48.0051, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7073, Val Loss: 48.7029, Recon: 0.7053, KL: 48.0020, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7237, Val Loss: 48.7124, Recon: 0.7164, KL: 48.0073, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7101, Val Loss: 48.6943, Recon: 0.7080, KL: 48.0021, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7245, Val Loss: 48.7228, Recon: 0.7160, KL: 48.0084, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7213, Val Loss: 48.7112, Recon: 0.7166, KL: 48.0047, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7026, Val Loss: 48.7117, Recon: 0.6999, KL: 48.0026, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7076, Val Loss: 48.6976, Recon: 0.7041, KL: 48.0034, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7038, Val Loss: 48.7219, Recon: 0.6971, KL: 48.0067, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7107, Val Loss: 48.7018, Recon: 0.7053, KL: 48.0054, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6969, Val Loss: 48.6889, Recon: 0.6944, KL: 48.0024, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7162, Val Loss: 48.7171, Recon: 0.7105, KL: 48.0057, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7001, Val Loss: 48.6936, Recon: 0.6978, KL: 48.0023, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7121, Val Loss: 48.7243, Recon: 0.7007, KL: 48.0114, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6977, Val Loss: 48.7017, Recon: 0.6923, KL: 48.0054, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6848, Val Loss: 48.6990, Recon: 0.6821, KL: 48.0027, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6957, Val Loss: 48.6899, Recon: 0.6908, KL: 48.0049, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6885, Val Loss: 48.6941, Recon: 0.6841, KL: 48.0044, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6814, Val Loss: 48.6898, Recon: 0.6776, KL: 48.0038, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6979, Val Loss: 48.6767, Recon: 0.6917, KL: 48.0062, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6919, Val Loss: 48.6860, Recon: 0.6880, KL: 48.0039, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6964, Val Loss: 48.7054, Recon: 0.6899, KL: 48.0065, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6849, Val Loss: 48.6865, Recon: 0.6786, KL: 48.0062, KL_weight: 4.8000
Saved model 45 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_44.pt
Training bootstrap model 46/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9900, Val Loss: 0.7618, Recon: 0.9900, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6976, Val Loss: 4.6166, Recon: 0.8277, KL: 3.8699, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4611, Val Loss: 9.4089, Recon: 0.8041, KL: 8.6570, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2468, Val Loss: 14.2154, Recon: 0.7913, KL: 13.4554, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0540, Val Loss: 19.0115, Recon: 0.7968, KL: 18.2572, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8207, Val Loss: 23.7811, Recon: 0.7674, KL: 23.0533, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6001, Val Loss: 28.5809, Recon: 0.7481, KL: 27.8519, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4096, Val Loss: 33.3667, Recon: 0.7646, KL: 32.6450, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2014, Val Loss: 38.1759, Recon: 0.7560, KL: 37.4454, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0349, Val Loss: 43.0059, Recon: 0.7859, KL: 42.2490, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8165, Val Loss: 47.7930, Recon: 0.7669, KL: 47.0496, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7581, Val Loss: 48.7447, Recon: 0.7516, KL: 48.0065, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7535, Val Loss: 48.7288, Recon: 0.7478, KL: 48.0057, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7615, Val Loss: 48.7160, Recon: 0.7538, KL: 48.0077, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7400, Val Loss: 48.7183, Recon: 0.7368, KL: 48.0032, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7498, Val Loss: 48.7133, Recon: 0.7426, KL: 48.0072, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7515, Val Loss: 48.7270, Recon: 0.7441, KL: 48.0074, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7569, Val Loss: 48.7311, Recon: 0.7484, KL: 48.0085, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7341, Val Loss: 48.7170, Recon: 0.7272, KL: 48.0070, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7347, Val Loss: 48.7220, Recon: 0.7298, KL: 48.0049, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7417, Val Loss: 48.7295, Recon: 0.7353, KL: 48.0064, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7227, Val Loss: 48.7285, Recon: 0.7189, KL: 48.0038, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7374, Val Loss: 48.7325, Recon: 0.7322, KL: 48.0052, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7242, Val Loss: 48.7156, Recon: 0.7211, KL: 48.0031, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7177, Val Loss: 48.7078, Recon: 0.7157, KL: 48.0021, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7315, Val Loss: 48.7021, Recon: 0.7293, KL: 48.0023, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7314, Val Loss: 48.7088, Recon: 0.7282, KL: 48.0032, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7195, Val Loss: 48.6994, Recon: 0.7167, KL: 48.0028, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7322, Val Loss: 48.7179, Recon: 0.7252, KL: 48.0070, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7335, Val Loss: 48.7084, Recon: 0.7285, KL: 48.0050, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7224, Val Loss: 48.7200, Recon: 0.7168, KL: 48.0055, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7118, Val Loss: 48.7144, Recon: 0.7083, KL: 48.0035, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7154, Val Loss: 48.7147, Recon: 0.7088, KL: 48.0066, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7103, Val Loss: 48.7021, Recon: 0.7054, KL: 48.0049, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7139, Val Loss: 48.7067, Recon: 0.7108, KL: 48.0031, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7184, Val Loss: 48.6889, Recon: 0.7163, KL: 48.0021, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7013, Val Loss: 48.6889, Recon: 0.6985, KL: 48.0028, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7099, Val Loss: 48.7081, Recon: 0.7055, KL: 48.0043, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7147, Val Loss: 48.6943, Recon: 0.7094, KL: 48.0053, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7056, Val Loss: 48.7079, Recon: 0.6971, KL: 48.0086, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6957, Val Loss: 48.6862, Recon: 0.6909, KL: 48.0047, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6961, Val Loss: 48.6874, Recon: 0.6917, KL: 48.0043, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7062, Val Loss: 48.7140, Recon: 0.6951, KL: 48.0111, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7057, Val Loss: 48.6910, Recon: 0.7001, KL: 48.0055, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6989, Val Loss: 48.6886, Recon: 0.6953, KL: 48.0036, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6924, Val Loss: 48.6734, Recon: 0.6891, KL: 48.0034, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7033, Val Loss: 48.6761, Recon: 0.6975, KL: 48.0058, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6921, Val Loss: 48.6803, Recon: 0.6882, KL: 48.0040, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6902, Val Loss: 48.6848, Recon: 0.6851, KL: 48.0051, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6870, Val Loss: 48.6775, Recon: 0.6829, KL: 48.0042, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6932, Val Loss: 48.6853, Recon: 0.6893, KL: 48.0039, KL_weight: 4.8000
Saved model 46 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_45.pt
Training bootstrap model 47/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9425, Val Loss: 0.7247, Recon: 0.9425, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6826, Val Loss: 4.6240, Recon: 0.8183, KL: 3.8643, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4591, Val Loss: 9.4237, Recon: 0.7994, KL: 8.6597, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2283, Val Loss: 14.2120, Recon: 0.7768, KL: 13.4515, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0271, Val Loss: 19.0109, Recon: 0.7712, KL: 18.2559, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8209, Val Loss: 23.8034, Recon: 0.7663, KL: 23.0545, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6065, Val Loss: 28.5822, Recon: 0.7581, KL: 27.8484, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3894, Val Loss: 33.3685, Recon: 0.7440, KL: 32.6454, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1911, Val Loss: 38.1667, Recon: 0.7437, KL: 37.4475, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0237, Val Loss: 42.9933, Recon: 0.7687, KL: 42.2549, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8262, Val Loss: 47.8066, Recon: 0.7646, KL: 47.0615, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7427, Val Loss: 48.7436, Recon: 0.7383, KL: 48.0045, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7653, Val Loss: 48.7310, Recon: 0.7608, KL: 48.0045, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7373, Val Loss: 48.7284, Recon: 0.7304, KL: 48.0069, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7273, Val Loss: 48.7311, Recon: 0.7237, KL: 48.0036, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7327, Val Loss: 48.7210, Recon: 0.7276, KL: 48.0051, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7344, Val Loss: 48.7174, Recon: 0.7313, KL: 48.0031, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7388, Val Loss: 48.7388, Recon: 0.7325, KL: 48.0064, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7318, Val Loss: 48.7041, Recon: 0.7245, KL: 48.0073, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7112, Val Loss: 48.7069, Recon: 0.7084, KL: 48.0029, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7278, Val Loss: 48.7114, Recon: 0.7207, KL: 48.0072, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7163, Val Loss: 48.6989, Recon: 0.7125, KL: 48.0038, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7122, Val Loss: 48.6956, Recon: 0.7088, KL: 48.0034, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7065, Val Loss: 48.7041, Recon: 0.7011, KL: 48.0054, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7226, Val Loss: 48.6956, Recon: 0.7166, KL: 48.0060, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7120, Val Loss: 48.7074, Recon: 0.7064, KL: 48.0056, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7109, Val Loss: 48.6983, Recon: 0.7061, KL: 48.0047, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7107, Val Loss: 48.7134, Recon: 0.7046, KL: 48.0061, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7011, Val Loss: 48.6936, Recon: 0.6980, KL: 48.0031, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7283, Val Loss: 48.7087, Recon: 0.7218, KL: 48.0065, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7097, Val Loss: 48.6909, Recon: 0.7040, KL: 48.0057, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7020, Val Loss: 48.7066, Recon: 0.6991, KL: 48.0029, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7123, Val Loss: 48.7170, Recon: 0.7049, KL: 48.0074, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6916, Val Loss: 48.6870, Recon: 0.6883, KL: 48.0033, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6944, Val Loss: 48.7088, Recon: 0.6881, KL: 48.0063, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6959, Val Loss: 48.6879, Recon: 0.6923, KL: 48.0036, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6959, Val Loss: 48.6922, Recon: 0.6920, KL: 48.0039, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6988, Val Loss: 48.6992, Recon: 0.6955, KL: 48.0034, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6879, Val Loss: 48.7034, Recon: 0.6852, KL: 48.0027, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7076, Val Loss: 48.6869, Recon: 0.6939, KL: 48.0137, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6975, Val Loss: 48.7133, Recon: 0.6922, KL: 48.0053, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7068, Val Loss: 48.7205, Recon: 0.6989, KL: 48.0080, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6902, Val Loss: 48.6769, Recon: 0.6870, KL: 48.0032, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6835, Val Loss: 48.6802, Recon: 0.6812, KL: 48.0023, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6823, Val Loss: 48.6907, Recon: 0.6796, KL: 48.0027, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6936, Val Loss: 48.6861, Recon: 0.6898, KL: 48.0037, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6825, Val Loss: 48.6891, Recon: 0.6763, KL: 48.0062, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6860, Val Loss: 48.6802, Recon: 0.6821, KL: 48.0039, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6820, Val Loss: 48.6898, Recon: 0.6773, KL: 48.0047, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6834, Val Loss: 48.6910, Recon: 0.6816, KL: 48.0018, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6907, Val Loss: 48.6728, Recon: 0.6869, KL: 48.0038, KL_weight: 4.8000
Saved model 47 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_46.pt
Training bootstrap model 48/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9843, Val Loss: 0.7286, Recon: 0.9843, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7281, Val Loss: 4.6459, Recon: 0.8553, KL: 3.8728, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4833, Val Loss: 9.4320, Recon: 0.8223, KL: 8.6610, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2725, Val Loss: 14.2298, Recon: 0.8157, KL: 13.4568, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0657, Val Loss: 19.0139, Recon: 0.8127, KL: 18.2530, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8472, Val Loss: 23.8222, Recon: 0.7918, KL: 23.0554, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6321, Val Loss: 28.5837, Recon: 0.7861, KL: 27.8461, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4329, Val Loss: 33.3824, Recon: 0.7846, KL: 32.6483, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2319, Val Loss: 38.2296, Recon: 0.7839, KL: 37.4480, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0474, Val Loss: 42.9849, Recon: 0.7943, KL: 42.2531, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8218, Val Loss: 47.7884, Recon: 0.7730, KL: 47.0488, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7704, Val Loss: 48.7325, Recon: 0.7631, KL: 48.0074, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7675, Val Loss: 48.7278, Recon: 0.7599, KL: 48.0077, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7577, Val Loss: 48.7229, Recon: 0.7521, KL: 48.0056, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7541, Val Loss: 48.7165, Recon: 0.7461, KL: 48.0079, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7547, Val Loss: 48.7425, Recon: 0.7424, KL: 48.0123, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7458, Val Loss: 48.7290, Recon: 0.7381, KL: 48.0077, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7480, Val Loss: 48.6991, Recon: 0.7431, KL: 48.0049, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7400, Val Loss: 48.7017, Recon: 0.7334, KL: 48.0066, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7331, Val Loss: 48.7089, Recon: 0.7282, KL: 48.0049, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7316, Val Loss: 48.7265, Recon: 0.7254, KL: 48.0063, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7328, Val Loss: 48.7158, Recon: 0.7276, KL: 48.0052, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7499, Val Loss: 48.7117, Recon: 0.7400, KL: 48.0099, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7467, Val Loss: 48.7094, Recon: 0.7417, KL: 48.0049, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7309, Val Loss: 48.7044, Recon: 0.7253, KL: 48.0056, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7218, Val Loss: 48.6951, Recon: 0.7173, KL: 48.0045, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7352, Val Loss: 48.7244, Recon: 0.7221, KL: 48.0131, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7557, Val Loss: 48.7446, Recon: 0.7430, KL: 48.0127, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7427, Val Loss: 48.7217, Recon: 0.7344, KL: 48.0083, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7285, Val Loss: 48.7028, Recon: 0.7207, KL: 48.0078, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7335, Val Loss: 48.7367, Recon: 0.7191, KL: 48.0144, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7212, Val Loss: 48.7039, Recon: 0.7159, KL: 48.0053, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7139, Val Loss: 48.6940, Recon: 0.7097, KL: 48.0042, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7167, Val Loss: 48.7133, Recon: 0.7128, KL: 48.0040, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7128, Val Loss: 48.7002, Recon: 0.7057, KL: 48.0070, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7509, Val Loss: 48.6988, Recon: 0.7157, KL: 48.0352, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7036, Val Loss: 48.6930, Recon: 0.7000, KL: 48.0035, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6998, Val Loss: 48.7004, Recon: 0.6965, KL: 48.0033, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7021, Val Loss: 48.6899, Recon: 0.6991, KL: 48.0031, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7108, Val Loss: 48.6881, Recon: 0.7045, KL: 48.0063, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7422, Val Loss: 48.7005, Recon: 0.7246, KL: 48.0177, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7027, Val Loss: 48.6813, Recon: 0.6946, KL: 48.0081, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6985, Val Loss: 48.7036, Recon: 0.6928, KL: 48.0057, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6986, Val Loss: 48.6809, Recon: 0.6935, KL: 48.0052, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7044, Val Loss: 48.6919, Recon: 0.7001, KL: 48.0043, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6976, Val Loss: 48.6784, Recon: 0.6936, KL: 48.0040, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7091, Val Loss: 48.6785, Recon: 0.6969, KL: 48.0123, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6921, Val Loss: 48.6822, Recon: 0.6871, KL: 48.0050, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6988, Val Loss: 48.6835, Recon: 0.6946, KL: 48.0042, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6977, Val Loss: 48.6773, Recon: 0.6933, KL: 48.0045, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.7115, Val Loss: 48.6889, Recon: 0.7049, KL: 48.0067, KL_weight: 4.8000
Saved model 48 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_47.pt
Training bootstrap model 49/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9671, Val Loss: 0.7520, Recon: 0.9671, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6921, Val Loss: 4.6489, Recon: 0.8216, KL: 3.8706, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4456, Val Loss: 9.4063, Recon: 0.7892, KL: 8.6564, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2399, Val Loss: 14.2191, Recon: 0.7882, KL: 13.4517, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0272, Val Loss: 18.9996, Recon: 0.7758, KL: 18.2514, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8105, Val Loss: 23.7830, Recon: 0.7633, KL: 23.0473, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6094, Val Loss: 28.5827, Recon: 0.7616, KL: 27.8479, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4251, Val Loss: 33.4187, Recon: 0.7612, KL: 32.6639, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1996, Val Loss: 38.1801, Recon: 0.7513, KL: 37.4483, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0142, Val Loss: 42.9878, Recon: 0.7635, KL: 42.2507, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8040, Val Loss: 47.7764, Recon: 0.7562, KL: 47.0478, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7554, Val Loss: 48.7257, Recon: 0.7500, KL: 48.0053, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7600, Val Loss: 48.7317, Recon: 0.7554, KL: 48.0046, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7455, Val Loss: 48.7229, Recon: 0.7411, KL: 48.0044, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7373, Val Loss: 48.7112, Recon: 0.7345, KL: 48.0029, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7546, Val Loss: 48.7220, Recon: 0.7462, KL: 48.0084, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7577, Val Loss: 48.7364, Recon: 0.7454, KL: 48.0123, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7349, Val Loss: 48.7117, Recon: 0.7288, KL: 48.0061, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7275, Val Loss: 48.7213, Recon: 0.7222, KL: 48.0053, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7335, Val Loss: 48.7407, Recon: 0.7269, KL: 48.0066, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7270, Val Loss: 48.7136, Recon: 0.7226, KL: 48.0045, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7229, Val Loss: 48.7081, Recon: 0.7206, KL: 48.0024, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7252, Val Loss: 48.7059, Recon: 0.7193, KL: 48.0059, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7574, Val Loss: 48.7326, Recon: 0.7381, KL: 48.0193, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7309, Val Loss: 48.7266, Recon: 0.7243, KL: 48.0066, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7194, Val Loss: 48.7230, Recon: 0.7162, KL: 48.0033, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7175, Val Loss: 48.7153, Recon: 0.7138, KL: 48.0037, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7311, Val Loss: 48.7271, Recon: 0.7183, KL: 48.0128, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7103, Val Loss: 48.6971, Recon: 0.7049, KL: 48.0054, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7145, Val Loss: 48.7135, Recon: 0.7103, KL: 48.0042, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7057, Val Loss: 48.6931, Recon: 0.7002, KL: 48.0055, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6960, Val Loss: 48.6950, Recon: 0.6934, KL: 48.0026, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7048, Val Loss: 48.6817, Recon: 0.7002, KL: 48.0046, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6988, Val Loss: 48.6941, Recon: 0.6947, KL: 48.0041, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6995, Val Loss: 48.6964, Recon: 0.6936, KL: 48.0059, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7066, Val Loss: 48.6756, Recon: 0.7035, KL: 48.0031, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6964, Val Loss: 48.7126, Recon: 0.6935, KL: 48.0030, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7084, Val Loss: 48.6970, Recon: 0.6977, KL: 48.0108, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7090, Val Loss: 48.6942, Recon: 0.7035, KL: 48.0056, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6954, Val Loss: 48.6886, Recon: 0.6926, KL: 48.0028, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6913, Val Loss: 48.6800, Recon: 0.6891, KL: 48.0022, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6886, Val Loss: 48.6781, Recon: 0.6854, KL: 48.0032, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6969, Val Loss: 48.6904, Recon: 0.6923, KL: 48.0047, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6871, Val Loss: 48.6734, Recon: 0.6839, KL: 48.0032, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6851, Val Loss: 48.6757, Recon: 0.6823, KL: 48.0028, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6955, Val Loss: 48.6866, Recon: 0.6852, KL: 48.0103, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7092, Val Loss: 48.6923, Recon: 0.7039, KL: 48.0053, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6910, Val Loss: 48.6774, Recon: 0.6884, KL: 48.0026, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7092, Val Loss: 48.6905, Recon: 0.6973, KL: 48.0120, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6960, Val Loss: 48.6788, Recon: 0.6932, KL: 48.0028, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6891, Val Loss: 48.6760, Recon: 0.6856, KL: 48.0035, KL_weight: 4.8000
Saved model 49 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_48.pt
Training bootstrap model 50/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9917, Val Loss: 0.8014, Recon: 0.9917, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7669, Val Loss: 4.6583, Recon: 0.8627, KL: 3.9042, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4958, Val Loss: 9.4207, Recon: 0.8331, KL: 8.6626, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2761, Val Loss: 14.2098, Recon: 0.8152, KL: 13.4609, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0588, Val Loss: 19.0023, Recon: 0.8046, KL: 18.2542, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8363, Val Loss: 23.7907, Recon: 0.7889, KL: 23.0475, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6350, Val Loss: 28.6140, Recon: 0.7836, KL: 27.8514, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4275, Val Loss: 33.3985, Recon: 0.7786, KL: 32.6489, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2343, Val Loss: 38.1931, Recon: 0.7818, KL: 37.4525, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0117, Val Loss: 42.9823, Recon: 0.7661, KL: 42.2456, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8235, Val Loss: 47.7709, Recon: 0.7763, KL: 47.0472, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7789, Val Loss: 48.7657, Recon: 0.7719, KL: 48.0070, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7523, Val Loss: 48.7322, Recon: 0.7474, KL: 48.0050, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7583, Val Loss: 48.7471, Recon: 0.7502, KL: 48.0081, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7601, Val Loss: 48.7310, Recon: 0.7524, KL: 48.0077, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7476, Val Loss: 48.7348, Recon: 0.7423, KL: 48.0053, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7571, Val Loss: 48.7442, Recon: 0.7449, KL: 48.0122, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7503, Val Loss: 48.7376, Recon: 0.7432, KL: 48.0071, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7424, Val Loss: 48.7255, Recon: 0.7393, KL: 48.0032, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7527, Val Loss: 48.7382, Recon: 0.7468, KL: 48.0059, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7371, Val Loss: 48.7120, Recon: 0.7340, KL: 48.0031, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7336, Val Loss: 48.7179, Recon: 0.7293, KL: 48.0043, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7445, Val Loss: 48.7163, Recon: 0.7415, KL: 48.0030, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7291, Val Loss: 48.7238, Recon: 0.7273, KL: 48.0018, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7330, Val Loss: 48.7103, Recon: 0.7293, KL: 48.0037, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7389, Val Loss: 48.7244, Recon: 0.7361, KL: 48.0028, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7360, Val Loss: 48.7232, Recon: 0.7313, KL: 48.0047, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7244, Val Loss: 48.7206, Recon: 0.7227, KL: 48.0018, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7338, Val Loss: 48.7091, Recon: 0.7282, KL: 48.0056, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7406, Val Loss: 48.7134, Recon: 0.7343, KL: 48.0063, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7367, Val Loss: 48.7029, Recon: 0.7344, KL: 48.0023, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7422, Val Loss: 48.7258, Recon: 0.7298, KL: 48.0124, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7310, Val Loss: 48.7217, Recon: 0.7270, KL: 48.0040, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7211, Val Loss: 48.7123, Recon: 0.7153, KL: 48.0058, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7339, Val Loss: 48.7199, Recon: 0.7240, KL: 48.0099, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7211, Val Loss: 48.6983, Recon: 0.7168, KL: 48.0043, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7219, Val Loss: 48.7081, Recon: 0.7157, KL: 48.0062, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7055, Val Loss: 48.6948, Recon: 0.7013, KL: 48.0042, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7143, Val Loss: 48.6984, Recon: 0.7105, KL: 48.0038, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7123, Val Loss: 48.7079, Recon: 0.7097, KL: 48.0026, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7245, Val Loss: 48.6935, Recon: 0.7056, KL: 48.0189, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7138, Val Loss: 48.7070, Recon: 0.7081, KL: 48.0056, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7122, Val Loss: 48.7292, Recon: 0.7067, KL: 48.0055, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7029, Val Loss: 48.7043, Recon: 0.6988, KL: 48.0041, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7065, Val Loss: 48.6892, Recon: 0.7003, KL: 48.0062, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6973, Val Loss: 48.6954, Recon: 0.6923, KL: 48.0050, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7074, Val Loss: 48.6837, Recon: 0.7016, KL: 48.0058, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6951, Val Loss: 48.6911, Recon: 0.6917, KL: 48.0034, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6978, Val Loss: 48.6881, Recon: 0.6922, KL: 48.0056, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7122, Val Loss: 48.7005, Recon: 0.7041, KL: 48.0081, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.7053, Val Loss: 48.6971, Recon: 0.7003, KL: 48.0050, KL_weight: 4.8000
Saved model 50 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_49.pt
Training bootstrap model 51/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9516, Val Loss: 0.7257, Recon: 0.9516, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6927, Val Loss: 4.6376, Recon: 0.8217, KL: 3.8710, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4493, Val Loss: 9.4093, Recon: 0.7944, KL: 8.6550, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2347, Val Loss: 14.2135, Recon: 0.7762, KL: 13.4585, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0273, Val Loss: 18.9977, Recon: 0.7741, KL: 18.2531, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8223, Val Loss: 23.7815, Recon: 0.7735, KL: 23.0488, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6041, Val Loss: 28.6118, Recon: 0.7573, KL: 27.8467, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4042, Val Loss: 33.3763, Recon: 0.7573, KL: 32.6469, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1963, Val Loss: 38.1790, Recon: 0.7509, KL: 37.4454, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9973, Val Loss: 42.9707, Recon: 0.7516, KL: 42.2457, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8218, Val Loss: 47.8003, Recon: 0.7597, KL: 47.0622, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7521, Val Loss: 48.7395, Recon: 0.7454, KL: 48.0067, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7406, Val Loss: 48.7263, Recon: 0.7359, KL: 48.0047, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7392, Val Loss: 48.7368, Recon: 0.7339, KL: 48.0054, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7389, Val Loss: 48.7353, Recon: 0.7356, KL: 48.0032, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7341, Val Loss: 48.7419, Recon: 0.7307, KL: 48.0033, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7245, Val Loss: 48.7173, Recon: 0.7214, KL: 48.0032, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7299, Val Loss: 48.7241, Recon: 0.7260, KL: 48.0039, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7321, Val Loss: 48.7104, Recon: 0.7300, KL: 48.0021, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7279, Val Loss: 48.7100, Recon: 0.7240, KL: 48.0039, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7246, Val Loss: 48.7095, Recon: 0.7223, KL: 48.0023, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7244, Val Loss: 48.7166, Recon: 0.7217, KL: 48.0027, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7206, Val Loss: 48.7161, Recon: 0.7168, KL: 48.0038, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7293, Val Loss: 48.7342, Recon: 0.7224, KL: 48.0069, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7179, Val Loss: 48.7082, Recon: 0.7146, KL: 48.0033, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7254, Val Loss: 48.7203, Recon: 0.7227, KL: 48.0027, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7125, Val Loss: 48.7236, Recon: 0.7104, KL: 48.0021, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7136, Val Loss: 48.7006, Recon: 0.7114, KL: 48.0022, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7147, Val Loss: 48.7279, Recon: 0.7104, KL: 48.0043, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7169, Val Loss: 48.7468, Recon: 0.7124, KL: 48.0045, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7170, Val Loss: 48.7087, Recon: 0.7118, KL: 48.0052, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7103, Val Loss: 48.7024, Recon: 0.7085, KL: 48.0018, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7064, Val Loss: 48.7006, Recon: 0.7036, KL: 48.0028, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7141, Val Loss: 48.7195, Recon: 0.7079, KL: 48.0062, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7081, Val Loss: 48.7028, Recon: 0.7051, KL: 48.0030, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6991, Val Loss: 48.7004, Recon: 0.6956, KL: 48.0034, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7031, Val Loss: 48.6984, Recon: 0.6978, KL: 48.0053, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7012, Val Loss: 48.6868, Recon: 0.6966, KL: 48.0047, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6989, Val Loss: 48.6968, Recon: 0.6939, KL: 48.0050, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6970, Val Loss: 48.6785, Recon: 0.6941, KL: 48.0029, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6981, Val Loss: 48.6843, Recon: 0.6930, KL: 48.0051, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6991, Val Loss: 48.6982, Recon: 0.6945, KL: 48.0046, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6865, Val Loss: 48.6837, Recon: 0.6830, KL: 48.0035, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6925, Val Loss: 48.6868, Recon: 0.6901, KL: 48.0024, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6877, Val Loss: 48.6825, Recon: 0.6845, KL: 48.0033, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6839, Val Loss: 48.6817, Recon: 0.6824, KL: 48.0014, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6860, Val Loss: 48.6758, Recon: 0.6838, KL: 48.0023, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6881, Val Loss: 48.6918, Recon: 0.6810, KL: 48.0071, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6841, Val Loss: 48.6832, Recon: 0.6805, KL: 48.0036, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6836, Val Loss: 48.6784, Recon: 0.6799, KL: 48.0037, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6858, Val Loss: 48.6766, Recon: 0.6822, KL: 48.0036, KL_weight: 4.8000
Saved model 51 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_50.pt
Training bootstrap model 52/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9402, Val Loss: 0.7268, Recon: 0.9402, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6962, Val Loss: 4.6481, Recon: 0.8227, KL: 3.8735, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4454, Val Loss: 9.4404, Recon: 0.7885, KL: 8.6569, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2247, Val Loss: 14.1938, Recon: 0.7723, KL: 13.4524, KL_weight: 1.3440
Epoch 20/250, Train Loss: 18.9990, Val Loss: 18.9817, Recon: 0.7508, KL: 18.2483, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8023, Val Loss: 23.7898, Recon: 0.7559, KL: 23.0464, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.5983, Val Loss: 28.5795, Recon: 0.7495, KL: 27.8488, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3868, Val Loss: 33.3891, Recon: 0.7383, KL: 32.6485, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1855, Val Loss: 38.1837, Recon: 0.7386, KL: 37.4469, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0103, Val Loss: 42.9945, Recon: 0.7587, KL: 42.2517, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7852, Val Loss: 47.7746, Recon: 0.7397, KL: 47.0455, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7380, Val Loss: 48.7313, Recon: 0.7340, KL: 48.0040, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7439, Val Loss: 48.7245, Recon: 0.7395, KL: 48.0044, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7427, Val Loss: 48.7209, Recon: 0.7393, KL: 48.0034, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7296, Val Loss: 48.7251, Recon: 0.7218, KL: 48.0078, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7218, Val Loss: 48.7289, Recon: 0.7176, KL: 48.0042, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7273, Val Loss: 48.7260, Recon: 0.7205, KL: 48.0068, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7148, Val Loss: 48.7240, Recon: 0.7122, KL: 48.0026, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7473, Val Loss: 48.7179, Recon: 0.7374, KL: 48.0099, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7211, Val Loss: 48.7124, Recon: 0.7134, KL: 48.0077, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7054, Val Loss: 48.6986, Recon: 0.7020, KL: 48.0034, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7093, Val Loss: 48.7201, Recon: 0.7052, KL: 48.0041, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7092, Val Loss: 48.7145, Recon: 0.7064, KL: 48.0028, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7140, Val Loss: 48.7142, Recon: 0.7079, KL: 48.0061, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.6966, Val Loss: 48.7002, Recon: 0.6909, KL: 48.0057, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7099, Val Loss: 48.7191, Recon: 0.7005, KL: 48.0094, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7008, Val Loss: 48.7209, Recon: 0.6958, KL: 48.0049, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.6958, Val Loss: 48.6991, Recon: 0.6941, KL: 48.0017, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.6927, Val Loss: 48.7068, Recon: 0.6893, KL: 48.0035, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7031, Val Loss: 48.7120, Recon: 0.6975, KL: 48.0056, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.6914, Val Loss: 48.7070, Recon: 0.6865, KL: 48.0049, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6880, Val Loss: 48.6897, Recon: 0.6840, KL: 48.0040, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6915, Val Loss: 48.7001, Recon: 0.6878, KL: 48.0037, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6860, Val Loss: 48.6999, Recon: 0.6802, KL: 48.0058, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6897, Val Loss: 48.6951, Recon: 0.6870, KL: 48.0027, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6904, Val Loss: 48.6876, Recon: 0.6823, KL: 48.0081, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6860, Val Loss: 48.6808, Recon: 0.6820, KL: 48.0041, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6898, Val Loss: 48.7030, Recon: 0.6842, KL: 48.0056, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6859, Val Loss: 48.6864, Recon: 0.6826, KL: 48.0033, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6744, Val Loss: 48.6721, Recon: 0.6721, KL: 48.0024, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6911, Val Loss: 48.6897, Recon: 0.6864, KL: 48.0047, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6744, Val Loss: 48.6772, Recon: 0.6725, KL: 48.0019, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6836, Val Loss: 48.6833, Recon: 0.6782, KL: 48.0054, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6777, Val Loss: 48.6790, Recon: 0.6747, KL: 48.0030, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6808, Val Loss: 48.6833, Recon: 0.6766, KL: 48.0042, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6832, Val Loss: 48.6746, Recon: 0.6805, KL: 48.0027, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6908, Val Loss: 48.6721, Recon: 0.6799, KL: 48.0109, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6719, Val Loss: 48.6844, Recon: 0.6695, KL: 48.0024, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6709, Val Loss: 48.6724, Recon: 0.6671, KL: 48.0039, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6747, Val Loss: 48.6721, Recon: 0.6708, KL: 48.0039, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6730, Val Loss: 48.6757, Recon: 0.6695, KL: 48.0035, KL_weight: 4.8000
Saved model 52 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_51.pt
Training bootstrap model 53/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9568, Val Loss: 0.7290, Recon: 0.9568, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6927, Val Loss: 4.6424, Recon: 0.8273, KL: 3.8654, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4521, Val Loss: 9.4098, Recon: 0.7938, KL: 8.6584, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2393, Val Loss: 14.1932, Recon: 0.7846, KL: 13.4548, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0152, Val Loss: 18.9866, Recon: 0.7660, KL: 18.2492, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8114, Val Loss: 23.7859, Recon: 0.7618, KL: 23.0496, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6192, Val Loss: 28.6017, Recon: 0.7665, KL: 27.8527, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4076, Val Loss: 33.3773, Recon: 0.7610, KL: 32.6466, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2058, Val Loss: 38.1856, Recon: 0.7568, KL: 37.4490, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0436, Val Loss: 42.9887, Recon: 0.7855, KL: 42.2580, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8071, Val Loss: 47.7994, Recon: 0.7596, KL: 47.0475, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7504, Val Loss: 48.7316, Recon: 0.7445, KL: 48.0059, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7488, Val Loss: 48.7558, Recon: 0.7447, KL: 48.0040, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7427, Val Loss: 48.7229, Recon: 0.7401, KL: 48.0026, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7501, Val Loss: 48.7435, Recon: 0.7424, KL: 48.0077, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7569, Val Loss: 48.7279, Recon: 0.7483, KL: 48.0086, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7479, Val Loss: 48.7269, Recon: 0.7420, KL: 48.0059, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7385, Val Loss: 48.7063, Recon: 0.7351, KL: 48.0034, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7297, Val Loss: 48.7352, Recon: 0.7273, KL: 48.0025, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7368, Val Loss: 48.7396, Recon: 0.7325, KL: 48.0043, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7266, Val Loss: 48.7183, Recon: 0.7248, KL: 48.0018, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7322, Val Loss: 48.7310, Recon: 0.7287, KL: 48.0035, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7337, Val Loss: 48.7065, Recon: 0.7290, KL: 48.0046, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7555, Val Loss: 48.7652, Recon: 0.7457, KL: 48.0098, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7239, Val Loss: 48.7091, Recon: 0.7213, KL: 48.0027, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7339, Val Loss: 48.7246, Recon: 0.7248, KL: 48.0091, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7287, Val Loss: 48.7309, Recon: 0.7256, KL: 48.0031, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7280, Val Loss: 48.7220, Recon: 0.7230, KL: 48.0049, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7225, Val Loss: 48.7079, Recon: 0.7184, KL: 48.0040, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7278, Val Loss: 48.7029, Recon: 0.7202, KL: 48.0076, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7168, Val Loss: 48.7314, Recon: 0.7113, KL: 48.0055, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7146, Val Loss: 48.7215, Recon: 0.7101, KL: 48.0045, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7117, Val Loss: 48.7050, Recon: 0.7055, KL: 48.0062, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7112, Val Loss: 48.6952, Recon: 0.7067, KL: 48.0045, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7191, Val Loss: 48.6989, Recon: 0.7119, KL: 48.0072, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7024, Val Loss: 48.7071, Recon: 0.7004, KL: 48.0020, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7118, Val Loss: 48.6952, Recon: 0.7037, KL: 48.0081, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7056, Val Loss: 48.6830, Recon: 0.7026, KL: 48.0030, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6982, Val Loss: 48.6894, Recon: 0.6955, KL: 48.0027, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6984, Val Loss: 48.6994, Recon: 0.6943, KL: 48.0042, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7118, Val Loss: 48.6959, Recon: 0.7090, KL: 48.0028, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7023, Val Loss: 48.6887, Recon: 0.6986, KL: 48.0037, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6903, Val Loss: 48.7006, Recon: 0.6868, KL: 48.0035, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6936, Val Loss: 48.6827, Recon: 0.6918, KL: 48.0018, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7073, Val Loss: 48.6867, Recon: 0.7032, KL: 48.0041, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6935, Val Loss: 48.7050, Recon: 0.6904, KL: 48.0031, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6946, Val Loss: 48.6979, Recon: 0.6888, KL: 48.0058, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6915, Val Loss: 48.6927, Recon: 0.6866, KL: 48.0048, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6911, Val Loss: 48.6725, Recon: 0.6864, KL: 48.0047, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6949, Val Loss: 48.6818, Recon: 0.6869, KL: 48.0080, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6874, Val Loss: 48.6912, Recon: 0.6814, KL: 48.0060, KL_weight: 4.8000
Saved model 53 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_52.pt
Training bootstrap model 54/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9483, Val Loss: 0.7155, Recon: 0.9483, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6999, Val Loss: 4.6409, Recon: 0.8301, KL: 3.8698, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4445, Val Loss: 9.4105, Recon: 0.7885, KL: 8.6560, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2316, Val Loss: 14.2001, Recon: 0.7816, KL: 13.4500, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0242, Val Loss: 18.9942, Recon: 0.7772, KL: 18.2469, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8302, Val Loss: 23.8094, Recon: 0.7728, KL: 23.0574, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6122, Val Loss: 28.5842, Recon: 0.7653, KL: 27.8469, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4129, Val Loss: 33.3760, Recon: 0.7662, KL: 32.6466, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2159, Val Loss: 38.1710, Recon: 0.7660, KL: 37.4499, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0037, Val Loss: 42.9745, Recon: 0.7553, KL: 42.2484, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7906, Val Loss: 47.7896, Recon: 0.7453, KL: 47.0454, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7566, Val Loss: 48.7408, Recon: 0.7511, KL: 48.0054, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7685, Val Loss: 48.7453, Recon: 0.7569, KL: 48.0116, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7579, Val Loss: 48.7317, Recon: 0.7544, KL: 48.0036, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7386, Val Loss: 48.7580, Recon: 0.7348, KL: 48.0037, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7489, Val Loss: 48.7188, Recon: 0.7441, KL: 48.0049, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7514, Val Loss: 48.7336, Recon: 0.7445, KL: 48.0069, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7331, Val Loss: 48.7197, Recon: 0.7296, KL: 48.0035, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7558, Val Loss: 48.7354, Recon: 0.7480, KL: 48.0078, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7387, Val Loss: 48.7446, Recon: 0.7310, KL: 48.0077, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7255, Val Loss: 48.7164, Recon: 0.7236, KL: 48.0019, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7352, Val Loss: 48.7186, Recon: 0.7314, KL: 48.0039, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7281, Val Loss: 48.7260, Recon: 0.7230, KL: 48.0051, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7271, Val Loss: 48.7120, Recon: 0.7240, KL: 48.0031, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7374, Val Loss: 48.7074, Recon: 0.7326, KL: 48.0048, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7227, Val Loss: 48.7074, Recon: 0.7207, KL: 48.0020, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7297, Val Loss: 48.7134, Recon: 0.7278, KL: 48.0019, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7224, Val Loss: 48.7261, Recon: 0.7197, KL: 48.0027, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7215, Val Loss: 48.7140, Recon: 0.7195, KL: 48.0020, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7295, Val Loss: 48.7190, Recon: 0.7262, KL: 48.0033, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7328, Val Loss: 48.7183, Recon: 0.7272, KL: 48.0056, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7261, Val Loss: 48.7342, Recon: 0.7181, KL: 48.0080, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7265, Val Loss: 48.7078, Recon: 0.7224, KL: 48.0041, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7154, Val Loss: 48.7066, Recon: 0.7133, KL: 48.0022, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7217, Val Loss: 48.7097, Recon: 0.7165, KL: 48.0053, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7142, Val Loss: 48.7011, Recon: 0.7124, KL: 48.0018, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7159, Val Loss: 48.7076, Recon: 0.7123, KL: 48.0036, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7195, Val Loss: 48.7133, Recon: 0.7170, KL: 48.0026, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7206, Val Loss: 48.7060, Recon: 0.7173, KL: 48.0033, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7170, Val Loss: 48.7031, Recon: 0.7145, KL: 48.0025, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7162, Val Loss: 48.7034, Recon: 0.7142, KL: 48.0020, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7180, Val Loss: 48.6978, Recon: 0.7129, KL: 48.0050, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7091, Val Loss: 48.7165, Recon: 0.7074, KL: 48.0017, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7159, Val Loss: 48.7032, Recon: 0.7147, KL: 48.0012, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7162, Val Loss: 48.7104, Recon: 0.7140, KL: 48.0022, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7107, Val Loss: 48.7043, Recon: 0.7072, KL: 48.0036, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7143, Val Loss: 48.6990, Recon: 0.7120, KL: 48.0023, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7124, Val Loss: 48.7024, Recon: 0.7103, KL: 48.0021, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7433, Val Loss: 48.7191, Recon: 0.7235, KL: 48.0198, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7139, Val Loss: 48.7062, Recon: 0.7114, KL: 48.0024, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.7202, Val Loss: 48.6957, Recon: 0.7166, KL: 48.0036, KL_weight: 4.8000
Saved model 54 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_53.pt
Training bootstrap model 55/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9727, Val Loss: 0.7307, Recon: 0.9727, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6841, Val Loss: 4.6240, Recon: 0.8171, KL: 3.8669, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4564, Val Loss: 9.4241, Recon: 0.7979, KL: 8.6585, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2391, Val Loss: 14.2194, Recon: 0.7826, KL: 13.4565, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0323, Val Loss: 19.0306, Recon: 0.7721, KL: 18.2602, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8118, Val Loss: 23.7866, Recon: 0.7607, KL: 23.0511, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6269, Val Loss: 28.5879, Recon: 0.7699, KL: 27.8571, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4073, Val Loss: 33.3810, Recon: 0.7576, KL: 32.6497, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1984, Val Loss: 38.1788, Recon: 0.7501, KL: 37.4484, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0027, Val Loss: 43.0133, Recon: 0.7533, KL: 42.2494, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7902, Val Loss: 47.7647, Recon: 0.7410, KL: 47.0492, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7669, Val Loss: 48.7432, Recon: 0.7570, KL: 48.0099, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7480, Val Loss: 48.7348, Recon: 0.7419, KL: 48.0060, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7522, Val Loss: 48.7276, Recon: 0.7434, KL: 48.0088, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7484, Val Loss: 48.7238, Recon: 0.7422, KL: 48.0062, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7427, Val Loss: 48.7341, Recon: 0.7386, KL: 48.0042, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7380, Val Loss: 48.7265, Recon: 0.7347, KL: 48.0033, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7325, Val Loss: 48.7188, Recon: 0.7260, KL: 48.0064, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7360, Val Loss: 48.7087, Recon: 0.7312, KL: 48.0048, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7162, Val Loss: 48.7152, Recon: 0.7125, KL: 48.0037, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7234, Val Loss: 48.7193, Recon: 0.7187, KL: 48.0047, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7106, Val Loss: 48.7205, Recon: 0.7080, KL: 48.0026, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7137, Val Loss: 48.7135, Recon: 0.7094, KL: 48.0043, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7086, Val Loss: 48.7119, Recon: 0.7059, KL: 48.0027, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7295, Val Loss: 48.7092, Recon: 0.7235, KL: 48.0060, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7212, Val Loss: 48.7119, Recon: 0.7147, KL: 48.0065, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7232, Val Loss: 48.7206, Recon: 0.7130, KL: 48.0102, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7189, Val Loss: 48.7079, Recon: 0.7105, KL: 48.0085, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7180, Val Loss: 48.7003, Recon: 0.7058, KL: 48.0122, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7159, Val Loss: 48.7029, Recon: 0.7110, KL: 48.0048, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7040, Val Loss: 48.6961, Recon: 0.6992, KL: 48.0049, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6969, Val Loss: 48.6946, Recon: 0.6916, KL: 48.0053, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6968, Val Loss: 48.6929, Recon: 0.6940, KL: 48.0027, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7005, Val Loss: 48.6910, Recon: 0.6978, KL: 48.0027, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6964, Val Loss: 48.7144, Recon: 0.6901, KL: 48.0063, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6944, Val Loss: 48.6999, Recon: 0.6911, KL: 48.0033, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6996, Val Loss: 48.6978, Recon: 0.6938, KL: 48.0058, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6932, Val Loss: 48.6930, Recon: 0.6896, KL: 48.0035, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6988, Val Loss: 48.7031, Recon: 0.6944, KL: 48.0043, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6954, Val Loss: 48.6794, Recon: 0.6917, KL: 48.0037, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6883, Val Loss: 48.6887, Recon: 0.6849, KL: 48.0034, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7304, Val Loss: 48.7049, Recon: 0.7191, KL: 48.0113, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6875, Val Loss: 48.6804, Recon: 0.6853, KL: 48.0022, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6952, Val Loss: 48.6975, Recon: 0.6885, KL: 48.0067, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6878, Val Loss: 48.6761, Recon: 0.6848, KL: 48.0030, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6810, Val Loss: 48.6854, Recon: 0.6794, KL: 48.0016, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6797, Val Loss: 48.6869, Recon: 0.6768, KL: 48.0029, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6799, Val Loss: 48.6894, Recon: 0.6769, KL: 48.0031, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6861, Val Loss: 48.6721, Recon: 0.6796, KL: 48.0065, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6849, Val Loss: 48.6754, Recon: 0.6816, KL: 48.0033, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.7003, Val Loss: 48.6875, Recon: 0.6885, KL: 48.0118, KL_weight: 4.8000
Saved model 55 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_54.pt
Training bootstrap model 56/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9552, Val Loss: 0.7166, Recon: 0.9552, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6786, Val Loss: 4.6396, Recon: 0.8076, KL: 3.8711, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4504, Val Loss: 9.4297, Recon: 0.7933, KL: 8.6571, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2240, Val Loss: 14.1932, Recon: 0.7748, KL: 13.4492, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0353, Val Loss: 19.0144, Recon: 0.7761, KL: 18.2592, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8185, Val Loss: 23.7853, Recon: 0.7686, KL: 23.0499, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6195, Val Loss: 28.5922, Recon: 0.7648, KL: 27.8547, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4000, Val Loss: 33.3975, Recon: 0.7503, KL: 32.6498, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1839, Val Loss: 38.1733, Recon: 0.7400, KL: 37.4439, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9913, Val Loss: 42.9859, Recon: 0.7423, KL: 42.2490, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7926, Val Loss: 47.7816, Recon: 0.7468, KL: 47.0458, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7502, Val Loss: 48.7224, Recon: 0.7452, KL: 48.0051, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7574, Val Loss: 48.7353, Recon: 0.7547, KL: 48.0027, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7529, Val Loss: 48.7240, Recon: 0.7448, KL: 48.0081, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7326, Val Loss: 48.7153, Recon: 0.7288, KL: 48.0038, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7545, Val Loss: 48.7366, Recon: 0.7418, KL: 48.0127, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7354, Val Loss: 48.7400, Recon: 0.7316, KL: 48.0037, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7352, Val Loss: 48.7463, Recon: 0.7290, KL: 48.0062, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7231, Val Loss: 48.7184, Recon: 0.7201, KL: 48.0030, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7355, Val Loss: 48.7278, Recon: 0.7288, KL: 48.0066, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7225, Val Loss: 48.7266, Recon: 0.7195, KL: 48.0030, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7245, Val Loss: 48.7254, Recon: 0.7195, KL: 48.0049, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7304, Val Loss: 48.7138, Recon: 0.7235, KL: 48.0070, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7175, Val Loss: 48.7217, Recon: 0.7125, KL: 48.0050, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7175, Val Loss: 48.7074, Recon: 0.7148, KL: 48.0028, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7187, Val Loss: 48.7111, Recon: 0.7160, KL: 48.0028, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7262, Val Loss: 48.7060, Recon: 0.7238, KL: 48.0024, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7148, Val Loss: 48.7018, Recon: 0.7137, KL: 48.0011, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7177, Val Loss: 48.7219, Recon: 0.7151, KL: 48.0027, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7260, Val Loss: 48.7177, Recon: 0.7215, KL: 48.0045, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7141, Val Loss: 48.7040, Recon: 0.7114, KL: 48.0027, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7083, Val Loss: 48.7037, Recon: 0.7067, KL: 48.0015, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7213, Val Loss: 48.7387, Recon: 0.7187, KL: 48.0026, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7188, Val Loss: 48.6993, Recon: 0.7136, KL: 48.0052, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7081, Val Loss: 48.6957, Recon: 0.7063, KL: 48.0017, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7319, Val Loss: 48.7293, Recon: 0.7259, KL: 48.0061, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7101, Val Loss: 48.7063, Recon: 0.7084, KL: 48.0017, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7056, Val Loss: 48.7046, Recon: 0.7042, KL: 48.0014, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7075, Val Loss: 48.7078, Recon: 0.7061, KL: 48.0014, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7094, Val Loss: 48.7006, Recon: 0.7072, KL: 48.0022, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7179, Val Loss: 48.7098, Recon: 0.7129, KL: 48.0050, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7120, Val Loss: 48.7180, Recon: 0.7089, KL: 48.0031, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7112, Val Loss: 48.7021, Recon: 0.7095, KL: 48.0017, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7110, Val Loss: 48.7085, Recon: 0.7048, KL: 48.0062, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7057, Val Loss: 48.6964, Recon: 0.7042, KL: 48.0015, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7090, Val Loss: 48.7254, Recon: 0.7076, KL: 48.0014, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7137, Val Loss: 48.7087, Recon: 0.7085, KL: 48.0052, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7084, Val Loss: 48.6966, Recon: 0.7070, KL: 48.0015, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7136, Val Loss: 48.7036, Recon: 0.7105, KL: 48.0031, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7131, Val Loss: 48.7113, Recon: 0.7077, KL: 48.0054, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.7130, Val Loss: 48.7091, Recon: 0.7029, KL: 48.0101, KL_weight: 4.8000
Saved model 56 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_55.pt
Training bootstrap model 57/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 1.0072, Val Loss: 0.7848, Recon: 1.0072, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7102, Val Loss: 4.6342, Recon: 0.8377, KL: 3.8725, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4724, Val Loss: 9.4244, Recon: 0.8090, KL: 8.6634, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2455, Val Loss: 14.2101, Recon: 0.7912, KL: 13.4543, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0359, Val Loss: 18.9925, Recon: 0.7834, KL: 18.2525, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8268, Val Loss: 23.7821, Recon: 0.7745, KL: 23.0523, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6090, Val Loss: 28.5767, Recon: 0.7635, KL: 27.8455, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4125, Val Loss: 33.4084, Recon: 0.7623, KL: 32.6502, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2148, Val Loss: 38.1948, Recon: 0.7670, KL: 37.4478, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0241, Val Loss: 42.9751, Recon: 0.7667, KL: 42.2574, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7991, Val Loss: 47.7664, Recon: 0.7519, KL: 47.0473, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7532, Val Loss: 48.7260, Recon: 0.7481, KL: 48.0051, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7605, Val Loss: 48.7358, Recon: 0.7534, KL: 48.0071, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7650, Val Loss: 48.7477, Recon: 0.7563, KL: 48.0087, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7573, Val Loss: 48.7503, Recon: 0.7507, KL: 48.0066, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7510, Val Loss: 48.7379, Recon: 0.7414, KL: 48.0097, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7431, Val Loss: 48.7166, Recon: 0.7365, KL: 48.0066, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7348, Val Loss: 48.6960, Recon: 0.7315, KL: 48.0033, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7427, Val Loss: 48.7121, Recon: 0.7361, KL: 48.0066, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7232, Val Loss: 48.7114, Recon: 0.7193, KL: 48.0040, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7358, Val Loss: 48.7051, Recon: 0.7282, KL: 48.0076, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7158, Val Loss: 48.7048, Recon: 0.7133, KL: 48.0026, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7271, Val Loss: 48.6930, Recon: 0.7226, KL: 48.0045, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7350, Val Loss: 48.7056, Recon: 0.7290, KL: 48.0060, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7104, Val Loss: 48.6984, Recon: 0.7060, KL: 48.0044, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7170, Val Loss: 48.6875, Recon: 0.7146, KL: 48.0024, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7165, Val Loss: 48.6883, Recon: 0.7122, KL: 48.0043, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7131, Val Loss: 48.6989, Recon: 0.7059, KL: 48.0072, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7202, Val Loss: 48.6983, Recon: 0.7126, KL: 48.0076, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7179, Val Loss: 48.6973, Recon: 0.7115, KL: 48.0064, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7142, Val Loss: 48.7078, Recon: 0.7096, KL: 48.0045, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7214, Val Loss: 48.7015, Recon: 0.7168, KL: 48.0046, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7115, Val Loss: 48.6970, Recon: 0.7055, KL: 48.0060, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7139, Val Loss: 48.6968, Recon: 0.7088, KL: 48.0051, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7067, Val Loss: 48.6933, Recon: 0.7017, KL: 48.0050, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7104, Val Loss: 48.6880, Recon: 0.7054, KL: 48.0051, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7133, Val Loss: 48.6901, Recon: 0.7094, KL: 48.0039, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6966, Val Loss: 48.7044, Recon: 0.6930, KL: 48.0035, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7035, Val Loss: 48.6902, Recon: 0.7014, KL: 48.0021, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7007, Val Loss: 48.6906, Recon: 0.6957, KL: 48.0050, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6983, Val Loss: 48.6753, Recon: 0.6910, KL: 48.0073, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7077, Val Loss: 48.7061, Recon: 0.7040, KL: 48.0037, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7036, Val Loss: 48.6805, Recon: 0.6992, KL: 48.0044, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7196, Val Loss: 48.6869, Recon: 0.7081, KL: 48.0115, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7103, Val Loss: 48.6801, Recon: 0.7048, KL: 48.0055, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7019, Val Loss: 48.6815, Recon: 0.6978, KL: 48.0041, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6982, Val Loss: 48.6889, Recon: 0.6927, KL: 48.0055, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7008, Val Loss: 48.6805, Recon: 0.6945, KL: 48.0064, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6877, Val Loss: 48.6696, Recon: 0.6851, KL: 48.0026, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6865, Val Loss: 48.6720, Recon: 0.6820, KL: 48.0045, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.7052, Val Loss: 48.6840, Recon: 0.6905, KL: 48.0147, KL_weight: 4.8000
Saved model 57 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_56.pt
Training bootstrap model 58/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9390, Val Loss: 0.7296, Recon: 0.9390, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6843, Val Loss: 4.6529, Recon: 0.8159, KL: 3.8684, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4624, Val Loss: 9.4263, Recon: 0.7999, KL: 8.6625, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2223, Val Loss: 14.2092, Recon: 0.7684, KL: 13.4539, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0128, Val Loss: 19.0223, Recon: 0.7594, KL: 18.2534, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8027, Val Loss: 23.7985, Recon: 0.7524, KL: 23.0503, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.5849, Val Loss: 28.5675, Recon: 0.7381, KL: 27.8467, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3874, Val Loss: 33.3790, Recon: 0.7414, KL: 32.6460, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1708, Val Loss: 38.1649, Recon: 0.7253, KL: 37.4455, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9939, Val Loss: 42.9814, Recon: 0.7462, KL: 42.2477, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7788, Val Loss: 47.7769, Recon: 0.7318, KL: 47.0469, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7363, Val Loss: 48.7233, Recon: 0.7332, KL: 48.0031, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7682, Val Loss: 48.7530, Recon: 0.7575, KL: 48.0107, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7336, Val Loss: 48.7248, Recon: 0.7288, KL: 48.0048, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7293, Val Loss: 48.7401, Recon: 0.7238, KL: 48.0055, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7210, Val Loss: 48.7368, Recon: 0.7162, KL: 48.0048, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7280, Val Loss: 48.7315, Recon: 0.7217, KL: 48.0064, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7222, Val Loss: 48.7334, Recon: 0.7176, KL: 48.0046, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7194, Val Loss: 48.7225, Recon: 0.7151, KL: 48.0043, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7210, Val Loss: 48.7240, Recon: 0.7181, KL: 48.0029, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7254, Val Loss: 48.7220, Recon: 0.7122, KL: 48.0132, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7195, Val Loss: 48.7296, Recon: 0.7148, KL: 48.0047, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7783, Val Loss: 48.7540, Recon: 0.7265, KL: 48.0517, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7166, Val Loss: 48.7336, Recon: 0.7126, KL: 48.0039, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7197, Val Loss: 48.7078, Recon: 0.7127, KL: 48.0070, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7179, Val Loss: 48.7176, Recon: 0.7135, KL: 48.0044, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7062, Val Loss: 48.7045, Recon: 0.7020, KL: 48.0042, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.6931, Val Loss: 48.6995, Recon: 0.6909, KL: 48.0022, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7019, Val Loss: 48.7067, Recon: 0.6972, KL: 48.0047, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7098, Val Loss: 48.7006, Recon: 0.7031, KL: 48.0067, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7023, Val Loss: 48.6913, Recon: 0.6983, KL: 48.0040, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6922, Val Loss: 48.6871, Recon: 0.6903, KL: 48.0019, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6923, Val Loss: 48.6917, Recon: 0.6871, KL: 48.0052, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6930, Val Loss: 48.6956, Recon: 0.6892, KL: 48.0038, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6920, Val Loss: 48.6985, Recon: 0.6883, KL: 48.0036, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6876, Val Loss: 48.6836, Recon: 0.6850, KL: 48.0026, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6789, Val Loss: 48.6856, Recon: 0.6754, KL: 48.0035, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6797, Val Loss: 48.6787, Recon: 0.6773, KL: 48.0024, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6894, Val Loss: 48.6892, Recon: 0.6858, KL: 48.0036, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7066, Val Loss: 48.7032, Recon: 0.6967, KL: 48.0099, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6808, Val Loss: 48.6859, Recon: 0.6779, KL: 48.0029, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6816, Val Loss: 48.6854, Recon: 0.6774, KL: 48.0042, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6827, Val Loss: 48.6913, Recon: 0.6803, KL: 48.0023, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6811, Val Loss: 48.6832, Recon: 0.6779, KL: 48.0032, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6802, Val Loss: 48.6712, Recon: 0.6775, KL: 48.0027, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6720, Val Loss: 48.6717, Recon: 0.6692, KL: 48.0028, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6782, Val Loss: 48.6744, Recon: 0.6746, KL: 48.0036, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6727, Val Loss: 48.6716, Recon: 0.6701, KL: 48.0025, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6842, Val Loss: 48.6821, Recon: 0.6794, KL: 48.0048, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6895, Val Loss: 48.6747, Recon: 0.6838, KL: 48.0057, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6939, Val Loss: 48.6901, Recon: 0.6848, KL: 48.0090, KL_weight: 4.8000
Saved model 58 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_57.pt
Training bootstrap model 59/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9684, Val Loss: 0.7293, Recon: 0.9684, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7146, Val Loss: 4.6456, Recon: 0.8399, KL: 3.8747, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4561, Val Loss: 9.4199, Recon: 0.7959, KL: 8.6603, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2245, Val Loss: 14.1890, Recon: 0.7767, KL: 13.4478, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0258, Val Loss: 19.0011, Recon: 0.7730, KL: 18.2528, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8088, Val Loss: 23.7982, Recon: 0.7612, KL: 23.0476, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6153, Val Loss: 28.6132, Recon: 0.7664, KL: 27.8489, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3990, Val Loss: 33.3947, Recon: 0.7505, KL: 32.6484, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2213, Val Loss: 38.2482, Recon: 0.7705, KL: 37.4507, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9977, Val Loss: 42.9799, Recon: 0.7518, KL: 42.2459, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7965, Val Loss: 47.7837, Recon: 0.7498, KL: 47.0467, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7596, Val Loss: 48.7326, Recon: 0.7531, KL: 48.0064, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7604, Val Loss: 48.7226, Recon: 0.7558, KL: 48.0046, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7433, Val Loss: 48.7427, Recon: 0.7399, KL: 48.0034, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7453, Val Loss: 48.7296, Recon: 0.7398, KL: 48.0055, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7311, Val Loss: 48.7133, Recon: 0.7282, KL: 48.0029, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7549, Val Loss: 48.7201, Recon: 0.7467, KL: 48.0082, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7385, Val Loss: 48.7217, Recon: 0.7325, KL: 48.0059, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7303, Val Loss: 48.7181, Recon: 0.7286, KL: 48.0017, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7342, Val Loss: 48.7375, Recon: 0.7282, KL: 48.0061, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7391, Val Loss: 48.7360, Recon: 0.7317, KL: 48.0074, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7254, Val Loss: 48.7225, Recon: 0.7165, KL: 48.0089, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7281, Val Loss: 48.7212, Recon: 0.7220, KL: 48.0061, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7483, Val Loss: 48.7183, Recon: 0.7391, KL: 48.0091, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7309, Val Loss: 48.7247, Recon: 0.7260, KL: 48.0049, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7186, Val Loss: 48.7060, Recon: 0.7169, KL: 48.0018, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7287, Val Loss: 48.7141, Recon: 0.7205, KL: 48.0083, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7183, Val Loss: 48.7085, Recon: 0.7162, KL: 48.0021, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7124, Val Loss: 48.7034, Recon: 0.7105, KL: 48.0019, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7184, Val Loss: 48.7054, Recon: 0.7175, KL: 48.0009, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7157, Val Loss: 48.7129, Recon: 0.7129, KL: 48.0028, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7098, Val Loss: 48.7082, Recon: 0.7073, KL: 48.0026, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7169, Val Loss: 48.7115, Recon: 0.7136, KL: 48.0033, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7198, Val Loss: 48.7055, Recon: 0.7182, KL: 48.0017, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7133, Val Loss: 48.7067, Recon: 0.7094, KL: 48.0040, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7234, Val Loss: 48.7021, Recon: 0.7221, KL: 48.0013, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7195, Val Loss: 48.7160, Recon: 0.7132, KL: 48.0063, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7202, Val Loss: 48.7028, Recon: 0.7169, KL: 48.0033, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7139, Val Loss: 48.7093, Recon: 0.7107, KL: 48.0032, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7152, Val Loss: 48.7058, Recon: 0.7133, KL: 48.0019, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7071, Val Loss: 48.7042, Recon: 0.7047, KL: 48.0023, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7081, Val Loss: 48.7027, Recon: 0.7068, KL: 48.0013, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7172, Val Loss: 48.7005, Recon: 0.7127, KL: 48.0045, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7070, Val Loss: 48.6979, Recon: 0.7042, KL: 48.0028, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7018, Val Loss: 48.6928, Recon: 0.6978, KL: 48.0039, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7126, Val Loss: 48.7054, Recon: 0.7105, KL: 48.0021, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7061, Val Loss: 48.7063, Recon: 0.7040, KL: 48.0021, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7064, Val Loss: 48.7107, Recon: 0.7026, KL: 48.0038, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7109, Val Loss: 48.7018, Recon: 0.7094, KL: 48.0015, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7046, Val Loss: 48.7053, Recon: 0.7019, KL: 48.0027, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.7081, Val Loss: 48.6960, Recon: 0.7053, KL: 48.0028, KL_weight: 4.8000
Saved model 59 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_58.pt
Training bootstrap model 60/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9385, Val Loss: 0.7048, Recon: 0.9385, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6902, Val Loss: 4.6372, Recon: 0.8193, KL: 3.8709, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4554, Val Loss: 9.4285, Recon: 0.7990, KL: 8.6564, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2422, Val Loss: 14.2087, Recon: 0.7844, KL: 13.4578, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0162, Val Loss: 19.0039, Recon: 0.7660, KL: 18.2502, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8096, Val Loss: 23.8044, Recon: 0.7607, KL: 23.0488, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6008, Val Loss: 28.5860, Recon: 0.7532, KL: 27.8476, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4006, Val Loss: 33.3726, Recon: 0.7544, KL: 32.6462, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2120, Val Loss: 38.1790, Recon: 0.7624, KL: 37.4496, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0233, Val Loss: 42.9765, Recon: 0.7642, KL: 42.2591, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8188, Val Loss: 47.8001, Recon: 0.7568, KL: 47.0619, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7551, Val Loss: 48.7260, Recon: 0.7486, KL: 48.0065, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7415, Val Loss: 48.7507, Recon: 0.7377, KL: 48.0038, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7566, Val Loss: 48.7336, Recon: 0.7455, KL: 48.0111, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7446, Val Loss: 48.7471, Recon: 0.7397, KL: 48.0049, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7420, Val Loss: 48.7319, Recon: 0.7372, KL: 48.0048, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7434, Val Loss: 48.7296, Recon: 0.7366, KL: 48.0068, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7297, Val Loss: 48.7273, Recon: 0.7270, KL: 48.0027, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7216, Val Loss: 48.7220, Recon: 0.7183, KL: 48.0033, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7254, Val Loss: 48.7040, Recon: 0.7221, KL: 48.0033, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7233, Val Loss: 48.7219, Recon: 0.7194, KL: 48.0039, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7257, Val Loss: 48.7161, Recon: 0.7209, KL: 48.0048, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7293, Val Loss: 48.7279, Recon: 0.7224, KL: 48.0069, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7360, Val Loss: 48.7182, Recon: 0.7263, KL: 48.0097, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7220, Val Loss: 48.7010, Recon: 0.7168, KL: 48.0052, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7171, Val Loss: 48.7136, Recon: 0.7137, KL: 48.0034, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7212, Val Loss: 48.7189, Recon: 0.7167, KL: 48.0044, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7199, Val Loss: 48.7006, Recon: 0.7151, KL: 48.0048, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7052, Val Loss: 48.7092, Recon: 0.7028, KL: 48.0024, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7001, Val Loss: 48.7078, Recon: 0.6970, KL: 48.0030, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7115, Val Loss: 48.7117, Recon: 0.7044, KL: 48.0072, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6987, Val Loss: 48.6999, Recon: 0.6955, KL: 48.0033, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7266, Val Loss: 48.7081, Recon: 0.7167, KL: 48.0099, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7020, Val Loss: 48.7060, Recon: 0.6983, KL: 48.0038, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7029, Val Loss: 48.7123, Recon: 0.6946, KL: 48.0083, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6962, Val Loss: 48.6940, Recon: 0.6926, KL: 48.0036, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6975, Val Loss: 48.7019, Recon: 0.6921, KL: 48.0053, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6981, Val Loss: 48.6884, Recon: 0.6944, KL: 48.0037, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6886, Val Loss: 48.6776, Recon: 0.6850, KL: 48.0036, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6931, Val Loss: 48.6853, Recon: 0.6912, KL: 48.0018, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7032, Val Loss: 48.6934, Recon: 0.6988, KL: 48.0043, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6889, Val Loss: 48.6828, Recon: 0.6847, KL: 48.0043, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6863, Val Loss: 48.6907, Recon: 0.6835, KL: 48.0028, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6829, Val Loss: 48.6865, Recon: 0.6801, KL: 48.0027, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6807, Val Loss: 48.6799, Recon: 0.6793, KL: 48.0014, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6825, Val Loss: 48.6809, Recon: 0.6794, KL: 48.0031, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6850, Val Loss: 48.6869, Recon: 0.6829, KL: 48.0021, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6862, Val Loss: 48.6766, Recon: 0.6819, KL: 48.0043, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6784, Val Loss: 48.6819, Recon: 0.6761, KL: 48.0023, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6805, Val Loss: 48.6944, Recon: 0.6777, KL: 48.0028, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6858, Val Loss: 48.6834, Recon: 0.6820, KL: 48.0039, KL_weight: 4.8000
Saved model 60 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_59.pt
Training bootstrap model 61/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9201, Val Loss: 0.7078, Recon: 0.9201, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6724, Val Loss: 4.6184, Recon: 0.8027, KL: 3.8697, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4319, Val Loss: 9.4253, Recon: 0.7765, KL: 8.6553, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2179, Val Loss: 14.1944, Recon: 0.7664, KL: 13.4515, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0070, Val Loss: 19.0018, Recon: 0.7510, KL: 18.2560, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8166, Val Loss: 23.7829, Recon: 0.7679, KL: 23.0487, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6053, Val Loss: 28.5887, Recon: 0.7545, KL: 27.8507, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3992, Val Loss: 33.3941, Recon: 0.7479, KL: 32.6513, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1950, Val Loss: 38.1760, Recon: 0.7475, KL: 37.4475, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9835, Val Loss: 42.9788, Recon: 0.7365, KL: 42.2470, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7967, Val Loss: 47.7921, Recon: 0.7400, KL: 47.0568, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7857, Val Loss: 48.7602, Recon: 0.7662, KL: 48.0195, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7540, Val Loss: 48.7354, Recon: 0.7490, KL: 48.0050, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7692, Val Loss: 48.7315, Recon: 0.7564, KL: 48.0128, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7367, Val Loss: 48.7299, Recon: 0.7308, KL: 48.0059, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7304, Val Loss: 48.7196, Recon: 0.7258, KL: 48.0046, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7339, Val Loss: 48.7360, Recon: 0.7302, KL: 48.0037, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7220, Val Loss: 48.7137, Recon: 0.7199, KL: 48.0021, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7221, Val Loss: 48.7031, Recon: 0.7186, KL: 48.0035, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7126, Val Loss: 48.7126, Recon: 0.7085, KL: 48.0042, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7468, Val Loss: 48.7274, Recon: 0.7405, KL: 48.0063, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7270, Val Loss: 48.7187, Recon: 0.7231, KL: 48.0039, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7233, Val Loss: 48.7174, Recon: 0.7198, KL: 48.0036, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7270, Val Loss: 48.7172, Recon: 0.7233, KL: 48.0037, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7149, Val Loss: 48.7168, Recon: 0.7126, KL: 48.0022, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7165, Val Loss: 48.7193, Recon: 0.7135, KL: 48.0030, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7204, Val Loss: 48.7128, Recon: 0.7177, KL: 48.0027, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7135, Val Loss: 48.7081, Recon: 0.7121, KL: 48.0014, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7200, Val Loss: 48.7133, Recon: 0.7157, KL: 48.0043, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7188, Val Loss: 48.7089, Recon: 0.7136, KL: 48.0052, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7077, Val Loss: 48.7170, Recon: 0.7049, KL: 48.0027, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7101, Val Loss: 48.7069, Recon: 0.7067, KL: 48.0034, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7130, Val Loss: 48.7023, Recon: 0.7073, KL: 48.0058, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7056, Val Loss: 48.6998, Recon: 0.7039, KL: 48.0016, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7056, Val Loss: 48.7094, Recon: 0.7023, KL: 48.0032, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7190, Val Loss: 48.7123, Recon: 0.7129, KL: 48.0061, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7159, Val Loss: 48.7090, Recon: 0.7143, KL: 48.0016, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6967, Val Loss: 48.7042, Recon: 0.6945, KL: 48.0022, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7020, Val Loss: 48.7050, Recon: 0.6999, KL: 48.0021, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7184, Val Loss: 48.7166, Recon: 0.7130, KL: 48.0054, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7109, Val Loss: 48.7176, Recon: 0.7036, KL: 48.0073, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6975, Val Loss: 48.6986, Recon: 0.6960, KL: 48.0015, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7216, Val Loss: 48.7094, Recon: 0.7118, KL: 48.0099, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7059, Val Loss: 48.6986, Recon: 0.7031, KL: 48.0028, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7018, Val Loss: 48.7040, Recon: 0.6986, KL: 48.0032, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6979, Val Loss: 48.7055, Recon: 0.6936, KL: 48.0043, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6905, Val Loss: 48.6925, Recon: 0.6885, KL: 48.0021, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7009, Val Loss: 48.7026, Recon: 0.6943, KL: 48.0066, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6992, Val Loss: 48.7124, Recon: 0.6907, KL: 48.0085, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6900, Val Loss: 48.6839, Recon: 0.6863, KL: 48.0038, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6829, Val Loss: 48.6874, Recon: 0.6789, KL: 48.0040, KL_weight: 4.8000
Saved model 61 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_60.pt
Training bootstrap model 62/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9523, Val Loss: 0.7172, Recon: 0.9523, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7081, Val Loss: 4.6452, Recon: 0.8337, KL: 3.8744, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4702, Val Loss: 9.4468, Recon: 0.8055, KL: 8.6648, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2490, Val Loss: 14.2115, Recon: 0.7911, KL: 13.4579, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0207, Val Loss: 18.9928, Recon: 0.7713, KL: 18.2494, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8182, Val Loss: 23.7975, Recon: 0.7683, KL: 23.0499, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6171, Val Loss: 28.5862, Recon: 0.7701, KL: 27.8470, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4366, Val Loss: 33.4117, Recon: 0.7758, KL: 32.6608, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2202, Val Loss: 38.1939, Recon: 0.7618, KL: 37.4583, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0435, Val Loss: 42.9906, Recon: 0.7758, KL: 42.2677, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8063, Val Loss: 47.7923, Recon: 0.7570, KL: 47.0493, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7508, Val Loss: 48.7242, Recon: 0.7461, KL: 48.0047, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7527, Val Loss: 48.7393, Recon: 0.7462, KL: 48.0065, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7531, Val Loss: 48.7334, Recon: 0.7489, KL: 48.0042, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7421, Val Loss: 48.7409, Recon: 0.7396, KL: 48.0025, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7459, Val Loss: 48.7286, Recon: 0.7428, KL: 48.0031, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7711, Val Loss: 48.7512, Recon: 0.7560, KL: 48.0151, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7369, Val Loss: 48.7231, Recon: 0.7329, KL: 48.0040, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7483, Val Loss: 48.7155, Recon: 0.7408, KL: 48.0075, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7441, Val Loss: 48.7096, Recon: 0.7415, KL: 48.0026, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7418, Val Loss: 48.7242, Recon: 0.7362, KL: 48.0055, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7367, Val Loss: 48.7203, Recon: 0.7320, KL: 48.0047, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7322, Val Loss: 48.7125, Recon: 0.7297, KL: 48.0025, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7349, Val Loss: 48.7425, Recon: 0.7333, KL: 48.0016, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7361, Val Loss: 48.7174, Recon: 0.7308, KL: 48.0054, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7277, Val Loss: 48.7145, Recon: 0.7253, KL: 48.0025, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7393, Val Loss: 48.7066, Recon: 0.7335, KL: 48.0058, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7545, Val Loss: 48.7221, Recon: 0.7456, KL: 48.0089, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7375, Val Loss: 48.7288, Recon: 0.7305, KL: 48.0070, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7259, Val Loss: 48.7050, Recon: 0.7206, KL: 48.0053, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7194, Val Loss: 48.7143, Recon: 0.7173, KL: 48.0022, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7244, Val Loss: 48.7185, Recon: 0.7211, KL: 48.0033, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7238, Val Loss: 48.7106, Recon: 0.7202, KL: 48.0036, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7224, Val Loss: 48.7068, Recon: 0.7201, KL: 48.0023, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7283, Val Loss: 48.7026, Recon: 0.7239, KL: 48.0045, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7348, Val Loss: 48.7169, Recon: 0.7328, KL: 48.0020, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7228, Val Loss: 48.7106, Recon: 0.7211, KL: 48.0017, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7283, Val Loss: 48.7029, Recon: 0.7230, KL: 48.0053, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7273, Val Loss: 48.7052, Recon: 0.7142, KL: 48.0131, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7238, Val Loss: 48.7052, Recon: 0.7200, KL: 48.0038, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7143, Val Loss: 48.7230, Recon: 0.7126, KL: 48.0016, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7289, Val Loss: 48.7033, Recon: 0.7220, KL: 48.0069, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7238, Val Loss: 48.7335, Recon: 0.7153, KL: 48.0085, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7198, Val Loss: 48.6933, Recon: 0.7180, KL: 48.0018, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7143, Val Loss: 48.6982, Recon: 0.7117, KL: 48.0026, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7185, Val Loss: 48.7023, Recon: 0.7118, KL: 48.0067, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7251, Val Loss: 48.7034, Recon: 0.7227, KL: 48.0024, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7133, Val Loss: 48.7076, Recon: 0.7111, KL: 48.0022, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7233, Val Loss: 48.7052, Recon: 0.7179, KL: 48.0054, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7223, Val Loss: 48.7264, Recon: 0.7161, KL: 48.0062, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.7153, Val Loss: 48.7071, Recon: 0.7133, KL: 48.0020, KL_weight: 4.8000
Saved model 62 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_61.pt
Training bootstrap model 63/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9203, Val Loss: 0.7136, Recon: 0.9203, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6872, Val Loss: 4.6308, Recon: 0.8145, KL: 3.8727, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4470, Val Loss: 9.4243, Recon: 0.7896, KL: 8.6575, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2297, Val Loss: 14.1989, Recon: 0.7751, KL: 13.4547, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0132, Val Loss: 18.9986, Recon: 0.7644, KL: 18.2487, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8070, Val Loss: 23.7902, Recon: 0.7569, KL: 23.0501, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6104, Val Loss: 28.5828, Recon: 0.7633, KL: 27.8471, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3868, Val Loss: 33.3803, Recon: 0.7425, KL: 32.6443, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1815, Val Loss: 38.1811, Recon: 0.7373, KL: 37.4442, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9751, Val Loss: 42.9700, Recon: 0.7305, KL: 42.2446, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7789, Val Loss: 47.7774, Recon: 0.7328, KL: 47.0461, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7456, Val Loss: 48.7434, Recon: 0.7414, KL: 48.0042, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7277, Val Loss: 48.7130, Recon: 0.7249, KL: 48.0028, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7382, Val Loss: 48.7608, Recon: 0.7319, KL: 48.0063, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7351, Val Loss: 48.7232, Recon: 0.7289, KL: 48.0062, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7352, Val Loss: 48.7237, Recon: 0.7328, KL: 48.0024, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7235, Val Loss: 48.7215, Recon: 0.7209, KL: 48.0026, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7274, Val Loss: 48.7404, Recon: 0.7229, KL: 48.0046, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7213, Val Loss: 48.7110, Recon: 0.7191, KL: 48.0022, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7209, Val Loss: 48.7110, Recon: 0.7176, KL: 48.0032, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7182, Val Loss: 48.7103, Recon: 0.7161, KL: 48.0021, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7047, Val Loss: 48.7102, Recon: 0.7025, KL: 48.0022, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7083, Val Loss: 48.7039, Recon: 0.7060, KL: 48.0023, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7148, Val Loss: 48.7088, Recon: 0.7131, KL: 48.0017, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7140, Val Loss: 48.7274, Recon: 0.7109, KL: 48.0031, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7090, Val Loss: 48.7303, Recon: 0.7069, KL: 48.0021, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7124, Val Loss: 48.7038, Recon: 0.7092, KL: 48.0032, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7147, Val Loss: 48.7099, Recon: 0.7064, KL: 48.0083, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7027, Val Loss: 48.7234, Recon: 0.6993, KL: 48.0033, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7078, Val Loss: 48.7005, Recon: 0.7046, KL: 48.0032, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7006, Val Loss: 48.7054, Recon: 0.6986, KL: 48.0021, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7115, Val Loss: 48.7148, Recon: 0.7069, KL: 48.0046, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7045, Val Loss: 48.6929, Recon: 0.7010, KL: 48.0035, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6948, Val Loss: 48.6894, Recon: 0.6933, KL: 48.0014, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6939, Val Loss: 48.6962, Recon: 0.6910, KL: 48.0029, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6934, Val Loss: 48.7054, Recon: 0.6896, KL: 48.0038, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6900, Val Loss: 48.6965, Recon: 0.6886, KL: 48.0014, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6874, Val Loss: 48.6878, Recon: 0.6840, KL: 48.0034, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6840, Val Loss: 48.6982, Recon: 0.6811, KL: 48.0030, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7127, Val Loss: 48.7170, Recon: 0.7052, KL: 48.0074, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7022, Val Loss: 48.6957, Recon: 0.6998, KL: 48.0024, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7017, Val Loss: 48.7109, Recon: 0.6877, KL: 48.0140, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6881, Val Loss: 48.6977, Recon: 0.6857, KL: 48.0024, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6832, Val Loss: 48.7119, Recon: 0.6801, KL: 48.0031, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6931, Val Loss: 48.6946, Recon: 0.6878, KL: 48.0053, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6803, Val Loss: 48.6876, Recon: 0.6786, KL: 48.0017, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6833, Val Loss: 48.6908, Recon: 0.6799, KL: 48.0035, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6820, Val Loss: 48.6848, Recon: 0.6797, KL: 48.0023, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6830, Val Loss: 48.6811, Recon: 0.6812, KL: 48.0018, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6796, Val Loss: 48.6762, Recon: 0.6759, KL: 48.0037, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6768, Val Loss: 48.6803, Recon: 0.6741, KL: 48.0027, KL_weight: 4.8000
Saved model 63 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_62.pt
Training bootstrap model 64/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9595, Val Loss: 0.7343, Recon: 0.9595, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6878, Val Loss: 4.6184, Recon: 0.8223, KL: 3.8654, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4472, Val Loss: 9.4176, Recon: 0.7903, KL: 8.6569, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2473, Val Loss: 14.2294, Recon: 0.7943, KL: 13.4529, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0135, Val Loss: 18.9884, Recon: 0.7646, KL: 18.2489, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8329, Val Loss: 23.8256, Recon: 0.7682, KL: 23.0646, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.5981, Val Loss: 28.5782, Recon: 0.7492, KL: 27.8489, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3972, Val Loss: 33.3699, Recon: 0.7513, KL: 32.6459, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2009, Val Loss: 38.2046, Recon: 0.7510, KL: 37.4499, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9960, Val Loss: 43.0026, Recon: 0.7455, KL: 42.2505, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8059, Val Loss: 47.7716, Recon: 0.7537, KL: 47.0521, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7558, Val Loss: 48.7478, Recon: 0.7481, KL: 48.0078, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7361, Val Loss: 48.7283, Recon: 0.7339, KL: 48.0022, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7349, Val Loss: 48.7222, Recon: 0.7306, KL: 48.0043, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7326, Val Loss: 48.7189, Recon: 0.7296, KL: 48.0030, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7266, Val Loss: 48.7259, Recon: 0.7230, KL: 48.0036, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7308, Val Loss: 48.7198, Recon: 0.7250, KL: 48.0058, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7341, Val Loss: 48.7140, Recon: 0.7293, KL: 48.0048, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7251, Val Loss: 48.7262, Recon: 0.7231, KL: 48.0020, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7249, Val Loss: 48.7189, Recon: 0.7206, KL: 48.0044, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7263, Val Loss: 48.7116, Recon: 0.7238, KL: 48.0025, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7217, Val Loss: 48.7304, Recon: 0.7178, KL: 48.0039, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7195, Val Loss: 48.7133, Recon: 0.7159, KL: 48.0035, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7194, Val Loss: 48.7153, Recon: 0.7133, KL: 48.0060, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7098, Val Loss: 48.7171, Recon: 0.7062, KL: 48.0036, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7065, Val Loss: 48.7036, Recon: 0.7025, KL: 48.0040, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7204, Val Loss: 48.7092, Recon: 0.7096, KL: 48.0108, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7126, Val Loss: 48.7476, Recon: 0.7062, KL: 48.0064, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7082, Val Loss: 48.6911, Recon: 0.7022, KL: 48.0061, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7013, Val Loss: 48.7111, Recon: 0.6968, KL: 48.0045, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7099, Val Loss: 48.7097, Recon: 0.7064, KL: 48.0035, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6894, Val Loss: 48.7213, Recon: 0.6858, KL: 48.0036, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6903, Val Loss: 48.7164, Recon: 0.6861, KL: 48.0042, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6908, Val Loss: 48.6896, Recon: 0.6860, KL: 48.0048, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6941, Val Loss: 48.7109, Recon: 0.6911, KL: 48.0030, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6941, Val Loss: 48.6997, Recon: 0.6907, KL: 48.0035, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6928, Val Loss: 48.7131, Recon: 0.6884, KL: 48.0044, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7072, Val Loss: 48.7126, Recon: 0.7031, KL: 48.0040, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6963, Val Loss: 48.6955, Recon: 0.6927, KL: 48.0036, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6819, Val Loss: 48.6924, Recon: 0.6792, KL: 48.0027, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6801, Val Loss: 48.6975, Recon: 0.6765, KL: 48.0036, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6885, Val Loss: 48.6917, Recon: 0.6849, KL: 48.0036, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6892, Val Loss: 48.6805, Recon: 0.6859, KL: 48.0033, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6807, Val Loss: 48.6876, Recon: 0.6785, KL: 48.0022, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6851, Val Loss: 48.6782, Recon: 0.6808, KL: 48.0043, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6822, Val Loss: 48.6978, Recon: 0.6776, KL: 48.0047, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6799, Val Loss: 48.6943, Recon: 0.6763, KL: 48.0036, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6791, Val Loss: 48.6780, Recon: 0.6762, KL: 48.0029, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6778, Val Loss: 48.6875, Recon: 0.6752, KL: 48.0026, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6833, Val Loss: 48.6732, Recon: 0.6802, KL: 48.0031, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6766, Val Loss: 48.6808, Recon: 0.6746, KL: 48.0020, KL_weight: 4.8000
Saved model 64 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_63.pt
Training bootstrap model 65/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9587, Val Loss: 0.7302, Recon: 0.9587, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6847, Val Loss: 4.6404, Recon: 0.8184, KL: 3.8664, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4500, Val Loss: 9.4060, Recon: 0.7921, KL: 8.6578, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2241, Val Loss: 14.1942, Recon: 0.7724, KL: 13.4517, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0074, Val Loss: 18.9784, Recon: 0.7606, KL: 18.2468, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8008, Val Loss: 23.7869, Recon: 0.7527, KL: 23.0481, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.5986, Val Loss: 28.5937, Recon: 0.7490, KL: 27.8496, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4067, Val Loss: 33.3846, Recon: 0.7591, KL: 32.6476, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1788, Val Loss: 38.1989, Recon: 0.7334, KL: 37.4455, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0175, Val Loss: 42.9891, Recon: 0.7602, KL: 42.2573, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7974, Val Loss: 47.7569, Recon: 0.7476, KL: 47.0498, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7355, Val Loss: 48.7192, Recon: 0.7317, KL: 48.0038, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7461, Val Loss: 48.7352, Recon: 0.7379, KL: 48.0081, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7372, Val Loss: 48.7152, Recon: 0.7331, KL: 48.0041, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7449, Val Loss: 48.7297, Recon: 0.7361, KL: 48.0088, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7286, Val Loss: 48.7287, Recon: 0.7239, KL: 48.0047, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7172, Val Loss: 48.7178, Recon: 0.7154, KL: 48.0018, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7507, Val Loss: 48.7441, Recon: 0.7361, KL: 48.0146, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7564, Val Loss: 48.7400, Recon: 0.7315, KL: 48.0249, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7535, Val Loss: 48.7360, Recon: 0.7449, KL: 48.0086, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7180, Val Loss: 48.7176, Recon: 0.7136, KL: 48.0044, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7272, Val Loss: 48.7161, Recon: 0.7224, KL: 48.0048, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7135, Val Loss: 48.7087, Recon: 0.7118, KL: 48.0017, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7113, Val Loss: 48.7165, Recon: 0.7091, KL: 48.0022, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7275, Val Loss: 48.7323, Recon: 0.7247, KL: 48.0028, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7224, Val Loss: 48.7099, Recon: 0.7138, KL: 48.0085, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7127, Val Loss: 48.7254, Recon: 0.7105, KL: 48.0022, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7133, Val Loss: 48.7152, Recon: 0.7109, KL: 48.0024, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7174, Val Loss: 48.7114, Recon: 0.7145, KL: 48.0029, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7403, Val Loss: 48.7102, Recon: 0.7279, KL: 48.0124, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7223, Val Loss: 48.7291, Recon: 0.7163, KL: 48.0059, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7138, Val Loss: 48.7247, Recon: 0.7123, KL: 48.0015, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7132, Val Loss: 48.7142, Recon: 0.7068, KL: 48.0065, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7060, Val Loss: 48.7196, Recon: 0.7034, KL: 48.0026, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7092, Val Loss: 48.7165, Recon: 0.7063, KL: 48.0029, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7137, Val Loss: 48.7087, Recon: 0.7106, KL: 48.0031, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7109, Val Loss: 48.7117, Recon: 0.7075, KL: 48.0034, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7092, Val Loss: 48.7127, Recon: 0.7046, KL: 48.0046, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7135, Val Loss: 48.7077, Recon: 0.7099, KL: 48.0036, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7135, Val Loss: 48.6994, Recon: 0.7073, KL: 48.0062, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7031, Val Loss: 48.7039, Recon: 0.6998, KL: 48.0033, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7015, Val Loss: 48.7114, Recon: 0.6989, KL: 48.0026, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7112, Val Loss: 48.7167, Recon: 0.7095, KL: 48.0017, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7084, Val Loss: 48.6949, Recon: 0.7054, KL: 48.0030, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6954, Val Loss: 48.7002, Recon: 0.6923, KL: 48.0031, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7029, Val Loss: 48.6923, Recon: 0.7004, KL: 48.0025, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6942, Val Loss: 48.6977, Recon: 0.6877, KL: 48.0065, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6965, Val Loss: 48.7028, Recon: 0.6889, KL: 48.0077, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6959, Val Loss: 48.7075, Recon: 0.6890, KL: 48.0070, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6869, Val Loss: 48.7008, Recon: 0.6843, KL: 48.0026, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6958, Val Loss: 48.7082, Recon: 0.6915, KL: 48.0043, KL_weight: 4.8000
Saved model 65 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_64.pt
Training bootstrap model 66/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9521, Val Loss: 0.7145, Recon: 0.9521, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7187, Val Loss: 4.6518, Recon: 0.8392, KL: 3.8795, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4760, Val Loss: 9.4179, Recon: 0.8166, KL: 8.6593, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2428, Val Loss: 14.2179, Recon: 0.7902, KL: 13.4527, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0239, Val Loss: 18.9960, Recon: 0.7738, KL: 18.2502, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8163, Val Loss: 23.7961, Recon: 0.7676, KL: 23.0487, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6215, Val Loss: 28.5858, Recon: 0.7659, KL: 27.8556, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4114, Val Loss: 33.3681, Recon: 0.7615, KL: 32.6499, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1990, Val Loss: 38.1736, Recon: 0.7532, KL: 37.4457, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9971, Val Loss: 42.9628, Recon: 0.7508, KL: 42.2463, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7886, Val Loss: 47.7713, Recon: 0.7437, KL: 47.0450, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7469, Val Loss: 48.7161, Recon: 0.7419, KL: 48.0050, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7462, Val Loss: 48.7296, Recon: 0.7401, KL: 48.0061, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7547, Val Loss: 48.7243, Recon: 0.7472, KL: 48.0075, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7337, Val Loss: 48.7228, Recon: 0.7311, KL: 48.0026, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7389, Val Loss: 48.7182, Recon: 0.7352, KL: 48.0037, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7432, Val Loss: 48.7231, Recon: 0.7387, KL: 48.0044, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7351, Val Loss: 48.7421, Recon: 0.7311, KL: 48.0040, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7356, Val Loss: 48.7216, Recon: 0.7292, KL: 48.0064, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7372, Val Loss: 48.7222, Recon: 0.7323, KL: 48.0049, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7422, Val Loss: 48.7317, Recon: 0.7361, KL: 48.0061, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7289, Val Loss: 48.7134, Recon: 0.7244, KL: 48.0045, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7277, Val Loss: 48.7205, Recon: 0.7224, KL: 48.0053, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7299, Val Loss: 48.7022, Recon: 0.7272, KL: 48.0027, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7210, Val Loss: 48.7107, Recon: 0.7189, KL: 48.0020, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7226, Val Loss: 48.7036, Recon: 0.7175, KL: 48.0051, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7203, Val Loss: 48.7155, Recon: 0.7158, KL: 48.0045, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7240, Val Loss: 48.7377, Recon: 0.7152, KL: 48.0088, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7405, Val Loss: 48.7156, Recon: 0.7326, KL: 48.0079, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7243, Val Loss: 48.7009, Recon: 0.7203, KL: 48.0039, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7101, Val Loss: 48.7039, Recon: 0.7066, KL: 48.0035, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7068, Val Loss: 48.7027, Recon: 0.7034, KL: 48.0034, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7198, Val Loss: 48.7052, Recon: 0.7162, KL: 48.0036, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7185, Val Loss: 48.6953, Recon: 0.7128, KL: 48.0056, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7062, Val Loss: 48.6887, Recon: 0.7029, KL: 48.0033, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6990, Val Loss: 48.6942, Recon: 0.6956, KL: 48.0034, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6991, Val Loss: 48.6835, Recon: 0.6962, KL: 48.0030, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6973, Val Loss: 48.6958, Recon: 0.6939, KL: 48.0034, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6980, Val Loss: 48.6886, Recon: 0.6915, KL: 48.0065, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7023, Val Loss: 48.7018, Recon: 0.6994, KL: 48.0029, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6901, Val Loss: 48.7132, Recon: 0.6856, KL: 48.0045, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6920, Val Loss: 48.6849, Recon: 0.6895, KL: 48.0025, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6938, Val Loss: 48.6924, Recon: 0.6905, KL: 48.0033, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6985, Val Loss: 48.6872, Recon: 0.6950, KL: 48.0035, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6924, Val Loss: 48.6927, Recon: 0.6877, KL: 48.0047, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6878, Val Loss: 48.6812, Recon: 0.6833, KL: 48.0045, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6918, Val Loss: 48.6834, Recon: 0.6889, KL: 48.0029, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6843, Val Loss: 48.6729, Recon: 0.6819, KL: 48.0024, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6983, Val Loss: 48.6840, Recon: 0.6943, KL: 48.0039, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6922, Val Loss: 48.6875, Recon: 0.6876, KL: 48.0047, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6854, Val Loss: 48.6790, Recon: 0.6825, KL: 48.0029, KL_weight: 4.8000
Saved model 66 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_65.pt
Training bootstrap model 67/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9445, Val Loss: 0.7409, Recon: 0.9445, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6794, Val Loss: 4.6482, Recon: 0.8141, KL: 3.8653, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4274, Val Loss: 9.4163, Recon: 0.7745, KL: 8.6530, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2257, Val Loss: 14.2060, Recon: 0.7730, KL: 13.4527, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0105, Val Loss: 19.0107, Recon: 0.7617, KL: 18.2489, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8052, Val Loss: 23.7980, Recon: 0.7583, KL: 23.0469, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.5916, Val Loss: 28.5771, Recon: 0.7405, KL: 27.8512, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3952, Val Loss: 33.3827, Recon: 0.7491, KL: 32.6461, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1882, Val Loss: 38.1737, Recon: 0.7425, KL: 37.4457, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9802, Val Loss: 42.9685, Recon: 0.7349, KL: 42.2453, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7916, Val Loss: 47.7855, Recon: 0.7439, KL: 47.0476, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7260, Val Loss: 48.7202, Recon: 0.7215, KL: 48.0045, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7393, Val Loss: 48.7291, Recon: 0.7309, KL: 48.0084, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7378, Val Loss: 48.7275, Recon: 0.7321, KL: 48.0057, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7276, Val Loss: 48.7188, Recon: 0.7211, KL: 48.0065, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7164, Val Loss: 48.7288, Recon: 0.7135, KL: 48.0029, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7149, Val Loss: 48.7104, Recon: 0.7118, KL: 48.0032, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7033, Val Loss: 48.6948, Recon: 0.7004, KL: 48.0029, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7126, Val Loss: 48.7168, Recon: 0.7084, KL: 48.0042, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7109, Val Loss: 48.7001, Recon: 0.7045, KL: 48.0064, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7073, Val Loss: 48.7200, Recon: 0.7029, KL: 48.0044, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7082, Val Loss: 48.7072, Recon: 0.7022, KL: 48.0060, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.6938, Val Loss: 48.6935, Recon: 0.6911, KL: 48.0027, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.6938, Val Loss: 48.7010, Recon: 0.6900, KL: 48.0037, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.6924, Val Loss: 48.6974, Recon: 0.6885, KL: 48.0039, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.6969, Val Loss: 48.6932, Recon: 0.6941, KL: 48.0028, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.6957, Val Loss: 48.6893, Recon: 0.6925, KL: 48.0032, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.6925, Val Loss: 48.6880, Recon: 0.6907, KL: 48.0018, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.6953, Val Loss: 48.7047, Recon: 0.6890, KL: 48.0063, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.6897, Val Loss: 48.6984, Recon: 0.6848, KL: 48.0049, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.6997, Val Loss: 48.6984, Recon: 0.6921, KL: 48.0075, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6943, Val Loss: 48.6968, Recon: 0.6920, KL: 48.0023, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6775, Val Loss: 48.6867, Recon: 0.6745, KL: 48.0030, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6813, Val Loss: 48.6926, Recon: 0.6772, KL: 48.0041, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6837, Val Loss: 48.6952, Recon: 0.6792, KL: 48.0044, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6857, Val Loss: 48.6887, Recon: 0.6835, KL: 48.0022, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6820, Val Loss: 48.6917, Recon: 0.6794, KL: 48.0026, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6842, Val Loss: 48.6924, Recon: 0.6810, KL: 48.0032, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6781, Val Loss: 48.6845, Recon: 0.6754, KL: 48.0027, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6801, Val Loss: 48.6937, Recon: 0.6762, KL: 48.0039, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6822, Val Loss: 48.6857, Recon: 0.6788, KL: 48.0034, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6808, Val Loss: 48.6954, Recon: 0.6779, KL: 48.0029, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6886, Val Loss: 48.6816, Recon: 0.6813, KL: 48.0073, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6749, Val Loss: 48.6874, Recon: 0.6722, KL: 48.0027, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6755, Val Loss: 48.6794, Recon: 0.6717, KL: 48.0038, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6803, Val Loss: 48.6737, Recon: 0.6760, KL: 48.0043, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6768, Val Loss: 48.6828, Recon: 0.6723, KL: 48.0044, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6744, Val Loss: 48.6779, Recon: 0.6721, KL: 48.0023, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6712, Val Loss: 48.6892, Recon: 0.6688, KL: 48.0025, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6720, Val Loss: 48.7030, Recon: 0.6670, KL: 48.0050, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6753, Val Loss: 48.6846, Recon: 0.6713, KL: 48.0040, KL_weight: 4.8000
Saved model 67 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_66.pt
Training bootstrap model 68/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9825, Val Loss: 0.7505, Recon: 0.9825, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7042, Val Loss: 4.6451, Recon: 0.8301, KL: 3.8741, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4664, Val Loss: 9.4209, Recon: 0.8072, KL: 8.6592, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2640, Val Loss: 14.2049, Recon: 0.8039, KL: 13.4601, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0409, Val Loss: 18.9947, Recon: 0.7869, KL: 18.2540, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8227, Val Loss: 23.7856, Recon: 0.7716, KL: 23.0510, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6167, Val Loss: 28.5855, Recon: 0.7701, KL: 27.8466, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4289, Val Loss: 33.3833, Recon: 0.7747, KL: 32.6542, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2040, Val Loss: 38.1674, Recon: 0.7583, KL: 37.4458, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0071, Val Loss: 42.9870, Recon: 0.7585, KL: 42.2486, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8166, Val Loss: 47.7794, Recon: 0.7637, KL: 47.0529, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7555, Val Loss: 48.7441, Recon: 0.7482, KL: 48.0073, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7584, Val Loss: 48.7460, Recon: 0.7528, KL: 48.0056, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7544, Val Loss: 48.7394, Recon: 0.7503, KL: 48.0040, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7494, Val Loss: 48.7327, Recon: 0.7439, KL: 48.0055, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7429, Val Loss: 48.7209, Recon: 0.7363, KL: 48.0066, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7348, Val Loss: 48.7319, Recon: 0.7291, KL: 48.0057, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7369, Val Loss: 48.7211, Recon: 0.7327, KL: 48.0042, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7278, Val Loss: 48.7112, Recon: 0.7254, KL: 48.0025, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7292, Val Loss: 48.7210, Recon: 0.7259, KL: 48.0032, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7460, Val Loss: 48.7208, Recon: 0.7308, KL: 48.0151, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7346, Val Loss: 48.7155, Recon: 0.7313, KL: 48.0033, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7439, Val Loss: 48.7135, Recon: 0.7407, KL: 48.0032, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7424, Val Loss: 48.7227, Recon: 0.7348, KL: 48.0076, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7235, Val Loss: 48.7199, Recon: 0.7195, KL: 48.0041, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7412, Val Loss: 48.7302, Recon: 0.7276, KL: 48.0137, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7395, Val Loss: 48.7127, Recon: 0.7346, KL: 48.0049, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7285, Val Loss: 48.7074, Recon: 0.7266, KL: 48.0020, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7284, Val Loss: 48.7103, Recon: 0.7250, KL: 48.0034, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7325, Val Loss: 48.7185, Recon: 0.7287, KL: 48.0039, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7331, Val Loss: 48.7174, Recon: 0.7270, KL: 48.0061, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7226, Val Loss: 48.7050, Recon: 0.7189, KL: 48.0037, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7180, Val Loss: 48.7086, Recon: 0.7173, KL: 48.0008, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7132, Val Loss: 48.6979, Recon: 0.7112, KL: 48.0020, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7338, Val Loss: 48.7176, Recon: 0.7238, KL: 48.0100, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7164, Val Loss: 48.6965, Recon: 0.7137, KL: 48.0027, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7117, Val Loss: 48.7036, Recon: 0.7082, KL: 48.0035, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7170, Val Loss: 48.7051, Recon: 0.7138, KL: 48.0033, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7122, Val Loss: 48.7009, Recon: 0.7098, KL: 48.0024, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7242, Val Loss: 48.7032, Recon: 0.7177, KL: 48.0066, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7084, Val Loss: 48.6992, Recon: 0.7055, KL: 48.0028, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7084, Val Loss: 48.7048, Recon: 0.7069, KL: 48.0015, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7097, Val Loss: 48.7023, Recon: 0.7070, KL: 48.0027, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7138, Val Loss: 48.7248, Recon: 0.7085, KL: 48.0052, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7260, Val Loss: 48.7168, Recon: 0.7150, KL: 48.0109, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7098, Val Loss: 48.6944, Recon: 0.7076, KL: 48.0022, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7200, Val Loss: 48.7008, Recon: 0.7168, KL: 48.0032, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7161, Val Loss: 48.6994, Recon: 0.7112, KL: 48.0049, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7193, Val Loss: 48.6986, Recon: 0.7122, KL: 48.0071, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7017, Val Loss: 48.6977, Recon: 0.6999, KL: 48.0018, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6992, Val Loss: 48.6918, Recon: 0.6974, KL: 48.0018, KL_weight: 4.8000
Saved model 68 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_67.pt
Training bootstrap model 69/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9550, Val Loss: 0.7148, Recon: 0.9550, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6736, Val Loss: 4.6304, Recon: 0.8094, KL: 3.8642, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4493, Val Loss: 9.4088, Recon: 0.7889, KL: 8.6604, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2135, Val Loss: 14.1890, Recon: 0.7620, KL: 13.4515, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0070, Val Loss: 19.0089, Recon: 0.7562, KL: 18.2508, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.7978, Val Loss: 23.7730, Recon: 0.7501, KL: 23.0478, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6037, Val Loss: 28.5777, Recon: 0.7546, KL: 27.8491, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4019, Val Loss: 33.3931, Recon: 0.7546, KL: 32.6473, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1755, Val Loss: 38.1615, Recon: 0.7314, KL: 37.4441, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9709, Val Loss: 42.9733, Recon: 0.7262, KL: 42.2446, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8043, Val Loss: 47.7728, Recon: 0.7342, KL: 47.0701, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7484, Val Loss: 48.7479, Recon: 0.7406, KL: 48.0078, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7336, Val Loss: 48.7155, Recon: 0.7292, KL: 48.0045, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7281, Val Loss: 48.7205, Recon: 0.7254, KL: 48.0027, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7335, Val Loss: 48.7252, Recon: 0.7272, KL: 48.0063, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.8108, Val Loss: 48.7348, Recon: 0.7677, KL: 48.0431, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7338, Val Loss: 48.7192, Recon: 0.7301, KL: 48.0037, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7198, Val Loss: 48.7047, Recon: 0.7174, KL: 48.0024, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7148, Val Loss: 48.7045, Recon: 0.7131, KL: 48.0017, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7170, Val Loss: 48.7107, Recon: 0.7124, KL: 48.0046, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7184, Val Loss: 48.7047, Recon: 0.7146, KL: 48.0038, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7212, Val Loss: 48.7114, Recon: 0.7168, KL: 48.0043, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7150, Val Loss: 48.7116, Recon: 0.7108, KL: 48.0042, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7082, Val Loss: 48.7087, Recon: 0.7054, KL: 48.0028, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7163, Val Loss: 48.7119, Recon: 0.7124, KL: 48.0038, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7101, Val Loss: 48.7063, Recon: 0.7058, KL: 48.0043, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7118, Val Loss: 48.7086, Recon: 0.7090, KL: 48.0028, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7156, Val Loss: 48.7092, Recon: 0.7127, KL: 48.0029, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7193, Val Loss: 48.7014, Recon: 0.7141, KL: 48.0053, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7162, Val Loss: 48.7034, Recon: 0.7109, KL: 48.0053, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7134, Val Loss: 48.7030, Recon: 0.7076, KL: 48.0058, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7087, Val Loss: 48.7072, Recon: 0.7041, KL: 48.0046, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7126, Val Loss: 48.7080, Recon: 0.7091, KL: 48.0035, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7194, Val Loss: 48.7043, Recon: 0.7144, KL: 48.0050, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7164, Val Loss: 48.7011, Recon: 0.7115, KL: 48.0049, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7203, Val Loss: 48.6953, Recon: 0.7086, KL: 48.0117, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7002, Val Loss: 48.7144, Recon: 0.6976, KL: 48.0025, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7000, Val Loss: 48.7000, Recon: 0.6981, KL: 48.0019, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7161, Val Loss: 48.7064, Recon: 0.7145, KL: 48.0016, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7062, Val Loss: 48.7022, Recon: 0.7009, KL: 48.0052, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7061, Val Loss: 48.7070, Recon: 0.7026, KL: 48.0035, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7093, Val Loss: 48.7080, Recon: 0.7049, KL: 48.0044, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7000, Val Loss: 48.6985, Recon: 0.6989, KL: 48.0012, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7081, Val Loss: 48.7047, Recon: 0.7019, KL: 48.0062, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7309, Val Loss: 48.7095, Recon: 0.7228, KL: 48.0081, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7068, Val Loss: 48.7187, Recon: 0.7012, KL: 48.0056, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7101, Val Loss: 48.7062, Recon: 0.7072, KL: 48.0029, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6985, Val Loss: 48.7043, Recon: 0.6955, KL: 48.0030, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7074, Val Loss: 48.6982, Recon: 0.7021, KL: 48.0053, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6988, Val Loss: 48.6958, Recon: 0.6956, KL: 48.0032, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6880, Val Loss: 48.6990, Recon: 0.6845, KL: 48.0036, KL_weight: 4.8000
Saved model 69 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_68.pt
Training bootstrap model 70/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9610, Val Loss: 0.7618, Recon: 0.9610, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6810, Val Loss: 4.6376, Recon: 0.8136, KL: 3.8674, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4470, Val Loss: 9.4259, Recon: 0.7937, KL: 8.6533, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2470, Val Loss: 14.2126, Recon: 0.7907, KL: 13.4564, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0271, Val Loss: 18.9801, Recon: 0.7785, KL: 18.2486, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8238, Val Loss: 23.8009, Recon: 0.7749, KL: 23.0489, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6183, Val Loss: 28.5890, Recon: 0.7683, KL: 27.8500, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4106, Val Loss: 33.3941, Recon: 0.7592, KL: 32.6514, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2130, Val Loss: 38.1964, Recon: 0.7616, KL: 37.4514, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0266, Val Loss: 42.9965, Recon: 0.7770, KL: 42.2496, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8032, Val Loss: 47.7838, Recon: 0.7584, KL: 47.0448, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7549, Val Loss: 48.7298, Recon: 0.7482, KL: 48.0067, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7414, Val Loss: 48.7296, Recon: 0.7368, KL: 48.0046, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7387, Val Loss: 48.7257, Recon: 0.7351, KL: 48.0037, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7558, Val Loss: 48.7302, Recon: 0.7448, KL: 48.0110, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7467, Val Loss: 48.7387, Recon: 0.7403, KL: 48.0064, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7331, Val Loss: 48.7172, Recon: 0.7281, KL: 48.0050, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7288, Val Loss: 48.7158, Recon: 0.7245, KL: 48.0044, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7745, Val Loss: 48.7344, Recon: 0.7610, KL: 48.0135, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7278, Val Loss: 48.7039, Recon: 0.7227, KL: 48.0051, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7461, Val Loss: 48.7178, Recon: 0.7286, KL: 48.0174, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7331, Val Loss: 48.7089, Recon: 0.7287, KL: 48.0044, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7231, Val Loss: 48.7209, Recon: 0.7195, KL: 48.0036, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7216, Val Loss: 48.7147, Recon: 0.7165, KL: 48.0051, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7322, Val Loss: 48.7169, Recon: 0.7290, KL: 48.0031, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7272, Val Loss: 48.7170, Recon: 0.7215, KL: 48.0057, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7165, Val Loss: 48.7114, Recon: 0.7143, KL: 48.0022, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7223, Val Loss: 48.7122, Recon: 0.7182, KL: 48.0041, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7208, Val Loss: 48.7207, Recon: 0.7167, KL: 48.0041, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7200, Val Loss: 48.7074, Recon: 0.7163, KL: 48.0037, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7182, Val Loss: 48.7039, Recon: 0.7149, KL: 48.0033, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7297, Val Loss: 48.7145, Recon: 0.7248, KL: 48.0049, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7160, Val Loss: 48.7157, Recon: 0.7117, KL: 48.0043, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7390, Val Loss: 48.7033, Recon: 0.7190, KL: 48.0200, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7224, Val Loss: 48.7100, Recon: 0.7122, KL: 48.0102, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7221, Val Loss: 48.7096, Recon: 0.7204, KL: 48.0017, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7079, Val Loss: 48.6975, Recon: 0.7072, KL: 48.0007, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7097, Val Loss: 48.6999, Recon: 0.7073, KL: 48.0024, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7098, Val Loss: 48.7038, Recon: 0.7079, KL: 48.0018, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7082, Val Loss: 48.7109, Recon: 0.7061, KL: 48.0021, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7113, Val Loss: 48.6953, Recon: 0.7086, KL: 48.0028, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7193, Val Loss: 48.7265, Recon: 0.7133, KL: 48.0061, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7210, Val Loss: 48.7009, Recon: 0.7190, KL: 48.0020, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7143, Val Loss: 48.7007, Recon: 0.7119, KL: 48.0025, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7105, Val Loss: 48.7062, Recon: 0.7092, KL: 48.0014, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7128, Val Loss: 48.6978, Recon: 0.7102, KL: 48.0026, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7203, Val Loss: 48.7039, Recon: 0.7134, KL: 48.0069, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7022, Val Loss: 48.6934, Recon: 0.7013, KL: 48.0009, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7091, Val Loss: 48.6961, Recon: 0.7054, KL: 48.0037, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7126, Val Loss: 48.6991, Recon: 0.7109, KL: 48.0017, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6980, Val Loss: 48.6938, Recon: 0.6957, KL: 48.0023, KL_weight: 4.8000
Saved model 70 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_69.pt
Training bootstrap model 71/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9259, Val Loss: 0.7247, Recon: 0.9259, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6736, Val Loss: 4.6350, Recon: 0.8053, KL: 3.8683, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4402, Val Loss: 9.4081, Recon: 0.7874, KL: 8.6529, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2339, Val Loss: 14.2271, Recon: 0.7805, KL: 13.4535, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0189, Val Loss: 18.9952, Recon: 0.7647, KL: 18.2542, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8082, Val Loss: 23.7977, Recon: 0.7573, KL: 23.0510, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.5936, Val Loss: 28.5971, Recon: 0.7433, KL: 27.8503, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4000, Val Loss: 33.3821, Recon: 0.7532, KL: 32.6468, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1855, Val Loss: 38.1699, Recon: 0.7416, KL: 37.4439, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0170, Val Loss: 42.9748, Recon: 0.7590, KL: 42.2580, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7990, Val Loss: 47.7917, Recon: 0.7491, KL: 47.0499, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7417, Val Loss: 48.7252, Recon: 0.7352, KL: 48.0065, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7463, Val Loss: 48.7532, Recon: 0.7393, KL: 48.0070, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7334, Val Loss: 48.7335, Recon: 0.7282, KL: 48.0052, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7227, Val Loss: 48.7180, Recon: 0.7193, KL: 48.0034, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7304, Val Loss: 48.7298, Recon: 0.7231, KL: 48.0073, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7174, Val Loss: 48.7056, Recon: 0.7138, KL: 48.0036, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7338, Val Loss: 48.7083, Recon: 0.7300, KL: 48.0038, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7138, Val Loss: 48.7159, Recon: 0.7106, KL: 48.0032, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7081, Val Loss: 48.6989, Recon: 0.7048, KL: 48.0034, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7111, Val Loss: 48.7070, Recon: 0.7081, KL: 48.0030, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7099, Val Loss: 48.7234, Recon: 0.7064, KL: 48.0035, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7312, Val Loss: 48.7248, Recon: 0.7181, KL: 48.0130, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7068, Val Loss: 48.7125, Recon: 0.7010, KL: 48.0058, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7129, Val Loss: 48.7146, Recon: 0.7088, KL: 48.0041, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.6946, Val Loss: 48.7133, Recon: 0.6908, KL: 48.0038, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7048, Val Loss: 48.6901, Recon: 0.6976, KL: 48.0072, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7104, Val Loss: 48.6976, Recon: 0.7023, KL: 48.0081, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.6988, Val Loss: 48.7156, Recon: 0.6926, KL: 48.0062, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7033, Val Loss: 48.7079, Recon: 0.6967, KL: 48.0066, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7051, Val Loss: 48.7004, Recon: 0.6962, KL: 48.0090, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6900, Val Loss: 48.6951, Recon: 0.6858, KL: 48.0041, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6888, Val Loss: 48.6895, Recon: 0.6859, KL: 48.0029, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6913, Val Loss: 48.6954, Recon: 0.6870, KL: 48.0043, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6911, Val Loss: 48.6912, Recon: 0.6883, KL: 48.0028, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6905, Val Loss: 48.6951, Recon: 0.6869, KL: 48.0036, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6900, Val Loss: 48.6818, Recon: 0.6860, KL: 48.0040, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6854, Val Loss: 48.6820, Recon: 0.6819, KL: 48.0034, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6860, Val Loss: 48.6876, Recon: 0.6820, KL: 48.0040, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6857, Val Loss: 48.6927, Recon: 0.6818, KL: 48.0039, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6854, Val Loss: 48.6836, Recon: 0.6824, KL: 48.0030, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6879, Val Loss: 48.6923, Recon: 0.6840, KL: 48.0039, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6869, Val Loss: 48.6944, Recon: 0.6829, KL: 48.0040, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6842, Val Loss: 48.6837, Recon: 0.6802, KL: 48.0040, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6754, Val Loss: 48.6853, Recon: 0.6733, KL: 48.0021, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6798, Val Loss: 48.6881, Recon: 0.6762, KL: 48.0035, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6755, Val Loss: 48.6740, Recon: 0.6736, KL: 48.0019, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6820, Val Loss: 48.6886, Recon: 0.6759, KL: 48.0061, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6814, Val Loss: 48.6863, Recon: 0.6769, KL: 48.0045, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6718, Val Loss: 48.6879, Recon: 0.6704, KL: 48.0015, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6776, Val Loss: 48.6828, Recon: 0.6714, KL: 48.0062, KL_weight: 4.8000
Saved model 71 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_70.pt
Training bootstrap model 72/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9364, Val Loss: 0.7133, Recon: 0.9364, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6976, Val Loss: 4.6480, Recon: 0.8254, KL: 3.8722, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4453, Val Loss: 9.4232, Recon: 0.7917, KL: 8.6536, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2295, Val Loss: 14.2174, Recon: 0.7771, KL: 13.4524, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0209, Val Loss: 19.0036, Recon: 0.7724, KL: 18.2485, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8301, Val Loss: 23.7968, Recon: 0.7687, KL: 23.0614, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6028, Val Loss: 28.6081, Recon: 0.7520, KL: 27.8509, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4078, Val Loss: 33.3788, Recon: 0.7581, KL: 32.6497, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2112, Val Loss: 38.1805, Recon: 0.7577, KL: 37.4535, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0108, Val Loss: 42.9836, Recon: 0.7615, KL: 42.2493, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7890, Val Loss: 47.7831, Recon: 0.7449, KL: 47.0441, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7390, Val Loss: 48.7311, Recon: 0.7357, KL: 48.0032, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7459, Val Loss: 48.7278, Recon: 0.7413, KL: 48.0046, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7507, Val Loss: 48.7312, Recon: 0.7410, KL: 48.0097, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7476, Val Loss: 48.7262, Recon: 0.7415, KL: 48.0061, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7490, Val Loss: 48.7203, Recon: 0.7424, KL: 48.0066, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7430, Val Loss: 48.7164, Recon: 0.7387, KL: 48.0043, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7331, Val Loss: 48.7261, Recon: 0.7298, KL: 48.0034, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7374, Val Loss: 48.7206, Recon: 0.7304, KL: 48.0070, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7242, Val Loss: 48.7252, Recon: 0.7221, KL: 48.0021, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7315, Val Loss: 48.7090, Recon: 0.7282, KL: 48.0034, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7314, Val Loss: 48.7053, Recon: 0.7272, KL: 48.0042, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7370, Val Loss: 48.7069, Recon: 0.7325, KL: 48.0045, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7282, Val Loss: 48.7027, Recon: 0.7254, KL: 48.0028, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7381, Val Loss: 48.7141, Recon: 0.7311, KL: 48.0070, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7244, Val Loss: 48.7179, Recon: 0.7220, KL: 48.0025, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7229, Val Loss: 48.6998, Recon: 0.7173, KL: 48.0056, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7466, Val Loss: 48.7494, Recon: 0.7357, KL: 48.0109, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7243, Val Loss: 48.7067, Recon: 0.7208, KL: 48.0035, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7212, Val Loss: 48.7194, Recon: 0.7184, KL: 48.0028, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7203, Val Loss: 48.7084, Recon: 0.7168, KL: 48.0035, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7272, Val Loss: 48.7100, Recon: 0.7234, KL: 48.0038, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7255, Val Loss: 48.7138, Recon: 0.7168, KL: 48.0087, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7264, Val Loss: 48.7146, Recon: 0.7217, KL: 48.0047, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7105, Val Loss: 48.7120, Recon: 0.7089, KL: 48.0015, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7147, Val Loss: 48.7037, Recon: 0.7132, KL: 48.0014, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7233, Val Loss: 48.7059, Recon: 0.7181, KL: 48.0053, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7088, Val Loss: 48.7030, Recon: 0.7071, KL: 48.0016, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7092, Val Loss: 48.6995, Recon: 0.7074, KL: 48.0018, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7123, Val Loss: 48.7048, Recon: 0.7105, KL: 48.0018, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7166, Val Loss: 48.7099, Recon: 0.7122, KL: 48.0043, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7181, Val Loss: 48.7070, Recon: 0.7150, KL: 48.0031, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7276, Val Loss: 48.7134, Recon: 0.7128, KL: 48.0148, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7185, Val Loss: 48.7100, Recon: 0.7134, KL: 48.0051, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7211, Val Loss: 48.7048, Recon: 0.7171, KL: 48.0039, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7163, Val Loss: 48.7119, Recon: 0.7148, KL: 48.0015, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7057, Val Loss: 48.7019, Recon: 0.7037, KL: 48.0020, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7064, Val Loss: 48.7099, Recon: 0.7051, KL: 48.0013, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7099, Val Loss: 48.6988, Recon: 0.7083, KL: 48.0016, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.7076, Val Loss: 48.6937, Recon: 0.7045, KL: 48.0031, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.7041, Val Loss: 48.7010, Recon: 0.7029, KL: 48.0012, KL_weight: 4.8000
Saved model 72 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_71.pt
Training bootstrap model 73/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9851, Val Loss: 0.7507, Recon: 0.9851, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7065, Val Loss: 4.6367, Recon: 0.8308, KL: 3.8756, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4789, Val Loss: 9.4135, Recon: 0.8129, KL: 8.6660, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2360, Val Loss: 14.1934, Recon: 0.7848, KL: 13.4512, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0363, Val Loss: 19.0026, Recon: 0.7832, KL: 18.2531, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8396, Val Loss: 23.7975, Recon: 0.7864, KL: 23.0532, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6166, Val Loss: 28.5938, Recon: 0.7685, KL: 27.8480, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4328, Val Loss: 33.3819, Recon: 0.7843, KL: 32.6485, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2128, Val Loss: 38.1957, Recon: 0.7662, KL: 37.4466, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0296, Val Loss: 42.9746, Recon: 0.7784, KL: 42.2511, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8063, Val Loss: 47.7853, Recon: 0.7602, KL: 47.0460, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7718, Val Loss: 48.7374, Recon: 0.7610, KL: 48.0108, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7958, Val Loss: 48.7493, Recon: 0.7738, KL: 48.0220, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7577, Val Loss: 48.7243, Recon: 0.7505, KL: 48.0072, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7394, Val Loss: 48.7269, Recon: 0.7345, KL: 48.0049, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7526, Val Loss: 48.7141, Recon: 0.7468, KL: 48.0058, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7429, Val Loss: 48.7404, Recon: 0.7370, KL: 48.0059, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7522, Val Loss: 48.7286, Recon: 0.7419, KL: 48.0103, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7217, Val Loss: 48.7207, Recon: 0.7190, KL: 48.0027, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7362, Val Loss: 48.7292, Recon: 0.7301, KL: 48.0060, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7360, Val Loss: 48.7230, Recon: 0.7289, KL: 48.0071, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7213, Val Loss: 48.7072, Recon: 0.7168, KL: 48.0044, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7252, Val Loss: 48.7164, Recon: 0.7210, KL: 48.0042, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7255, Val Loss: 48.7189, Recon: 0.7217, KL: 48.0038, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7154, Val Loss: 48.7223, Recon: 0.7120, KL: 48.0034, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7145, Val Loss: 48.7185, Recon: 0.7108, KL: 48.0037, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7205, Val Loss: 48.7098, Recon: 0.7160, KL: 48.0045, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7117, Val Loss: 48.6988, Recon: 0.7074, KL: 48.0042, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7188, Val Loss: 48.7353, Recon: 0.7094, KL: 48.0094, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7100, Val Loss: 48.6925, Recon: 0.7053, KL: 48.0046, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7397, Val Loss: 48.7129, Recon: 0.7246, KL: 48.0151, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7355, Val Loss: 48.6971, Recon: 0.7156, KL: 48.0199, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7279, Val Loss: 48.6994, Recon: 0.7149, KL: 48.0130, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7057, Val Loss: 48.6999, Recon: 0.7012, KL: 48.0045, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7138, Val Loss: 48.7144, Recon: 0.7098, KL: 48.0040, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6997, Val Loss: 48.6951, Recon: 0.6956, KL: 48.0041, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7132, Val Loss: 48.7109, Recon: 0.7047, KL: 48.0084, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6982, Val Loss: 48.6849, Recon: 0.6947, KL: 48.0035, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6953, Val Loss: 48.6816, Recon: 0.6906, KL: 48.0048, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6963, Val Loss: 48.6872, Recon: 0.6920, KL: 48.0044, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7033, Val Loss: 48.6837, Recon: 0.6976, KL: 48.0057, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6977, Val Loss: 48.6862, Recon: 0.6946, KL: 48.0031, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6928, Val Loss: 48.6848, Recon: 0.6896, KL: 48.0032, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6924, Val Loss: 48.6737, Recon: 0.6892, KL: 48.0033, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7067, Val Loss: 48.6903, Recon: 0.6946, KL: 48.0121, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6935, Val Loss: 48.6797, Recon: 0.6914, KL: 48.0020, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6940, Val Loss: 48.6928, Recon: 0.6866, KL: 48.0074, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6899, Val Loss: 48.6781, Recon: 0.6881, KL: 48.0018, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.7058, Val Loss: 48.6847, Recon: 0.6931, KL: 48.0127, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6900, Val Loss: 48.6753, Recon: 0.6855, KL: 48.0045, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6954, Val Loss: 48.6716, Recon: 0.6886, KL: 48.0068, KL_weight: 4.8000
Saved model 73 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_72.pt
Training bootstrap model 74/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9931, Val Loss: 0.7989, Recon: 0.9931, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6928, Val Loss: 4.6490, Recon: 0.8254, KL: 3.8674, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4428, Val Loss: 9.4266, Recon: 0.7886, KL: 8.6542, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2314, Val Loss: 14.1954, Recon: 0.7812, KL: 13.4502, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0133, Val Loss: 19.0076, Recon: 0.7636, KL: 18.2496, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8057, Val Loss: 23.7909, Recon: 0.7567, KL: 23.0490, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6093, Val Loss: 28.6029, Recon: 0.7563, KL: 27.8530, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4203, Val Loss: 33.3733, Recon: 0.7698, KL: 32.6505, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1991, Val Loss: 38.1805, Recon: 0.7498, KL: 37.4493, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9969, Val Loss: 42.9742, Recon: 0.7525, KL: 42.2444, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7985, Val Loss: 47.7949, Recon: 0.7472, KL: 47.0513, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7439, Val Loss: 48.7220, Recon: 0.7394, KL: 48.0045, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7427, Val Loss: 48.7427, Recon: 0.7367, KL: 48.0060, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7443, Val Loss: 48.7552, Recon: 0.7398, KL: 48.0045, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7559, Val Loss: 48.7296, Recon: 0.7481, KL: 48.0078, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7412, Val Loss: 48.7242, Recon: 0.7326, KL: 48.0086, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7383, Val Loss: 48.7176, Recon: 0.7298, KL: 48.0085, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7265, Val Loss: 48.7168, Recon: 0.7241, KL: 48.0024, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7333, Val Loss: 48.7403, Recon: 0.7312, KL: 48.0022, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7420, Val Loss: 48.7222, Recon: 0.7334, KL: 48.0086, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7385, Val Loss: 48.7308, Recon: 0.7324, KL: 48.0060, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7328, Val Loss: 48.7345, Recon: 0.7277, KL: 48.0051, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7273, Val Loss: 48.7203, Recon: 0.7195, KL: 48.0077, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7303, Val Loss: 48.7136, Recon: 0.7271, KL: 48.0032, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7313, Val Loss: 48.7281, Recon: 0.7274, KL: 48.0039, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7250, Val Loss: 48.7137, Recon: 0.7193, KL: 48.0056, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7207, Val Loss: 48.7289, Recon: 0.7168, KL: 48.0038, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7160, Val Loss: 48.7097, Recon: 0.7121, KL: 48.0039, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7156, Val Loss: 48.7108, Recon: 0.7136, KL: 48.0020, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7179, Val Loss: 48.7139, Recon: 0.7150, KL: 48.0029, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7276, Val Loss: 48.7193, Recon: 0.7228, KL: 48.0048, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7118, Val Loss: 48.7135, Recon: 0.7097, KL: 48.0021, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7203, Val Loss: 48.7138, Recon: 0.7162, KL: 48.0041, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7104, Val Loss: 48.7083, Recon: 0.7071, KL: 48.0032, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7286, Val Loss: 48.7082, Recon: 0.7155, KL: 48.0131, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7179, Val Loss: 48.7211, Recon: 0.7136, KL: 48.0043, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7150, Val Loss: 48.7101, Recon: 0.7097, KL: 48.0053, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7257, Val Loss: 48.7036, Recon: 0.7180, KL: 48.0077, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7111, Val Loss: 48.7102, Recon: 0.7088, KL: 48.0023, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7094, Val Loss: 48.7078, Recon: 0.7038, KL: 48.0056, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7034, Val Loss: 48.6912, Recon: 0.7000, KL: 48.0034, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7003, Val Loss: 48.7095, Recon: 0.6972, KL: 48.0031, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7016, Val Loss: 48.7084, Recon: 0.6963, KL: 48.0053, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6997, Val Loss: 48.6878, Recon: 0.6963, KL: 48.0034, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7014, Val Loss: 48.6807, Recon: 0.6961, KL: 48.0053, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7069, Val Loss: 48.6858, Recon: 0.7011, KL: 48.0058, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.7054, Val Loss: 48.6958, Recon: 0.6990, KL: 48.0064, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6899, Val Loss: 48.6887, Recon: 0.6873, KL: 48.0026, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6964, Val Loss: 48.7294, Recon: 0.6913, KL: 48.0051, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6963, Val Loss: 48.6966, Recon: 0.6912, KL: 48.0051, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6902, Val Loss: 48.6837, Recon: 0.6869, KL: 48.0033, KL_weight: 4.8000
Saved model 74 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_73.pt
Training bootstrap model 75/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9899, Val Loss: 0.7612, Recon: 0.9899, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7216, Val Loss: 4.6607, Recon: 0.8439, KL: 3.8777, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4452, Val Loss: 9.3987, Recon: 0.7909, KL: 8.6543, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2290, Val Loss: 14.2141, Recon: 0.7777, KL: 13.4513, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0125, Val Loss: 18.9904, Recon: 0.7637, KL: 18.2488, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8085, Val Loss: 23.7736, Recon: 0.7613, KL: 23.0473, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6046, Val Loss: 28.5827, Recon: 0.7588, KL: 27.8458, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3954, Val Loss: 33.3727, Recon: 0.7493, KL: 32.6461, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1958, Val Loss: 38.1758, Recon: 0.7487, KL: 37.4471, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0058, Val Loss: 42.9779, Recon: 0.7580, KL: 42.2478, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7958, Val Loss: 47.7812, Recon: 0.7493, KL: 47.0464, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7492, Val Loss: 48.7262, Recon: 0.7410, KL: 48.0082, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7529, Val Loss: 48.7429, Recon: 0.7450, KL: 48.0079, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7397, Val Loss: 48.7241, Recon: 0.7331, KL: 48.0066, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7591, Val Loss: 48.7432, Recon: 0.7502, KL: 48.0088, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7391, Val Loss: 48.7268, Recon: 0.7334, KL: 48.0056, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7256, Val Loss: 48.7246, Recon: 0.7227, KL: 48.0029, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7269, Val Loss: 48.7146, Recon: 0.7217, KL: 48.0052, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7229, Val Loss: 48.7063, Recon: 0.7206, KL: 48.0023, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7212, Val Loss: 48.7065, Recon: 0.7179, KL: 48.0033, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7178, Val Loss: 48.7057, Recon: 0.7157, KL: 48.0021, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7177, Val Loss: 48.7056, Recon: 0.7140, KL: 48.0037, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7188, Val Loss: 48.7200, Recon: 0.7142, KL: 48.0046, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7136, Val Loss: 48.7084, Recon: 0.7124, KL: 48.0012, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7167, Val Loss: 48.7057, Recon: 0.7122, KL: 48.0045, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7197, Val Loss: 48.7035, Recon: 0.7164, KL: 48.0032, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7118, Val Loss: 48.7187, Recon: 0.7077, KL: 48.0040, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7085, Val Loss: 48.6989, Recon: 0.7039, KL: 48.0046, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7144, Val Loss: 48.6989, Recon: 0.7093, KL: 48.0051, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7039, Val Loss: 48.6850, Recon: 0.7008, KL: 48.0031, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7047, Val Loss: 48.6894, Recon: 0.7014, KL: 48.0033, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7002, Val Loss: 48.6858, Recon: 0.6948, KL: 48.0054, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7077, Val Loss: 48.6834, Recon: 0.6974, KL: 48.0103, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6971, Val Loss: 48.6979, Recon: 0.6916, KL: 48.0056, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7034, Val Loss: 48.6766, Recon: 0.6992, KL: 48.0042, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7006, Val Loss: 48.6867, Recon: 0.6947, KL: 48.0059, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7011, Val Loss: 48.6855, Recon: 0.6976, KL: 48.0035, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6897, Val Loss: 48.6837, Recon: 0.6823, KL: 48.0074, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6839, Val Loss: 48.6865, Recon: 0.6798, KL: 48.0041, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6892, Val Loss: 48.6793, Recon: 0.6859, KL: 48.0033, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6841, Val Loss: 48.6806, Recon: 0.6800, KL: 48.0041, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6902, Val Loss: 48.6792, Recon: 0.6863, KL: 48.0040, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6820, Val Loss: 48.6805, Recon: 0.6792, KL: 48.0028, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6766, Val Loss: 48.6739, Recon: 0.6747, KL: 48.0018, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6811, Val Loss: 48.6764, Recon: 0.6779, KL: 48.0032, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6814, Val Loss: 48.6684, Recon: 0.6789, KL: 48.0026, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6721, Val Loss: 48.6678, Recon: 0.6696, KL: 48.0025, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6838, Val Loss: 48.6821, Recon: 0.6795, KL: 48.0043, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6820, Val Loss: 48.6729, Recon: 0.6787, KL: 48.0033, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6702, Val Loss: 48.6729, Recon: 0.6688, KL: 48.0014, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6795, Val Loss: 48.6685, Recon: 0.6770, KL: 48.0025, KL_weight: 4.8000
Saved model 75 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_74.pt
Training bootstrap model 76/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9622, Val Loss: 0.7262, Recon: 0.9622, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6949, Val Loss: 4.6470, Recon: 0.8229, KL: 3.8720, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4506, Val Loss: 9.4260, Recon: 0.7920, KL: 8.6586, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2283, Val Loss: 14.1891, Recon: 0.7735, KL: 13.4548, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0236, Val Loss: 18.9713, Recon: 0.7700, KL: 18.2535, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8164, Val Loss: 23.7891, Recon: 0.7643, KL: 23.0521, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6141, Val Loss: 28.6173, Recon: 0.7610, KL: 27.8531, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.3932, Val Loss: 33.3673, Recon: 0.7478, KL: 32.6454, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1959, Val Loss: 38.1941, Recon: 0.7496, KL: 37.4463, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9820, Val Loss: 42.9852, Recon: 0.7372, KL: 42.2448, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7943, Val Loss: 47.7733, Recon: 0.7434, KL: 47.0510, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7435, Val Loss: 48.7323, Recon: 0.7387, KL: 48.0048, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7475, Val Loss: 48.7371, Recon: 0.7413, KL: 48.0062, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7409, Val Loss: 48.7305, Recon: 0.7376, KL: 48.0033, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7519, Val Loss: 48.7306, Recon: 0.7463, KL: 48.0056, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7403, Val Loss: 48.7359, Recon: 0.7363, KL: 48.0040, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7299, Val Loss: 48.7086, Recon: 0.7269, KL: 48.0030, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7427, Val Loss: 48.7262, Recon: 0.7356, KL: 48.0071, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7329, Val Loss: 48.7123, Recon: 0.7267, KL: 48.0062, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7227, Val Loss: 48.7171, Recon: 0.7200, KL: 48.0026, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7402, Val Loss: 48.7212, Recon: 0.7316, KL: 48.0086, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7300, Val Loss: 48.7505, Recon: 0.7241, KL: 48.0059, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7310, Val Loss: 48.7133, Recon: 0.7216, KL: 48.0093, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7183, Val Loss: 48.7226, Recon: 0.7145, KL: 48.0038, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7133, Val Loss: 48.7016, Recon: 0.7080, KL: 48.0053, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7067, Val Loss: 48.7203, Recon: 0.7037, KL: 48.0030, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7158, Val Loss: 48.7090, Recon: 0.7101, KL: 48.0057, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7092, Val Loss: 48.7077, Recon: 0.7026, KL: 48.0066, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7159, Val Loss: 48.7247, Recon: 0.7108, KL: 48.0050, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7070, Val Loss: 48.7090, Recon: 0.7040, KL: 48.0031, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7082, Val Loss: 48.7091, Recon: 0.7029, KL: 48.0054, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7157, Val Loss: 48.7205, Recon: 0.7039, KL: 48.0118, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7155, Val Loss: 48.7104, Recon: 0.7089, KL: 48.0066, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7035, Val Loss: 48.7071, Recon: 0.6996, KL: 48.0039, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7161, Val Loss: 48.6980, Recon: 0.7113, KL: 48.0048, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.6998, Val Loss: 48.6986, Recon: 0.6928, KL: 48.0069, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6966, Val Loss: 48.6990, Recon: 0.6914, KL: 48.0052, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.6971, Val Loss: 48.6871, Recon: 0.6933, KL: 48.0038, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6998, Val Loss: 48.6929, Recon: 0.6953, KL: 48.0045, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6961, Val Loss: 48.6956, Recon: 0.6930, KL: 48.0031, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7081, Val Loss: 48.6945, Recon: 0.7026, KL: 48.0054, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6865, Val Loss: 48.6876, Recon: 0.6836, KL: 48.0029, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6916, Val Loss: 48.6867, Recon: 0.6874, KL: 48.0041, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6894, Val Loss: 48.6918, Recon: 0.6857, KL: 48.0038, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6825, Val Loss: 48.6858, Recon: 0.6795, KL: 48.0030, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7019, Val Loss: 48.6829, Recon: 0.6980, KL: 48.0040, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6773, Val Loss: 48.6878, Recon: 0.6754, KL: 48.0018, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6866, Val Loss: 48.6846, Recon: 0.6813, KL: 48.0053, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6824, Val Loss: 48.6886, Recon: 0.6797, KL: 48.0027, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6893, Val Loss: 48.6951, Recon: 0.6838, KL: 48.0055, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6948, Val Loss: 48.6904, Recon: 0.6894, KL: 48.0054, KL_weight: 4.8000
Saved model 76 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_75.pt
Training bootstrap model 77/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 1.0087, Val Loss: 0.7679, Recon: 1.0087, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7165, Val Loss: 4.6340, Recon: 0.8411, KL: 3.8754, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4673, Val Loss: 9.4203, Recon: 0.8069, KL: 8.6604, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2505, Val Loss: 14.2003, Recon: 0.7965, KL: 13.4540, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0343, Val Loss: 18.9947, Recon: 0.7840, KL: 18.2503, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8221, Val Loss: 23.7865, Recon: 0.7718, KL: 23.0503, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6214, Val Loss: 28.5817, Recon: 0.7703, KL: 27.8512, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4260, Val Loss: 33.3719, Recon: 0.7719, KL: 32.6541, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2193, Val Loss: 38.1919, Recon: 0.7614, KL: 37.4579, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9967, Val Loss: 42.9849, Recon: 0.7518, KL: 42.2448, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7979, Val Loss: 47.7707, Recon: 0.7534, KL: 47.0445, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7565, Val Loss: 48.7417, Recon: 0.7506, KL: 48.0059, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7522, Val Loss: 48.7142, Recon: 0.7449, KL: 48.0073, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7620, Val Loss: 48.7341, Recon: 0.7536, KL: 48.0084, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7456, Val Loss: 48.7394, Recon: 0.7408, KL: 48.0048, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7375, Val Loss: 48.7341, Recon: 0.7335, KL: 48.0040, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7322, Val Loss: 48.7127, Recon: 0.7291, KL: 48.0031, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7433, Val Loss: 48.7101, Recon: 0.7378, KL: 48.0055, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7357, Val Loss: 48.7436, Recon: 0.7277, KL: 48.0080, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7294, Val Loss: 48.7144, Recon: 0.7253, KL: 48.0041, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7730, Val Loss: 48.7253, Recon: 0.7470, KL: 48.0261, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7237, Val Loss: 48.7186, Recon: 0.7202, KL: 48.0035, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7321, Val Loss: 48.7209, Recon: 0.7277, KL: 48.0044, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7233, Val Loss: 48.7207, Recon: 0.7197, KL: 48.0036, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7453, Val Loss: 48.7274, Recon: 0.7403, KL: 48.0050, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7133, Val Loss: 48.6981, Recon: 0.7092, KL: 48.0041, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7264, Val Loss: 48.7090, Recon: 0.7232, KL: 48.0031, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7178, Val Loss: 48.6997, Recon: 0.7132, KL: 48.0046, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7156, Val Loss: 48.7382, Recon: 0.7122, KL: 48.0034, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7314, Val Loss: 48.7043, Recon: 0.7253, KL: 48.0061, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7108, Val Loss: 48.7092, Recon: 0.7065, KL: 48.0044, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7587, Val Loss: 48.7324, Recon: 0.7346, KL: 48.0242, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7170, Val Loss: 48.7131, Recon: 0.7109, KL: 48.0061, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7112, Val Loss: 48.6961, Recon: 0.7057, KL: 48.0055, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.6985, Val Loss: 48.6941, Recon: 0.6959, KL: 48.0026, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7143, Val Loss: 48.7075, Recon: 0.7085, KL: 48.0058, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7146, Val Loss: 48.6992, Recon: 0.7055, KL: 48.0091, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7131, Val Loss: 48.7032, Recon: 0.7064, KL: 48.0066, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.6947, Val Loss: 48.6830, Recon: 0.6918, KL: 48.0030, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6938, Val Loss: 48.6925, Recon: 0.6905, KL: 48.0033, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6932, Val Loss: 48.6777, Recon: 0.6905, KL: 48.0027, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6979, Val Loss: 48.6864, Recon: 0.6935, KL: 48.0043, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7000, Val Loss: 48.6969, Recon: 0.6951, KL: 48.0049, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6911, Val Loss: 48.6724, Recon: 0.6885, KL: 48.0027, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6940, Val Loss: 48.6963, Recon: 0.6897, KL: 48.0042, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.7064, Val Loss: 48.6847, Recon: 0.6945, KL: 48.0119, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6964, Val Loss: 48.6923, Recon: 0.6932, KL: 48.0032, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7059, Val Loss: 48.7014, Recon: 0.6922, KL: 48.0137, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6947, Val Loss: 48.7011, Recon: 0.6929, KL: 48.0019, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6845, Val Loss: 48.6933, Recon: 0.6820, KL: 48.0025, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6851, Val Loss: 48.6871, Recon: 0.6820, KL: 48.0032, KL_weight: 4.8000
Saved model 77 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_76.pt
Training bootstrap model 78/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9476, Val Loss: 0.7239, Recon: 0.9476, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6912, Val Loss: 4.6551, Recon: 0.8245, KL: 3.8667, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4535, Val Loss: 9.4162, Recon: 0.7972, KL: 8.6563, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2429, Val Loss: 14.2112, Recon: 0.7885, KL: 13.4544, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0227, Val Loss: 18.9766, Recon: 0.7738, KL: 18.2490, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8045, Val Loss: 23.7759, Recon: 0.7586, KL: 23.0458, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6086, Val Loss: 28.5796, Recon: 0.7616, KL: 27.8470, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4052, Val Loss: 33.3848, Recon: 0.7564, KL: 32.6488, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2027, Val Loss: 38.1671, Recon: 0.7555, KL: 37.4472, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9963, Val Loss: 42.9824, Recon: 0.7493, KL: 42.2471, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8121, Val Loss: 47.7777, Recon: 0.7635, KL: 47.0486, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7588, Val Loss: 48.7222, Recon: 0.7508, KL: 48.0080, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7774, Val Loss: 48.7161, Recon: 0.7567, KL: 48.0207, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7507, Val Loss: 48.7327, Recon: 0.7451, KL: 48.0055, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7389, Val Loss: 48.7135, Recon: 0.7356, KL: 48.0034, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7289, Val Loss: 48.7236, Recon: 0.7253, KL: 48.0036, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7366, Val Loss: 48.7241, Recon: 0.7340, KL: 48.0026, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7384, Val Loss: 48.7296, Recon: 0.7355, KL: 48.0028, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7446, Val Loss: 48.7293, Recon: 0.7402, KL: 48.0044, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7275, Val Loss: 48.7134, Recon: 0.7262, KL: 48.0013, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7239, Val Loss: 48.7131, Recon: 0.7207, KL: 48.0032, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7371, Val Loss: 48.7070, Recon: 0.7325, KL: 48.0046, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7483, Val Loss: 48.7205, Recon: 0.7404, KL: 48.0079, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7270, Val Loss: 48.7090, Recon: 0.7229, KL: 48.0041, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7484, Val Loss: 48.7383, Recon: 0.7374, KL: 48.0110, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7280, Val Loss: 48.7269, Recon: 0.7204, KL: 48.0076, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7327, Val Loss: 48.7104, Recon: 0.7304, KL: 48.0023, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7227, Val Loss: 48.7295, Recon: 0.7176, KL: 48.0051, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7290, Val Loss: 48.7126, Recon: 0.7239, KL: 48.0051, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7299, Val Loss: 48.7128, Recon: 0.7248, KL: 48.0051, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7204, Val Loss: 48.7094, Recon: 0.7161, KL: 48.0043, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7203, Val Loss: 48.6946, Recon: 0.7159, KL: 48.0044, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7169, Val Loss: 48.6976, Recon: 0.7143, KL: 48.0026, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7233, Val Loss: 48.7252, Recon: 0.7189, KL: 48.0044, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7169, Val Loss: 48.7111, Recon: 0.7129, KL: 48.0039, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7061, Val Loss: 48.7059, Recon: 0.7042, KL: 48.0019, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7027, Val Loss: 48.6878, Recon: 0.6981, KL: 48.0047, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7148, Val Loss: 48.6914, Recon: 0.7109, KL: 48.0039, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7058, Val Loss: 48.6889, Recon: 0.7019, KL: 48.0039, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7072, Val Loss: 48.6970, Recon: 0.7060, KL: 48.0012, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7071, Val Loss: 48.6866, Recon: 0.6982, KL: 48.0089, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.7139, Val Loss: 48.7118, Recon: 0.6924, KL: 48.0215, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.7046, Val Loss: 48.6881, Recon: 0.7027, KL: 48.0018, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7043, Val Loss: 48.6834, Recon: 0.6999, KL: 48.0044, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6934, Val Loss: 48.6829, Recon: 0.6867, KL: 48.0067, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6964, Val Loss: 48.6873, Recon: 0.6944, KL: 48.0020, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6979, Val Loss: 48.6804, Recon: 0.6942, KL: 48.0037, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6933, Val Loss: 48.6880, Recon: 0.6909, KL: 48.0024, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6945, Val Loss: 48.6880, Recon: 0.6895, KL: 48.0050, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6951, Val Loss: 48.6800, Recon: 0.6909, KL: 48.0042, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6939, Val Loss: 48.6747, Recon: 0.6899, KL: 48.0040, KL_weight: 4.8000
Saved model 78 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_77.pt
Training bootstrap model 79/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9572, Val Loss: 0.7152, Recon: 0.9572, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.7162, Val Loss: 4.6277, Recon: 0.8438, KL: 3.8724, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4791, Val Loss: 9.4203, Recon: 0.8198, KL: 8.6593, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2552, Val Loss: 14.2048, Recon: 0.8000, KL: 13.4552, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0459, Val Loss: 19.0116, Recon: 0.7884, KL: 18.2575, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8388, Val Loss: 23.8049, Recon: 0.7874, KL: 23.0514, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6350, Val Loss: 28.5859, Recon: 0.7818, KL: 27.8532, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4361, Val Loss: 33.3953, Recon: 0.7827, KL: 32.6534, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.2130, Val Loss: 38.1803, Recon: 0.7659, KL: 37.4470, KL_weight: 3.7440
Epoch 45/250, Train Loss: 43.0104, Val Loss: 42.9800, Recon: 0.7594, KL: 42.2510, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.8241, Val Loss: 47.7920, Recon: 0.7699, KL: 47.0542, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7618, Val Loss: 48.7272, Recon: 0.7572, KL: 48.0046, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7620, Val Loss: 48.7467, Recon: 0.7537, KL: 48.0083, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7684, Val Loss: 48.7399, Recon: 0.7598, KL: 48.0086, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7583, Val Loss: 48.7231, Recon: 0.7549, KL: 48.0033, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7450, Val Loss: 48.7252, Recon: 0.7417, KL: 48.0033, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7490, Val Loss: 48.7134, Recon: 0.7463, KL: 48.0027, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7424, Val Loss: 48.7245, Recon: 0.7392, KL: 48.0032, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7435, Val Loss: 48.7266, Recon: 0.7396, KL: 48.0039, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7453, Val Loss: 48.7171, Recon: 0.7388, KL: 48.0065, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7749, Val Loss: 48.7548, Recon: 0.7658, KL: 48.0091, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7417, Val Loss: 48.7088, Recon: 0.7394, KL: 48.0022, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7381, Val Loss: 48.7239, Recon: 0.7352, KL: 48.0029, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7411, Val Loss: 48.7135, Recon: 0.7335, KL: 48.0076, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7328, Val Loss: 48.7127, Recon: 0.7295, KL: 48.0032, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7433, Val Loss: 48.7314, Recon: 0.7344, KL: 48.0088, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7403, Val Loss: 48.7279, Recon: 0.7328, KL: 48.0075, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7423, Val Loss: 48.7171, Recon: 0.7343, KL: 48.0080, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7302, Val Loss: 48.7277, Recon: 0.7239, KL: 48.0063, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.7262, Val Loss: 48.7062, Recon: 0.7208, KL: 48.0054, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.7414, Val Loss: 48.7178, Recon: 0.7331, KL: 48.0083, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.7398, Val Loss: 48.7180, Recon: 0.7231, KL: 48.0167, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.7219, Val Loss: 48.7023, Recon: 0.7185, KL: 48.0034, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.7238, Val Loss: 48.7114, Recon: 0.7191, KL: 48.0047, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7087, Val Loss: 48.7043, Recon: 0.7051, KL: 48.0036, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7172, Val Loss: 48.6854, Recon: 0.7108, KL: 48.0064, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.7029, Val Loss: 48.6855, Recon: 0.6995, KL: 48.0035, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7088, Val Loss: 48.6951, Recon: 0.7051, KL: 48.0036, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7019, Val Loss: 48.6815, Recon: 0.6985, KL: 48.0033, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.7001, Val Loss: 48.6891, Recon: 0.6963, KL: 48.0039, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.7114, Val Loss: 48.6934, Recon: 0.6956, KL: 48.0158, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6974, Val Loss: 48.6831, Recon: 0.6935, KL: 48.0039, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6958, Val Loss: 48.6776, Recon: 0.6930, KL: 48.0028, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.7054, Val Loss: 48.6992, Recon: 0.6924, KL: 48.0131, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.7137, Val Loss: 48.7014, Recon: 0.7063, KL: 48.0074, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6881, Val Loss: 48.6806, Recon: 0.6847, KL: 48.0034, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6888, Val Loss: 48.6839, Recon: 0.6855, KL: 48.0033, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.7076, Val Loss: 48.6931, Recon: 0.7033, KL: 48.0042, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6988, Val Loss: 48.6713, Recon: 0.6958, KL: 48.0030, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6942, Val Loss: 48.6854, Recon: 0.6890, KL: 48.0052, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6852, Val Loss: 48.6808, Recon: 0.6814, KL: 48.0038, KL_weight: 4.8000
Saved model 79 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_78.pt
Training bootstrap model 80/80
Training data shape IM MODEL: torch.Size([1560, 644])
Epoch 1/250, Train Loss: 0.9475, Val Loss: 0.7286, Recon: 0.9475, KL: 0.0000, KL_weight: 0.0000
Epoch 5/250, Train Loss: 4.6806, Val Loss: 4.6426, Recon: 0.8124, KL: 3.8683, KL_weight: 0.3840
Epoch 10/250, Train Loss: 9.4570, Val Loss: 9.4186, Recon: 0.7941, KL: 8.6629, KL_weight: 0.8640
Epoch 15/250, Train Loss: 14.2414, Val Loss: 14.2289, Recon: 0.7880, KL: 13.4534, KL_weight: 1.3440
Epoch 20/250, Train Loss: 19.0297, Val Loss: 19.0025, Recon: 0.7763, KL: 18.2534, KL_weight: 1.8240
Epoch 25/250, Train Loss: 23.8291, Val Loss: 23.8056, Recon: 0.7716, KL: 23.0575, KL_weight: 2.3040
Epoch 30/250, Train Loss: 28.6110, Val Loss: 28.6012, Recon: 0.7614, KL: 27.8496, KL_weight: 2.7840
Epoch 35/250, Train Loss: 33.4047, Val Loss: 33.4051, Recon: 0.7578, KL: 32.6469, KL_weight: 3.2640
Epoch 40/250, Train Loss: 38.1982, Val Loss: 38.1902, Recon: 0.7516, KL: 37.4466, KL_weight: 3.7440
Epoch 45/250, Train Loss: 42.9984, Val Loss: 42.9890, Recon: 0.7502, KL: 42.2483, KL_weight: 4.2240
Epoch 50/250, Train Loss: 47.7918, Val Loss: 47.7753, Recon: 0.7484, KL: 47.0434, KL_weight: 4.7040
Epoch 55/250, Train Loss: 48.7605, Val Loss: 48.7352, Recon: 0.7511, KL: 48.0094, KL_weight: 4.8000
Epoch 60/250, Train Loss: 48.7779, Val Loss: 48.7524, Recon: 0.7530, KL: 48.0250, KL_weight: 4.8000
Epoch 65/250, Train Loss: 48.7605, Val Loss: 48.7268, Recon: 0.7529, KL: 48.0076, KL_weight: 4.8000
Epoch 70/250, Train Loss: 48.7371, Val Loss: 48.7206, Recon: 0.7327, KL: 48.0044, KL_weight: 4.8000
Epoch 75/250, Train Loss: 48.7382, Val Loss: 48.7062, Recon: 0.7344, KL: 48.0038, KL_weight: 4.8000
Epoch 80/250, Train Loss: 48.7360, Val Loss: 48.7162, Recon: 0.7342, KL: 48.0019, KL_weight: 4.8000
Epoch 85/250, Train Loss: 48.7309, Val Loss: 48.7171, Recon: 0.7269, KL: 48.0040, KL_weight: 4.8000
Epoch 90/250, Train Loss: 48.7296, Val Loss: 48.7308, Recon: 0.7249, KL: 48.0047, KL_weight: 4.8000
Epoch 95/250, Train Loss: 48.7258, Val Loss: 48.7092, Recon: 0.7231, KL: 48.0026, KL_weight: 4.8000
Epoch 100/250, Train Loss: 48.7231, Val Loss: 48.7153, Recon: 0.7196, KL: 48.0035, KL_weight: 4.8000
Epoch 105/250, Train Loss: 48.7349, Val Loss: 48.7330, Recon: 0.7275, KL: 48.0074, KL_weight: 4.8000
Epoch 110/250, Train Loss: 48.7199, Val Loss: 48.7055, Recon: 0.7176, KL: 48.0023, KL_weight: 4.8000
Epoch 115/250, Train Loss: 48.7289, Val Loss: 48.7126, Recon: 0.7217, KL: 48.0072, KL_weight: 4.8000
Epoch 120/250, Train Loss: 48.7159, Val Loss: 48.7014, Recon: 0.7098, KL: 48.0061, KL_weight: 4.8000
Epoch 125/250, Train Loss: 48.7232, Val Loss: 48.6943, Recon: 0.7164, KL: 48.0068, KL_weight: 4.8000
Epoch 130/250, Train Loss: 48.7162, Val Loss: 48.6958, Recon: 0.7111, KL: 48.0051, KL_weight: 4.8000
Epoch 135/250, Train Loss: 48.7129, Val Loss: 48.7003, Recon: 0.7069, KL: 48.0059, KL_weight: 4.8000
Epoch 140/250, Train Loss: 48.7020, Val Loss: 48.7044, Recon: 0.6979, KL: 48.0042, KL_weight: 4.8000
Epoch 145/250, Train Loss: 48.6964, Val Loss: 48.6990, Recon: 0.6934, KL: 48.0031, KL_weight: 4.8000
Epoch 150/250, Train Loss: 48.6966, Val Loss: 48.6868, Recon: 0.6936, KL: 48.0030, KL_weight: 4.8000
Epoch 155/250, Train Loss: 48.6976, Val Loss: 48.6952, Recon: 0.6928, KL: 48.0048, KL_weight: 4.8000
Epoch 160/250, Train Loss: 48.6934, Val Loss: 48.6925, Recon: 0.6889, KL: 48.0045, KL_weight: 4.8000
Epoch 165/250, Train Loss: 48.6906, Val Loss: 48.6865, Recon: 0.6884, KL: 48.0022, KL_weight: 4.8000
Epoch 170/250, Train Loss: 48.7003, Val Loss: 48.6929, Recon: 0.6972, KL: 48.0031, KL_weight: 4.8000
Epoch 175/250, Train Loss: 48.7106, Val Loss: 48.6968, Recon: 0.7053, KL: 48.0053, KL_weight: 4.8000
Epoch 180/250, Train Loss: 48.6991, Val Loss: 48.6899, Recon: 0.6964, KL: 48.0027, KL_weight: 4.8000
Epoch 185/250, Train Loss: 48.7242, Val Loss: 48.6919, Recon: 0.7120, KL: 48.0122, KL_weight: 4.8000
Epoch 190/250, Train Loss: 48.7021, Val Loss: 48.6938, Recon: 0.6947, KL: 48.0075, KL_weight: 4.8000
Epoch 195/250, Train Loss: 48.6998, Val Loss: 48.6818, Recon: 0.6940, KL: 48.0058, KL_weight: 4.8000
Epoch 200/250, Train Loss: 48.6912, Val Loss: 48.6798, Recon: 0.6878, KL: 48.0034, KL_weight: 4.8000
Epoch 205/250, Train Loss: 48.6913, Val Loss: 48.6859, Recon: 0.6865, KL: 48.0048, KL_weight: 4.8000
Epoch 210/250, Train Loss: 48.6845, Val Loss: 48.6771, Recon: 0.6804, KL: 48.0042, KL_weight: 4.8000
Epoch 215/250, Train Loss: 48.6871, Val Loss: 48.6801, Recon: 0.6831, KL: 48.0040, KL_weight: 4.8000
Epoch 220/250, Train Loss: 48.6913, Val Loss: 48.6872, Recon: 0.6878, KL: 48.0035, KL_weight: 4.8000
Epoch 225/250, Train Loss: 48.6866, Val Loss: 48.6776, Recon: 0.6823, KL: 48.0044, KL_weight: 4.8000
Epoch 230/250, Train Loss: 48.6857, Val Loss: 48.6910, Recon: 0.6831, KL: 48.0026, KL_weight: 4.8000
Epoch 235/250, Train Loss: 48.6819, Val Loss: 48.6770, Recon: 0.6797, KL: 48.0022, KL_weight: 4.8000
Epoch 240/250, Train Loss: 48.6846, Val Loss: 48.6825, Recon: 0.6799, KL: 48.0047, KL_weight: 4.8000
Epoch 245/250, Train Loss: 48.6877, Val Loss: 48.6848, Recon: 0.6809, KL: 48.0068, KL_weight: 4.8000
Epoch 250/250, Train Loss: 48.6808, Val Loss: 48.6941, Recon: 0.6773, KL: 48.0035, KL_weight: 4.8000
Saved model 80 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/models/bootstrap_model_79.pt

================================================================================
RUNNING POST-TRAINING DIAGNOSTICS
================================================================================

================================================================================
STARTING VAE DIAGNOSTICS
================================================================================

============================================================
Extracting latents for: HC_train
============================================================

============================================================
Extracting latents for: HC_valid
============================================================

============================================================
POSTERIOR COLLAPSE CHECK - HC_train
============================================================

Latent Space Statistics (across 1560 samples):
  Mean variance per dimension: 0.127916
  Std variance per dimension: 0.017680
  Min variance: 0.101369
  Max variance: 0.162724

  Collapsed dimensions (var < 0.01): 0/20

  Mean logvar per dimension: -1.1998
  Std logvar per dimension: 0.0758

  Mean L2 norm (distance to origin): 1.5733
  Std L2 norm: 0.5564

  Active dimensions (var > 0.1): 20/20

============================================================
POSTERIOR COLLAPSE CHECK - HC_valid
============================================================

Latent Space Statistics (across 390 samples):
  Mean variance per dimension: 0.116592
  Std variance per dimension: 0.015461
  Min variance: 0.093989
  Max variance: 0.151105

  Collapsed dimensions (var < 0.01): 0/20

  Mean logvar per dimension: -1.2109
  Std logvar per dimension: 0.0777

  Mean L2 norm (distance to origin): 1.5067
  Std L2 norm: 0.5885

  Active dimensions (var > 0.1): 17/20

============================================================
GROUP COMPARISON: HC_train vs HC_valid
============================================================

KL Divergence Statistics:
  HC    - Mean: 6.6347, Std: 1.0352, Median: 6.8039
  HC_valid - Mean: 6.6113, Std: 1.0556, Median: 6.7583
  Difference: -0.0234
  T-test: t=0.3979, p=0.6908
    PROBLEM DETECTED: HC_valid has LOWER KL than HC!

Reconstruction Error Statistics:
  HC    - Mean: 0.679409, Std: 0.220900
  HC_valid - Mean: 0.672408, Std: 0.166303
  Difference: -0.007000
  T-test: t=0.5854, p=0.5583

Latent Space Variance:
  HC    - Mean variance: 0.127916
  HC_valid - Mean variance: 0.116592
  Ratio: 0.9115
    HC_valid has LESS variance  easier to fit to prior!

Distance to Origin (L2 norm):
  HC    - Mean: 1.5733, Std: 0.5564
  HC_valid - Mean: 1.5067, Std: 0.5885

============================================================
MAHALANOBIS DISTANCE (proper anomaly detection)
============================================================
  HC    - Mean Mahalanobis: 4.1674, Std: 1.1502
  HC_valid - Mean Mahalanobis: 4.1932, Std: 1.1299
  T-test: t=-0.3969, p=0.6915
   GOOD: HC_valid is further from HC distribution

 Diagnostic plots saved to: /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/diagnostics_post_training/vae_diagnostics.png
 Diagnostic report saved to: /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/diagnostics_post_training/diagnostic_report.txt

================================================================================
DIAGNOSTICS COMPLETE
================================================================================
Outputs saved to: /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/diagnostics_post_training
 Post-training diagnostics completed
  Diagnostic plots saved to: /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640/diagnostics_post_training/

Key Findings:
  HC Train KL: 6.6347
  HC Valid KL: 6.6113
  Collapsed dimensions: 0/20
Successfully trained 80 bootstrap models
Normative modeling training completed successfully!
Results saved to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640
Normative modeling complete. Results saved to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_Vgm_G_T_lpba40_neuromorphometrics_ibsr_aparc_dk40_aparc_destrieux_columnwise_20251103_1640
