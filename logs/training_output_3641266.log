Training set erstellt: /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/data_training/train_metadataHC_0.720251022_1630.csv (1955 Patienten)
Test set erstellt: /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/data_training/test_metadataHC_0.720251022_1630.csv (2213 Patienten, davon 838 HC und 1375 andere)
Only one CUDA device found. Using cuda:0

####################################################################################################

Starting Catatonia CPA training session NormativeVAE20_all_20251022_1630_HC at 2025-10-22_18-30
-----------------------------------------------------------------------------------------------

Using Device:        cuda:0
Queued Epochs:       200
Batch Size:          16
Data Summary:        ['/net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/data_training/train_metadataHC_0.720251022_1630.csv']
MRI Data Directory:  /net/data.isilon/ag-cherrmann/lduttenhoefer/project/CAT12_newvals/QC/CAT12_results_final.csv
Loading Model:       False
Output Directory:    /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_a_l_l_all_20251022_1630

More details in log file: /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_a_l_l_all_20251022_1630/logs/2025-10-22_18-30_NormativeVAE20_all_20251022_1630_HC_training_log_.txt

####################################################################################################
Starting normative modeling with atlas: all, epochs: 200, bootstraps: 100
Configuration saved to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_a_l_l_all_20251022_1630/config.csv
Using device: cuda
Loading NORM control data...
[INFO] Loading MRI data from: /net/data.isilon/ag-cherrmann/lduttenhoefer/project/CAT12_newvals/QC/CAT12_results_final.csv
[INFO] Processing atlases: ['neuromorphometrics', 'lpba40', 'cobra', 'suit', 'ibsr', 'aal3', 'schaefer100', 'schaefer200', 'aparc_dk40', 'aparc_destrieux']
[INFO] Target volume types: ['Vgm', 'Vwm', 'Vcsf', 'G', 'T']
[INFO] Loaded MRI data with shape: (4163, 1211)
[INFO] Found 1194 ROI columns in MRI data
[INFO] Processing atlas: neuromorphometrics (prefix: Neurom)
[INFO] Found 123 columns for atlas neuromorphometrics
[INFO] Processing atlas: lpba40 (prefix: lpba40)
[INFO] Found 56 columns for atlas lpba40
[INFO] Processing atlas: cobra (prefix: Cobra)
[WARNING] No columns found for atlas cobra with volume types ['Vgm', 'Vwm', 'Vcsf', 'G', 'T']
[INFO] Processing atlas: suit (prefix: SUIT)
[INFO] Found 28 columns for atlas suit
[INFO] Processing atlas: ibsr (prefix: IBSR)
[INFO] Found 32 columns for atlas ibsr
[INFO] Processing atlas: aal3 (prefix: AAL3)
[INFO] Found 170 columns for atlas aal3
[INFO] Processing atlas: schaefer100 (prefix: Sch100)
[INFO] Found 100 columns for atlas schaefer100
[INFO] Processing atlas: schaefer200 (prefix: Sch200)
[INFO] Found 200 columns for atlas schaefer200
[INFO] Processing atlas: aparc_dk40 (prefix: DK40)
[INFO] Found 274 columns for atlas aparc_dk40
[INFO] Processing atlas: aparc_destrieux (prefix: Destrieux)
[INFO] Found 592 columns for atlas aparc_destrieux
[INFO] Selected 1142 feature columns total
[INFO] Total ROI names: 1575
[INFO] Data normalized and scaled
[INFO] Matching 1955 metadata entries with MRI data...
[INFO] Successfully matched 1954/1955 subjects
[WARNING] 1 subjects from metadata not found in MRI data
[WARNING] Unmatched files: ['sub-031461_T1w']
[INFO] Total subjects processed: 1954
[INFO] Total ROI features per subject: 1575
[INFO] Data loading complete!
Value counts of Diagnosis in annotations_norm:
Diagnosis
HC    1955
Name: count, dtype: int64
size annotations: 1955
size annotations: 1954
29
Number of ROIs in atlas: 1142
[INFO] 1560 subjects in training set
[INFO] 390 subjects in validation set
[WARNING] 4 subjects not found in annotations:
  - sub-031704_T1w
  - sub-NDARINVEY033HCZ_run01_T1w
  - sub-031705_T1w
  - sub-NDARINVKC627BAV_run01_T1w
                        Filename Data_Type  ... NSS_Motor NSS_Total
0                       sub-0001     train  ...       NaN       NaN
1                       sub-0004     train  ...       NaN       NaN
2                       sub-0011     train  ...       NaN       NaN
3                       sub-0013     train  ...       NaN       NaN
4                       sub-0016     train  ...       NaN       NaN
...                          ...       ...  ...       ...       ...
1946           sub-NM5946_0_MPR1     valid  ...       NaN       NaN
1947           sub-NM7365_0_MPR1     valid  ...       NaN       NaN
1948           sub-NM8356_0_MPR1     valid  ...       NaN       NaN
1949  sub-whiteCAT191_ses-01_T1w     valid  ...       0.0       3.0
1950  sub-whiteCAT200_ses-01_T1w     valid  ...       1.0       9.0

[1951 rows x 21 columns]
Using atlas: ['all']
Number of ROIs: 1142
---------------
Data Processing
---------------
Loading Data
  Training Data:       1560 subjects loaded
  Validation Data:      390 subjects loaded

Creating Model
--------------
tensor([[ 0.2859, -0.5647,  0.0562,  ...,  1.1793,  1.5319, -0.9285],
        [-0.1607,  0.2187,  0.6898,  ...,  0.0500,  0.8297,  0.1544],
        [-1.9391, -2.1443, -1.2141,  ..., -1.4026, -0.7805,  0.0638],
        ...,
        [ 0.6400,  0.4137,  1.6251,  ..., -0.3193, -1.4567,  0.4248],
        [-0.0431, -0.2942, -1.0007,  ...,  1.4647, -0.5638, -1.0932],
        [ 2.3372,  3.1303,  1.8980,  ..., -2.2818, -0.0592, -0.6351]])
tensor([[-0.1999, -0.1268,  0.7143,  ...,  0.2068, -0.1990,  0.5067],
        [-1.2676, -1.4426,  0.1272,  ..., -0.1299,  0.6742, -0.4274],
        [ 0.2515,  0.4309,  0.7222,  ..., -0.2551,  0.1850,  0.3267],
        ...,
        [-0.0706, -0.4081, -0.7889,  ...,  1.8792,  0.6591, -0.4848],
        [-1.1637, -1.2769, -1.5934,  ...,  0.1024,  0.9673, -0.6562],
        [-2.0848, -2.1356, -1.2434,  ...,  1.6938, -0.3336,  0.8062]])
Training data shape: torch.Size([1560, 1142])
Validation data shape: torch.Size([390, 1142])
/net/data.isilon/ag-cherrmann/lduttenhoefer/project/miniconda3/envs/LISA_ba_env/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/src/models/ContrastVAE_2D.py:132: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = GradScaler()
Model Archtecture: 
NormativeVAE_2D(
  (encoder): Sequential(
    (0): Linear(in_features=1142, out_features=100, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=100, out_features=100, bias=True)
    (4): LeakyReLU(negative_slope=0.01)
    (5): Dropout(p=0.1, inplace=False)
    (6): Linear(in_features=100, out_features=20, bias=True)
  )
  (fc_mu): Linear(in_features=20, out_features=20, bias=True)
  (fc_var): Linear(in_features=20, out_features=20, bias=True)
  (decoder): Sequential(
    (0): Linear(in_features=20, out_features=100, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=100, out_features=100, bias=True)
    (4): LeakyReLU(negative_slope=0.01)
    (5): Dropout(p=0.1, inplace=False)
    (6): Linear(in_features=100, out_features=1142, bias=True)
  )
)

    latent_dim:          20
    optimizer:           Adam (
    scheduler:           <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x2b82f7026f10>
    scaler:              <torch.cuda.amp.grad_scaler.GradScaler object at 0x2b82f613d9d0>
    recon_loss_weight:   16.6449
    kldiv_loss_weight:   1.2
    contr_loss_weight:   0.0
    schedule_on_validation: True
    scheduler_patience:  10
    scheduler_factor:    0.5
    learning_rate:       0.000559
    weight_decay:        1e-05
    dropout_prob:        0.1
    device:              cuda
    Total Parameters:    254,802
    Trainable Params:    254,802
Training baseline model before bootstrap training...
Training data shape IM MODEL: torch.Size([1560, 1142])
Epoch 1/200, Train Loss: 1.2251, Val Loss: 1.0282, Recon: 1.0171, KL: 0.2079
Epoch 5/200, Train Loss: 1.0141, Val Loss: 0.9891, Recon: 1.0099, KL: 0.0041
Epoch 10/200, Train Loss: 1.0110, Val Loss: 0.9876, Recon: 1.0102, KL: 0.0009
Epoch 15/200, Train Loss: 1.0092, Val Loss: 0.9878, Recon: 1.0088, KL: 0.0004
Epoch 20/200, Train Loss: 1.0095, Val Loss: 0.9872, Recon: 1.0092, KL: 0.0003
Epoch 25/200, Train Loss: 1.0088, Val Loss: 0.9870, Recon: 1.0085, KL: 0.0003
Epoch 30/200, Train Loss: 0.8332, Val Loss: 0.7662, Recon: 0.7462, KL: 0.0870
Epoch 35/200, Train Loss: 0.7741, Val Loss: 0.7454, Recon: 0.6898, KL: 0.0843
Epoch 40/200, Train Loss: 0.7506, Val Loss: 0.7341, Recon: 0.6602, KL: 0.0904
Epoch 45/200, Train Loss: 0.7356, Val Loss: 0.7111, Recon: 0.6522, KL: 0.0835
Epoch 50/200, Train Loss: 0.7147, Val Loss: 0.7024, Recon: 0.6332, KL: 0.0815
Epoch 55/200, Train Loss: 0.7044, Val Loss: 0.6822, Recon: 0.6245, KL: 0.0799
Epoch 60/200, Train Loss: 0.7011, Val Loss: 0.6800, Recon: 0.6217, KL: 0.0794
Epoch 65/200, Train Loss: 0.6983, Val Loss: 0.6826, Recon: 0.6184, KL: 0.0799
Epoch 70/200, Train Loss: 0.7030, Val Loss: 0.6821, Recon: 0.6218, KL: 0.0812
Epoch 75/200, Train Loss: 0.6986, Val Loss: 0.6832, Recon: 0.6170, KL: 0.0817
Epoch 80/200, Train Loss: 0.6965, Val Loss: 0.6818, Recon: 0.6163, KL: 0.0802
Epoch 85/200, Train Loss: 0.6995, Val Loss: 0.6843, Recon: 0.6181, KL: 0.0814
Epoch 90/200, Train Loss: 0.6962, Val Loss: 0.6798, Recon: 0.6163, KL: 0.0798
Epoch 95/200, Train Loss: 0.6952, Val Loss: 0.6780, Recon: 0.6138, KL: 0.0813
Epoch 100/200, Train Loss: 0.6965, Val Loss: 0.6794, Recon: 0.6164, KL: 0.0801
Epoch 105/200, Train Loss: 0.6958, Val Loss: 0.6804, Recon: 0.6153, KL: 0.0805
Epoch 110/200, Train Loss: 0.6940, Val Loss: 0.6830, Recon: 0.6140, KL: 0.0800
Epoch 115/200, Train Loss: 0.6937, Val Loss: 0.6798, Recon: 0.6127, KL: 0.0809
Epoch 120/200, Train Loss: 0.6969, Val Loss: 0.6869, Recon: 0.6151, KL: 0.0817
Epoch 125/200, Train Loss: 0.6926, Val Loss: 0.6810, Recon: 0.6128, KL: 0.0798
Epoch 130/200, Train Loss: 0.6906, Val Loss: 0.6822, Recon: 0.6116, KL: 0.0790
Epoch 135/200, Train Loss: 0.6973, Val Loss: 0.6838, Recon: 0.6154, KL: 0.0819
Epoch 140/200, Train Loss: 0.6912, Val Loss: 0.6822, Recon: 0.6119, KL: 0.0793
Epoch 145/200, Train Loss: 0.6899, Val Loss: 0.6809, Recon: 0.6114, KL: 0.0785
Epoch 150/200, Train Loss: 0.6893, Val Loss: 0.6775, Recon: 0.6112, KL: 0.0781
Epoch 155/200, Train Loss: 0.6910, Val Loss: 0.6788, Recon: 0.6112, KL: 0.0798
Epoch 160/200, Train Loss: 0.6920, Val Loss: 0.6824, Recon: 0.6129, KL: 0.0791
Epoch 165/200, Train Loss: 0.6926, Val Loss: 0.6843, Recon: 0.6107, KL: 0.0819
Epoch 170/200, Train Loss: 0.6881, Val Loss: 0.6841, Recon: 0.6079, KL: 0.0802
Epoch 175/200, Train Loss: 0.6948, Val Loss: 0.6848, Recon: 0.6121, KL: 0.0827
Epoch 180/200, Train Loss: 0.6920, Val Loss: 0.6844, Recon: 0.6120, KL: 0.0800
Epoch 185/200, Train Loss: 0.6928, Val Loss: 0.6862, Recon: 0.6119, KL: 0.0809
Epoch 190/200, Train Loss: 0.6912, Val Loss: 0.6851, Recon: 0.6114, KL: 0.0798
Epoch 195/200, Train Loss: 0.6911, Val Loss: 0.6792, Recon: 0.6100, KL: 0.0811
Epoch 200/200, Train Loss: 0.6902, Val Loss: 0.6832, Recon: 0.6096, KL: 0.0805
Training bootstrap models...
Starting bootstrap training with 100 iterations
Training bootstrap model 1/100
Training data shape IM MODEL: torch.Size([1560, 1142])
Epoch 1/200, Train Loss: 1.1606, Val Loss: 1.0260, Recon: 0.9888, KL: 0.1718
Epoch 5/200, Train Loss: 0.8294, Val Loss: 0.7741, Recon: 0.7309, KL: 0.0984
Epoch 10/200, Train Loss: 0.7662, Val Loss: 0.7518, Recon: 0.6808, KL: 0.0854
Epoch 15/200, Train Loss: 0.7216, Val Loss: 0.7062, Recon: 0.6402, KL: 0.0814
Epoch 20/200, Train Loss: 0.6930, Val Loss: 0.6984, Recon: 0.6167, KL: 0.0763
Epoch 25/200, Train Loss: 0.6934, Val Loss: 0.6898, Recon: 0.6145, KL: 0.0790
Epoch 30/200, Train Loss: 0.6972, Val Loss: 0.6864, Recon: 0.6171, KL: 0.0801
Epoch 35/200, Train Loss: 0.6922, Val Loss: 0.6865, Recon: 0.6119, KL: 0.0802
Epoch 40/200, Train Loss: 0.6892, Val Loss: 0.6841, Recon: 0.6098, KL: 0.0795
Epoch 45/200, Train Loss: 0.6892, Val Loss: 0.6823, Recon: 0.6117, KL: 0.0775
Epoch 50/200, Train Loss: 0.6880, Val Loss: 0.6853, Recon: 0.6086, KL: 0.0794
Epoch 55/200, Train Loss: 0.6900, Val Loss: 0.6860, Recon: 0.6100, KL: 0.0800
Epoch 60/200, Train Loss: 0.6878, Val Loss: 0.6799, Recon: 0.6084, KL: 0.0794
Epoch 65/200, Train Loss: 0.6848, Val Loss: 0.6867, Recon: 0.6054, KL: 0.0794
Epoch 70/200, Train Loss: 0.6873, Val Loss: 0.6800, Recon: 0.6077, KL: 0.0796
Epoch 75/200, Train Loss: 0.6859, Val Loss: 0.6856, Recon: 0.6061, KL: 0.0798
Epoch 80/200, Train Loss: 0.6849, Val Loss: 0.6821, Recon: 0.6063, KL: 0.0786
Epoch 85/200, Train Loss: 0.6864, Val Loss: 0.6842, Recon: 0.6065, KL: 0.0800
Epoch 90/200, Train Loss: 0.6842, Val Loss: 0.6874, Recon: 0.6062, KL: 0.0780
Epoch 95/200, Train Loss: 0.6834, Val Loss: 0.6811, Recon: 0.6045, KL: 0.0789
Epoch 100/200, Train Loss: 0.6852, Val Loss: 0.6781, Recon: 0.6055, KL: 0.0797
Epoch 105/200, Train Loss: 0.6823, Val Loss: 0.6821, Recon: 0.6037, KL: 0.0786
Epoch 110/200, Train Loss: 0.6834, Val Loss: 0.6834, Recon: 0.6031, KL: 0.0803
Epoch 115/200, Train Loss: 0.6840, Val Loss: 0.6808, Recon: 0.6055, KL: 0.0785
Epoch 120/200, Train Loss: 0.6830, Val Loss: 0.6844, Recon: 0.6047, KL: 0.0783
Epoch 125/200, Train Loss: 0.6842, Val Loss: 0.6803, Recon: 0.6050, KL: 0.0791
Epoch 130/200, Train Loss: 0.6822, Val Loss: 0.6799, Recon: 0.6038, KL: 0.0784
Epoch 135/200, Train Loss: 0.6840, Val Loss: 0.6808, Recon: 0.6052, KL: 0.0789
Epoch 140/200, Train Loss: 0.6827, Val Loss: 0.6831, Recon: 0.6025, KL: 0.0802
Epoch 145/200, Train Loss: 0.6833, Val Loss: 0.6829, Recon: 0.6037, KL: 0.0795
Epoch 150/200, Train Loss: 0.6841, Val Loss: 0.6866, Recon: 0.6049, KL: 0.0792
Epoch 155/200, Train Loss: 0.6834, Val Loss: 0.6814, Recon: 0.6034, KL: 0.0800
Epoch 160/200, Train Loss: 0.6819, Val Loss: 0.6775, Recon: 0.6026, KL: 0.0793
Epoch 165/200, Train Loss: 0.6814, Val Loss: 0.6827, Recon: 0.6021, KL: 0.0793
Epoch 170/200, Train Loss: 0.6868, Val Loss: 0.6815, Recon: 0.6051, KL: 0.0817
Epoch 175/200, Train Loss: 0.6826, Val Loss: 0.6835, Recon: 0.6036, KL: 0.0790
Epoch 180/200, Train Loss: 0.6799, Val Loss: 0.6865, Recon: 0.6013, KL: 0.0786
Epoch 185/200, Train Loss: 0.6821, Val Loss: 0.6809, Recon: 0.6031, KL: 0.0790
Epoch 190/200, Train Loss: 0.6819, Val Loss: 0.6865, Recon: 0.6022, KL: 0.0797
Epoch 195/200, Train Loss: 0.6792, Val Loss: 0.6910, Recon: 0.6019, KL: 0.0773
Epoch 200/200, Train Loss: 0.6813, Val Loss: 0.6820, Recon: 0.6033, KL: 0.0780
Saved model 1 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_a_l_l_all_20251022_1630/models/bootstrap_model_0.pt
Training bootstrap model 2/100
Training data shape IM MODEL: torch.Size([1560, 1142])
Epoch 1/200, Train Loss: 1.1439, Val Loss: 1.0214, Recon: 0.9851, KL: 0.1588
Epoch 5/200, Train Loss: 0.9821, Val Loss: 0.9895, Recon: 0.9790, KL: 0.0030
Epoch 10/200, Train Loss: 0.9780, Val Loss: 0.9875, Recon: 0.9773, KL: 0.0006
Epoch 15/200, Train Loss: 0.9768, Val Loss: 0.9856, Recon: 0.9753, KL: 0.0015
Epoch 20/200, Train Loss: 0.7753, Val Loss: 0.7791, Recon: 0.6918, KL: 0.0835
Epoch 25/200, Train Loss: 0.7354, Val Loss: 0.7094, Recon: 0.6553, KL: 0.0800
Epoch 30/200, Train Loss: 0.7057, Val Loss: 0.6852, Recon: 0.6289, KL: 0.0768
Epoch 35/200, Train Loss: 0.6986, Val Loss: 0.6814, Recon: 0.6215, KL: 0.0771
Epoch 40/200, Train Loss: 0.6937, Val Loss: 0.6847, Recon: 0.6183, KL: 0.0754
Epoch 45/200, Train Loss: 0.6978, Val Loss: 0.6841, Recon: 0.6180, KL: 0.0798
Epoch 50/200, Train Loss: 0.6946, Val Loss: 0.6878, Recon: 0.6178, KL: 0.0768
Epoch 55/200, Train Loss: 0.6946, Val Loss: 0.6850, Recon: 0.6165, KL: 0.0781
Epoch 60/200, Train Loss: 0.6951, Val Loss: 0.6803, Recon: 0.6149, KL: 0.0802
Epoch 65/200, Train Loss: 0.6949, Val Loss: 0.6862, Recon: 0.6156, KL: 0.0793
Epoch 70/200, Train Loss: 0.6934, Val Loss: 0.6834, Recon: 0.6146, KL: 0.0789
Epoch 75/200, Train Loss: 0.6904, Val Loss: 0.6854, Recon: 0.6133, KL: 0.0771
Epoch 80/200, Train Loss: 0.6917, Val Loss: 0.6856, Recon: 0.6144, KL: 0.0772
Epoch 85/200, Train Loss: 0.6924, Val Loss: 0.6819, Recon: 0.6139, KL: 0.0785
Epoch 90/200, Train Loss: 0.6922, Val Loss: 0.6787, Recon: 0.6127, KL: 0.0795
Epoch 95/200, Train Loss: 0.6910, Val Loss: 0.6783, Recon: 0.6135, KL: 0.0775
Epoch 100/200, Train Loss: 0.6892, Val Loss: 0.6890, Recon: 0.6109, KL: 0.0783
Epoch 105/200, Train Loss: 0.6900, Val Loss: 0.6840, Recon: 0.6128, KL: 0.0772
Epoch 110/200, Train Loss: 0.6891, Val Loss: 0.6911, Recon: 0.6111, KL: 0.0779
Epoch 115/200, Train Loss: 0.6900, Val Loss: 0.6871, Recon: 0.6128, KL: 0.0771
Epoch 120/200, Train Loss: 0.6884, Val Loss: 0.6753, Recon: 0.6111, KL: 0.0773
Epoch 125/200, Train Loss: 0.6879, Val Loss: 0.6793, Recon: 0.6114, KL: 0.0765
Epoch 130/200, Train Loss: 0.6904, Val Loss: 0.6882, Recon: 0.6109, KL: 0.0795
Epoch 135/200, Train Loss: 0.6879, Val Loss: 0.6834, Recon: 0.6106, KL: 0.0773
Epoch 140/200, Train Loss: 0.6880, Val Loss: 0.6831, Recon: 0.6090, KL: 0.0790
Epoch 145/200, Train Loss: 0.6881, Val Loss: 0.6852, Recon: 0.6086, KL: 0.0795
Epoch 150/200, Train Loss: 0.6877, Val Loss: 0.6804, Recon: 0.6101, KL: 0.0776
Epoch 155/200, Train Loss: 0.6866, Val Loss: 0.6815, Recon: 0.6102, KL: 0.0764
Epoch 160/200, Train Loss: 0.6858, Val Loss: 0.6846, Recon: 0.6088, KL: 0.0770
Epoch 165/200, Train Loss: 0.6899, Val Loss: 0.6835, Recon: 0.6105, KL: 0.0794
Epoch 170/200, Train Loss: 0.6856, Val Loss: 0.6812, Recon: 0.6080, KL: 0.0776
Epoch 175/200, Train Loss: 0.6879, Val Loss: 0.6810, Recon: 0.6092, KL: 0.0787
Epoch 180/200, Train Loss: 0.6886, Val Loss: 0.6820, Recon: 0.6088, KL: 0.0798
Epoch 185/200, Train Loss: 0.6864, Val Loss: 0.6871, Recon: 0.6097, KL: 0.0768
Epoch 190/200, Train Loss: 0.6863, Val Loss: 0.6837, Recon: 0.6082, KL: 0.0781
Epoch 195/200, Train Loss: 0.6865, Val Loss: 0.6819, Recon: 0.6081, KL: 0.0784
Epoch 200/200, Train Loss: 0.6868, Val Loss: 0.6812, Recon: 0.6096, KL: 0.0772
Saved model 2 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_a_l_l_all_20251022_1630/models/bootstrap_model_1.pt
Training bootstrap model 3/100
Training data shape IM MODEL: torch.Size([1560, 1142])
Epoch 1/200, Train Loss: 1.2108, Val Loss: 1.0178, Recon: 1.0306, KL: 0.1802
Epoch 5/200, Train Loss: 1.0262, Val Loss: 0.9905, Recon: 1.0227, KL: 0.0035
Epoch 10/200, Train Loss: 1.0205, Val Loss: 0.9885, Recon: 1.0197, KL: 0.0009
Epoch 15/200, Train Loss: 0.8063, Val Loss: 0.7712, Recon: 0.7124, KL: 0.0939
Epoch 20/200, Train Loss: 0.7802, Val Loss: 0.7505, Recon: 0.6883, KL: 0.0919
Epoch 25/200, Train Loss: 0.7456, Val Loss: 0.7234, Recon: 0.6545, KL: 0.0911
Epoch 30/200, Train Loss: 0.7307, Val Loss: 0.7214, Recon: 0.6418, KL: 0.0889
Epoch 35/200, Train Loss: 0.7134, Val Loss: 0.6928, Recon: 0.6305, KL: 0.0830
Epoch 40/200, Train Loss: 0.7018, Val Loss: 0.6954, Recon: 0.6204, KL: 0.0813
Epoch 45/200, Train Loss: 0.6998, Val Loss: 0.6796, Recon: 0.6182, KL: 0.0816
Epoch 50/200, Train Loss: 0.7000, Val Loss: 0.6818, Recon: 0.6189, KL: 0.0811
Epoch 55/200, Train Loss: 0.6981, Val Loss: 0.6857, Recon: 0.6149, KL: 0.0832
Epoch 60/200, Train Loss: 0.6957, Val Loss: 0.6789, Recon: 0.6145, KL: 0.0813
Epoch 65/200, Train Loss: 0.6941, Val Loss: 0.6894, Recon: 0.6131, KL: 0.0811
Epoch 70/200, Train Loss: 0.6930, Val Loss: 0.6832, Recon: 0.6112, KL: 0.0818
Epoch 75/200, Train Loss: 0.6934, Val Loss: 0.6857, Recon: 0.6122, KL: 0.0812
Epoch 80/200, Train Loss: 0.6916, Val Loss: 0.6881, Recon: 0.6112, KL: 0.0804
Epoch 85/200, Train Loss: 0.6931, Val Loss: 0.6823, Recon: 0.6119, KL: 0.0813
Epoch 90/200, Train Loss: 0.6930, Val Loss: 0.6795, Recon: 0.6116, KL: 0.0814
Epoch 95/200, Train Loss: 0.6937, Val Loss: 0.6764, Recon: 0.6123, KL: 0.0814
Epoch 100/200, Train Loss: 0.6888, Val Loss: 0.6844, Recon: 0.6087, KL: 0.0801
Epoch 105/200, Train Loss: 0.6910, Val Loss: 0.6801, Recon: 0.6098, KL: 0.0812
Epoch 110/200, Train Loss: 0.6925, Val Loss: 0.6795, Recon: 0.6101, KL: 0.0824
Epoch 115/200, Train Loss: 0.6901, Val Loss: 0.6826, Recon: 0.6083, KL: 0.0818
Epoch 120/200, Train Loss: 0.6926, Val Loss: 0.6839, Recon: 0.6106, KL: 0.0820
Epoch 125/200, Train Loss: 0.6901, Val Loss: 0.6829, Recon: 0.6080, KL: 0.0822
Epoch 130/200, Train Loss: 0.6894, Val Loss: 0.6786, Recon: 0.6088, KL: 0.0806
Epoch 135/200, Train Loss: 0.6896, Val Loss: 0.6921, Recon: 0.6070, KL: 0.0826
Epoch 140/200, Train Loss: 0.6890, Val Loss: 0.6799, Recon: 0.6063, KL: 0.0827
Epoch 145/200, Train Loss: 0.6893, Val Loss: 0.6837, Recon: 0.6072, KL: 0.0821
Epoch 150/200, Train Loss: 0.6886, Val Loss: 0.6793, Recon: 0.6081, KL: 0.0805
Epoch 155/200, Train Loss: 0.6889, Val Loss: 0.6786, Recon: 0.6070, KL: 0.0818
Epoch 160/200, Train Loss: 0.6892, Val Loss: 0.6815, Recon: 0.6071, KL: 0.0821
Epoch 165/200, Train Loss: 0.6878, Val Loss: 0.6873, Recon: 0.6069, KL: 0.0809
Epoch 170/200, Train Loss: 0.6888, Val Loss: 0.6841, Recon: 0.6071, KL: 0.0816
Epoch 175/200, Train Loss: 0.6871, Val Loss: 0.6875, Recon: 0.6058, KL: 0.0812
Epoch 180/200, Train Loss: 0.6860, Val Loss: 0.6845, Recon: 0.6060, KL: 0.0800
Epoch 185/200, Train Loss: 0.6888, Val Loss: 0.6849, Recon: 0.6069, KL: 0.0818
Epoch 190/200, Train Loss: 0.6865, Val Loss: 0.6884, Recon: 0.6061, KL: 0.0804
Epoch 195/200, Train Loss: 0.6898, Val Loss: 0.6831, Recon: 0.6072, KL: 0.0826
Epoch 200/200, Train Loss: 0.6882, Val Loss: 0.6801, Recon: 0.6053, KL: 0.0829
Saved model 3 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_a_l_l_all_20251022_1630/models/bootstrap_model_2.pt
Training bootstrap model 4/100
Training data shape IM MODEL: torch.Size([1560, 1142])
Epoch 1/200, Train Loss: 1.1969, Val Loss: 1.0262, Recon: 1.0268, KL: 0.1701
Epoch 5/200, Train Loss: 1.0209, Val Loss: 0.9908, Recon: 1.0180, KL: 0.0028
Epoch 10/200, Train Loss: 1.0186, Val Loss: 0.9914, Recon: 1.0176, KL: 0.0011
Epoch 15/200, Train Loss: 0.8001, Val Loss: 0.7515, Recon: 0.7129, KL: 0.0872
Epoch 20/200, Train Loss: 0.7496, Val Loss: 0.7063, Recon: 0.6671, KL: 0.0825
Epoch 25/200, Train Loss: 0.7176, Val Loss: 0.6848, Recon: 0.6402, KL: 0.0773
Epoch 30/200, Train Loss: 0.7169, Val Loss: 0.6843, Recon: 0.6361, KL: 0.0808
Epoch 35/200, Train Loss: 0.7132, Val Loss: 0.6855, Recon: 0.6321, KL: 0.0811
Epoch 40/200, Train Loss: 0.7106, Val Loss: 0.6851, Recon: 0.6294, KL: 0.0812
Epoch 45/200, Train Loss: 0.7051, Val Loss: 0.6836, Recon: 0.6244, KL: 0.0807
Epoch 50/200, Train Loss: 0.7087, Val Loss: 0.6864, Recon: 0.6281, KL: 0.0805
Epoch 55/200, Train Loss: 0.7095, Val Loss: 0.6781, Recon: 0.6282, KL: 0.0813
Epoch 60/200, Train Loss: 0.7084, Val Loss: 0.6861, Recon: 0.6267, KL: 0.0816
Epoch 65/200, Train Loss: 0.7075, Val Loss: 0.6842, Recon: 0.6266, KL: 0.0809
Epoch 70/200, Train Loss: 0.7035, Val Loss: 0.6843, Recon: 0.6229, KL: 0.0806
Epoch 75/200, Train Loss: 0.7047, Val Loss: 0.6803, Recon: 0.6237, KL: 0.0811
Epoch 80/200, Train Loss: 0.7047, Val Loss: 0.6847, Recon: 0.6231, KL: 0.0816
Epoch 85/200, Train Loss: 0.7054, Val Loss: 0.6827, Recon: 0.6244, KL: 0.0810
Epoch 90/200, Train Loss: 0.7064, Val Loss: 0.6896, Recon: 0.6259, KL: 0.0805
Epoch 95/200, Train Loss: 0.7016, Val Loss: 0.6830, Recon: 0.6204, KL: 0.0812
Epoch 100/200, Train Loss: 0.7058, Val Loss: 0.6847, Recon: 0.6239, KL: 0.0820
Epoch 105/200, Train Loss: 0.7033, Val Loss: 0.6854, Recon: 0.6226, KL: 0.0807
Epoch 110/200, Train Loss: 0.7025, Val Loss: 0.6790, Recon: 0.6211, KL: 0.0813
Epoch 115/200, Train Loss: 0.7038, Val Loss: 0.6867, Recon: 0.6223, KL: 0.0816
Epoch 120/200, Train Loss: 0.7001, Val Loss: 0.6795, Recon: 0.6199, KL: 0.0802
Epoch 125/200, Train Loss: 0.7017, Val Loss: 0.6845, Recon: 0.6217, KL: 0.0800
Epoch 130/200, Train Loss: 0.7011, Val Loss: 0.6896, Recon: 0.6208, KL: 0.0803
Epoch 135/200, Train Loss: 0.7014, Val Loss: 0.6766, Recon: 0.6196, KL: 0.0817
Epoch 140/200, Train Loss: 0.7024, Val Loss: 0.6848, Recon: 0.6210, KL: 0.0814
Epoch 145/200, Train Loss: 0.7013, Val Loss: 0.6840, Recon: 0.6207, KL: 0.0805
Epoch 150/200, Train Loss: 0.6993, Val Loss: 0.6827, Recon: 0.6188, KL: 0.0805
Epoch 155/200, Train Loss: 0.6986, Val Loss: 0.6821, Recon: 0.6179, KL: 0.0808
Epoch 160/200, Train Loss: 0.6986, Val Loss: 0.6817, Recon: 0.6173, KL: 0.0814
Epoch 165/200, Train Loss: 0.6990, Val Loss: 0.6847, Recon: 0.6187, KL: 0.0802
Epoch 170/200, Train Loss: 0.7021, Val Loss: 0.6821, Recon: 0.6200, KL: 0.0821
Epoch 175/200, Train Loss: 0.6999, Val Loss: 0.6826, Recon: 0.6174, KL: 0.0825
Epoch 180/200, Train Loss: 0.6976, Val Loss: 0.6846, Recon: 0.6176, KL: 0.0800
Epoch 185/200, Train Loss: 0.6981, Val Loss: 0.6855, Recon: 0.6164, KL: 0.0818
Epoch 190/200, Train Loss: 0.6975, Val Loss: 0.6768, Recon: 0.6167, KL: 0.0809
Epoch 195/200, Train Loss: 0.6936, Val Loss: 0.6825, Recon: 0.6135, KL: 0.0801
Epoch 200/200, Train Loss: 0.6978, Val Loss: 0.6836, Recon: 0.6169, KL: 0.0809
Saved model 4 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_a_l_l_all_20251022_1630/models/bootstrap_model_3.pt
Training bootstrap model 5/100
Training data shape IM MODEL: torch.Size([1560, 1142])
Epoch 1/200, Train Loss: 1.1231, Val Loss: 1.0084, Recon: 1.0035, KL: 0.1195
Epoch 5/200, Train Loss: 0.9952, Val Loss: 0.9861, Recon: 0.9924, KL: 0.0028
Epoch 10/200, Train Loss: 0.7852, Val Loss: 0.7545, Recon: 0.6974, KL: 0.0878
Epoch 15/200, Train Loss: 0.7687, Val Loss: 0.7404, Recon: 0.6837, KL: 0.0850
Epoch 20/200, Train Loss: 0.7471, Val Loss: 0.7283, Recon: 0.6622, KL: 0.0849
Epoch 25/200, Train Loss: 0.7420, Val Loss: 0.7216, Recon: 0.6511, KL: 0.0910
Epoch 30/200, Train Loss: 0.7361, Val Loss: 0.7157, Recon: 0.6476, KL: 0.0885
Epoch 35/200, Train Loss: 0.7192, Val Loss: 0.7069, Recon: 0.6339, KL: 0.0853
Epoch 40/200, Train Loss: 0.7013, Val Loss: 0.6921, Recon: 0.6241, KL: 0.0772
Epoch 45/200, Train Loss: 0.7016, Val Loss: 0.6934, Recon: 0.6206, KL: 0.0811
Epoch 50/200, Train Loss: 0.6992, Val Loss: 0.6861, Recon: 0.6202, KL: 0.0790
Epoch 55/200, Train Loss: 0.6962, Val Loss: 0.6841, Recon: 0.6185, KL: 0.0777
Epoch 60/200, Train Loss: 0.6975, Val Loss: 0.6883, Recon: 0.6173, KL: 0.0802
Epoch 65/200, Train Loss: 0.6965, Val Loss: 0.6827, Recon: 0.6169, KL: 0.0796
Epoch 70/200, Train Loss: 0.6955, Val Loss: 0.6848, Recon: 0.6165, KL: 0.0789
Epoch 75/200, Train Loss: 0.6934, Val Loss: 0.6860, Recon: 0.6149, KL: 0.0785
Epoch 80/200, Train Loss: 0.6981, Val Loss: 0.6805, Recon: 0.6178, KL: 0.0802
Epoch 85/200, Train Loss: 0.6957, Val Loss: 0.6838, Recon: 0.6170, KL: 0.0788
Epoch 90/200, Train Loss: 0.6958, Val Loss: 0.6861, Recon: 0.6168, KL: 0.0790
Epoch 95/200, Train Loss: 0.6944, Val Loss: 0.6819, Recon: 0.6144, KL: 0.0799
Epoch 100/200, Train Loss: 0.7013, Val Loss: 0.6826, Recon: 0.6200, KL: 0.0813
Epoch 105/200, Train Loss: 0.6969, Val Loss: 0.6781, Recon: 0.6170, KL: 0.0799
Epoch 110/200, Train Loss: 0.6943, Val Loss: 0.6823, Recon: 0.6164, KL: 0.0779
Epoch 115/200, Train Loss: 0.6946, Val Loss: 0.6877, Recon: 0.6136, KL: 0.0810
Epoch 120/200, Train Loss: 0.6950, Val Loss: 0.6832, Recon: 0.6144, KL: 0.0806
Epoch 125/200, Train Loss: 0.6927, Val Loss: 0.6841, Recon: 0.6141, KL: 0.0786
Epoch 130/200, Train Loss: 0.6937, Val Loss: 0.6859, Recon: 0.6139, KL: 0.0798
Epoch 135/200, Train Loss: 0.6938, Val Loss: 0.6841, Recon: 0.6127, KL: 0.0811
Epoch 140/200, Train Loss: 0.6934, Val Loss: 0.6821, Recon: 0.6133, KL: 0.0801
Epoch 145/200, Train Loss: 0.6937, Val Loss: 0.6802, Recon: 0.6135, KL: 0.0803
Epoch 150/200, Train Loss: 0.6942, Val Loss: 0.6823, Recon: 0.6135, KL: 0.0807
Epoch 155/200, Train Loss: 0.6928, Val Loss: 0.6812, Recon: 0.6144, KL: 0.0783
Epoch 160/200, Train Loss: 0.6932, Val Loss: 0.6856, Recon: 0.6139, KL: 0.0793
Epoch 165/200, Train Loss: 0.6934, Val Loss: 0.6819, Recon: 0.6126, KL: 0.0808
Epoch 170/200, Train Loss: 0.6958, Val Loss: 0.6852, Recon: 0.6155, KL: 0.0803
Epoch 175/200, Train Loss: 0.6962, Val Loss: 0.6850, Recon: 0.6147, KL: 0.0815
Epoch 180/200, Train Loss: 0.6915, Val Loss: 0.6818, Recon: 0.6114, KL: 0.0801
Epoch 185/200, Train Loss: 0.6934, Val Loss: 0.6903, Recon: 0.6124, KL: 0.0809
Epoch 190/200, Train Loss: 0.6928, Val Loss: 0.6902, Recon: 0.6135, KL: 0.0793
Epoch 195/200, Train Loss: 0.6931, Val Loss: 0.6827, Recon: 0.6136, KL: 0.0795
Epoch 200/200, Train Loss: 0.6931, Val Loss: 0.6862, Recon: 0.6126, KL: 0.0805
Saved model 5 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_a_l_l_all_20251022_1630/models/bootstrap_model_4.pt
Training bootstrap model 6/100
Training data shape IM MODEL: torch.Size([1560, 1142])
Epoch 1/200, Train Loss: 1.2016, Val Loss: 1.0152, Recon: 1.0346, KL: 0.1670
Epoch 5/200, Train Loss: 1.0297, Val Loss: 0.9921, Recon: 1.0262, KL: 0.0036
Epoch 10/200, Train Loss: 0.7880, Val Loss: 0.7562, Recon: 0.7005, KL: 0.0875
Epoch 15/200, Train Loss: 0.7677, Val Loss: 0.7428, Recon: 0.6787, KL: 0.0890
Epoch 20/200, Train Loss: 0.7175, Val Loss: 0.6945, Recon: 0.6380, KL: 0.0795
Epoch 25/200, Train Loss: 0.7088, Val Loss: 0.6890, Recon: 0.6293, KL: 0.0795
Epoch 30/200, Train Loss: 0.7060, Val Loss: 0.7031, Recon: 0.6259, KL: 0.0801
Epoch 35/200, Train Loss: 0.7046, Val Loss: 0.6847, Recon: 0.6226, KL: 0.0820
Epoch 40/200, Train Loss: 0.7035, Val Loss: 0.6878, Recon: 0.6226, KL: 0.0808
Epoch 45/200, Train Loss: 0.7018, Val Loss: 0.6857, Recon: 0.6210, KL: 0.0808
Epoch 50/200, Train Loss: 0.7025, Val Loss: 0.6885, Recon: 0.6215, KL: 0.0810
Epoch 55/200, Train Loss: 0.7007, Val Loss: 0.6794, Recon: 0.6197, KL: 0.0810
Epoch 60/200, Train Loss: 0.6998, Val Loss: 0.6881, Recon: 0.6197, KL: 0.0800
Epoch 65/200, Train Loss: 0.6998, Val Loss: 0.6829, Recon: 0.6184, KL: 0.0813
Epoch 70/200, Train Loss: 0.7025, Val Loss: 0.6858, Recon: 0.6199, KL: 0.0825
Epoch 75/200, Train Loss: 0.7025, Val Loss: 0.6800, Recon: 0.6210, KL: 0.0814
Epoch 80/200, Train Loss: 0.7004, Val Loss: 0.6838, Recon: 0.6192, KL: 0.0812
Epoch 85/200, Train Loss: 0.6992, Val Loss: 0.6852, Recon: 0.6182, KL: 0.0810
Epoch 90/200, Train Loss: 0.7010, Val Loss: 0.6825, Recon: 0.6182, KL: 0.0828
Epoch 95/200, Train Loss: 0.6996, Val Loss: 0.6868, Recon: 0.6178, KL: 0.0819
Epoch 100/200, Train Loss: 0.6988, Val Loss: 0.6802, Recon: 0.6163, KL: 0.0825
Epoch 105/200, Train Loss: 0.6971, Val Loss: 0.6822, Recon: 0.6160, KL: 0.0811
Epoch 110/200, Train Loss: 0.6922, Val Loss: 0.6809, Recon: 0.6115, KL: 0.0807
Epoch 115/200, Train Loss: 0.6955, Val Loss: 0.6860, Recon: 0.6142, KL: 0.0814
Epoch 120/200, Train Loss: 0.6992, Val Loss: 0.6802, Recon: 0.6182, KL: 0.0810
Epoch 125/200, Train Loss: 0.6941, Val Loss: 0.6827, Recon: 0.6125, KL: 0.0816
Epoch 130/200, Train Loss: 0.6969, Val Loss: 0.6878, Recon: 0.6155, KL: 0.0814
Epoch 135/200, Train Loss: 0.6962, Val Loss: 0.6862, Recon: 0.6141, KL: 0.0821
Epoch 140/200, Train Loss: 0.6923, Val Loss: 0.6822, Recon: 0.6114, KL: 0.0809
Epoch 145/200, Train Loss: 0.6961, Val Loss: 0.6806, Recon: 0.6139, KL: 0.0823
Epoch 150/200, Train Loss: 0.6959, Val Loss: 0.6881, Recon: 0.6133, KL: 0.0826
Epoch 155/200, Train Loss: 0.6984, Val Loss: 0.6895, Recon: 0.6161, KL: 0.0824
Epoch 160/200, Train Loss: 0.6936, Val Loss: 0.6822, Recon: 0.6129, KL: 0.0807
Epoch 165/200, Train Loss: 0.6941, Val Loss: 0.6838, Recon: 0.6140, KL: 0.0801
Epoch 170/200, Train Loss: 0.6942, Val Loss: 0.6904, Recon: 0.6135, KL: 0.0807
Epoch 175/200, Train Loss: 0.6925, Val Loss: 0.6874, Recon: 0.6111, KL: 0.0814
Epoch 180/200, Train Loss: 0.6951, Val Loss: 0.6887, Recon: 0.6140, KL: 0.0811
Epoch 185/200, Train Loss: 0.6952, Val Loss: 0.6867, Recon: 0.6138, KL: 0.0814
Epoch 190/200, Train Loss: 0.6925, Val Loss: 0.6831, Recon: 0.6120, KL: 0.0805
Epoch 195/200, Train Loss: 0.6959, Val Loss: 0.6832, Recon: 0.6128, KL: 0.0831
Epoch 200/200, Train Loss: 0.6918, Val Loss: 0.6862, Recon: 0.6128, KL: 0.0791
Saved model 6 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_a_l_l_all_20251022_1630/models/bootstrap_model_5.pt
Training bootstrap model 7/100
Training data shape IM MODEL: torch.Size([1560, 1142])
Epoch 1/200, Train Loss: 1.1717, Val Loss: 1.0152, Recon: 1.0261, KL: 0.1456
Epoch 5/200, Train Loss: 0.8107, Val Loss: 0.7696, Recon: 0.7193, KL: 0.0914
Epoch 10/200, Train Loss: 0.7666, Val Loss: 0.7504, Recon: 0.6781, KL: 0.0885
Epoch 15/200, Train Loss: 0.7333, Val Loss: 0.7130, Recon: 0.6443, KL: 0.0890
Epoch 20/200, Train Loss: 0.7009, Val Loss: 0.6908, Recon: 0.6195, KL: 0.0815
Epoch 25/200, Train Loss: 0.7000, Val Loss: 0.6867, Recon: 0.6184, KL: 0.0816
Epoch 30/200, Train Loss: 0.6954, Val Loss: 0.6841, Recon: 0.6117, KL: 0.0838
Epoch 35/200, Train Loss: 0.6923, Val Loss: 0.6832, Recon: 0.6102, KL: 0.0820
Epoch 40/200, Train Loss: 0.6962, Val Loss: 0.6865, Recon: 0.6129, KL: 0.0833
Epoch 45/200, Train Loss: 0.6930, Val Loss: 0.6822, Recon: 0.6099, KL: 0.0831
Epoch 50/200, Train Loss: 0.6914, Val Loss: 0.6835, Recon: 0.6096, KL: 0.0818
Epoch 55/200, Train Loss: 0.6885, Val Loss: 0.6838, Recon: 0.6078, KL: 0.0807
Epoch 60/200, Train Loss: 0.6929, Val Loss: 0.6822, Recon: 0.6098, KL: 0.0831
Epoch 65/200, Train Loss: 0.6896, Val Loss: 0.6816, Recon: 0.6076, KL: 0.0820
Epoch 70/200, Train Loss: 0.6885, Val Loss: 0.6801, Recon: 0.6055, KL: 0.0830
Epoch 75/200, Train Loss: 0.6888, Val Loss: 0.6830, Recon: 0.6076, KL: 0.0811
Epoch 80/200, Train Loss: 0.6880, Val Loss: 0.6868, Recon: 0.6064, KL: 0.0817
Epoch 85/200, Train Loss: 0.6877, Val Loss: 0.6861, Recon: 0.6070, KL: 0.0806
Epoch 90/200, Train Loss: 0.6865, Val Loss: 0.6917, Recon: 0.6053, KL: 0.0812
Epoch 95/200, Train Loss: 0.6909, Val Loss: 0.6828, Recon: 0.6087, KL: 0.0822
Epoch 100/200, Train Loss: 0.6865, Val Loss: 0.6842, Recon: 0.6055, KL: 0.0809
Epoch 105/200, Train Loss: 0.6882, Val Loss: 0.6841, Recon: 0.6074, KL: 0.0807
Epoch 110/200, Train Loss: 0.6874, Val Loss: 0.6844, Recon: 0.6050, KL: 0.0823
Epoch 115/200, Train Loss: 0.6863, Val Loss: 0.6818, Recon: 0.6035, KL: 0.0827
Epoch 120/200, Train Loss: 0.6877, Val Loss: 0.6803, Recon: 0.6061, KL: 0.0816
Epoch 125/200, Train Loss: 0.6861, Val Loss: 0.6812, Recon: 0.6037, KL: 0.0824
Epoch 130/200, Train Loss: 0.6862, Val Loss: 0.6844, Recon: 0.6040, KL: 0.0821
Epoch 135/200, Train Loss: 0.6821, Val Loss: 0.6842, Recon: 0.6007, KL: 0.0814
Epoch 140/200, Train Loss: 0.6865, Val Loss: 0.6862, Recon: 0.6042, KL: 0.0823
Epoch 145/200, Train Loss: 0.6856, Val Loss: 0.6880, Recon: 0.6026, KL: 0.0831
Epoch 150/200, Train Loss: 0.6855, Val Loss: 0.6845, Recon: 0.6038, KL: 0.0818
Epoch 155/200, Train Loss: 0.6852, Val Loss: 0.6871, Recon: 0.6041, KL: 0.0811
Epoch 160/200, Train Loss: 0.6850, Val Loss: 0.6859, Recon: 0.6022, KL: 0.0828
Epoch 165/200, Train Loss: 0.6855, Val Loss: 0.6841, Recon: 0.6034, KL: 0.0821
Epoch 170/200, Train Loss: 0.6840, Val Loss: 0.6827, Recon: 0.6025, KL: 0.0815
Epoch 175/200, Train Loss: 0.6843, Val Loss: 0.6859, Recon: 0.6009, KL: 0.0834
Epoch 180/200, Train Loss: 0.6831, Val Loss: 0.6836, Recon: 0.6000, KL: 0.0831
Epoch 185/200, Train Loss: 0.6836, Val Loss: 0.6793, Recon: 0.6026, KL: 0.0810
Epoch 190/200, Train Loss: 0.6829, Val Loss: 0.6806, Recon: 0.6000, KL: 0.0829
Epoch 195/200, Train Loss: 0.6842, Val Loss: 0.6845, Recon: 0.6021, KL: 0.0821
Epoch 200/200, Train Loss: 0.6850, Val Loss: 0.6838, Recon: 0.6027, KL: 0.0823
Saved model 7 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_a_l_l_all_20251022_1630/models/bootstrap_model_6.pt
Training bootstrap model 8/100
Training data shape IM MODEL: torch.Size([1560, 1142])
Epoch 1/200, Train Loss: 1.1762, Val Loss: 1.0244, Recon: 1.0098, KL: 0.1664
Epoch 5/200, Train Loss: 1.0038, Val Loss: 0.9882, Recon: 1.0000, KL: 0.0038
Epoch 10/200, Train Loss: 0.7860, Val Loss: 0.7619, Recon: 0.7012, KL: 0.0849
Epoch 15/200, Train Loss: 0.7845, Val Loss: 0.7545, Recon: 0.6979, KL: 0.0866
Epoch 20/200, Train Loss: 0.7682, Val Loss: 0.7493, Recon: 0.6817, KL: 0.0866
Epoch 25/200, Train Loss: 0.7569, Val Loss: 0.7289, Recon: 0.6716, KL: 0.0853
Epoch 30/200, Train Loss: 0.7233, Val Loss: 0.6999, Recon: 0.6443, KL: 0.0790
Epoch 35/200, Train Loss: 0.7074, Val Loss: 0.6884, Recon: 0.6309, KL: 0.0764
Epoch 40/200, Train Loss: 0.7066, Val Loss: 0.6877, Recon: 0.6280, KL: 0.0785
Epoch 45/200, Train Loss: 0.7036, Val Loss: 0.6856, Recon: 0.6251, KL: 0.0785
Epoch 50/200, Train Loss: 0.7056, Val Loss: 0.6911, Recon: 0.6249, KL: 0.0807
Epoch 55/200, Train Loss: 0.7055, Val Loss: 0.6837, Recon: 0.6268, KL: 0.0786
Epoch 60/200, Train Loss: 0.7018, Val Loss: 0.6874, Recon: 0.6226, KL: 0.0792
Epoch 65/200, Train Loss: 0.7042, Val Loss: 0.6827, Recon: 0.6250, KL: 0.0793
Epoch 70/200, Train Loss: 0.7016, Val Loss: 0.6891, Recon: 0.6221, KL: 0.0795
Epoch 75/200, Train Loss: 0.7011, Val Loss: 0.6878, Recon: 0.6230, KL: 0.0781
Epoch 80/200, Train Loss: 0.7017, Val Loss: 0.6805, Recon: 0.6224, KL: 0.0793
Epoch 85/200, Train Loss: 0.6993, Val Loss: 0.6832, Recon: 0.6210, KL: 0.0783
Epoch 90/200, Train Loss: 0.6998, Val Loss: 0.6817, Recon: 0.6209, KL: 0.0789
Epoch 95/200, Train Loss: 0.7002, Val Loss: 0.6864, Recon: 0.6220, KL: 0.0781
Epoch 100/200, Train Loss: 0.7003, Val Loss: 0.6829, Recon: 0.6201, KL: 0.0802
Epoch 105/200, Train Loss: 0.6991, Val Loss: 0.6878, Recon: 0.6200, KL: 0.0791
Epoch 110/200, Train Loss: 0.6989, Val Loss: 0.6856, Recon: 0.6201, KL: 0.0788
Epoch 115/200, Train Loss: 0.7010, Val Loss: 0.6803, Recon: 0.6213, KL: 0.0797
Epoch 120/200, Train Loss: 0.6983, Val Loss: 0.6796, Recon: 0.6200, KL: 0.0782
Epoch 125/200, Train Loss: 0.7011, Val Loss: 0.6841, Recon: 0.6222, KL: 0.0789
Epoch 130/200, Train Loss: 0.6968, Val Loss: 0.6847, Recon: 0.6182, KL: 0.0786
Epoch 135/200, Train Loss: 0.7013, Val Loss: 0.6781, Recon: 0.6211, KL: 0.0802
Epoch 140/200, Train Loss: 0.6984, Val Loss: 0.6812, Recon: 0.6193, KL: 0.0792
Epoch 145/200, Train Loss: 0.7000, Val Loss: 0.6838, Recon: 0.6208, KL: 0.0792
Epoch 150/200, Train Loss: 0.6968, Val Loss: 0.6898, Recon: 0.6178, KL: 0.0789
Epoch 155/200, Train Loss: 0.6982, Val Loss: 0.6840, Recon: 0.6206, KL: 0.0776
Epoch 160/200, Train Loss: 0.6997, Val Loss: 0.6829, Recon: 0.6194, KL: 0.0804
Epoch 165/200, Train Loss: 0.6967, Val Loss: 0.6827, Recon: 0.6181, KL: 0.0787
Epoch 170/200, Train Loss: 0.6981, Val Loss: 0.6858, Recon: 0.6193, KL: 0.0788
Epoch 175/200, Train Loss: 0.6949, Val Loss: 0.6843, Recon: 0.6165, KL: 0.0784
Epoch 180/200, Train Loss: 0.6957, Val Loss: 0.6797, Recon: 0.6168, KL: 0.0789
Epoch 185/200, Train Loss: 0.6980, Val Loss: 0.6797, Recon: 0.6179, KL: 0.0801
Epoch 190/200, Train Loss: 0.6972, Val Loss: 0.6837, Recon: 0.6186, KL: 0.0786
Epoch 195/200, Train Loss: 0.6954, Val Loss: 0.6886, Recon: 0.6179, KL: 0.0775
Epoch 200/200, Train Loss: 0.6955, Val Loss: 0.6793, Recon: 0.6171, KL: 0.0784
Saved model 8 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_a_l_l_all_20251022_1630/models/bootstrap_model_7.pt
Training bootstrap model 9/100
Training data shape IM MODEL: torch.Size([1560, 1142])
Epoch 1/200, Train Loss: 1.2305, Val Loss: 1.0393, Recon: 1.0076, KL: 0.2229
Epoch 5/200, Train Loss: 1.0048, Val Loss: 0.9934, Recon: 0.9984, KL: 0.0063
Epoch 10/200, Train Loss: 0.8095, Val Loss: 0.7810, Recon: 0.7130, KL: 0.0965
Epoch 15/200, Train Loss: 0.7571, Val Loss: 0.7480, Recon: 0.6711, KL: 0.0859
Epoch 20/200, Train Loss: 0.7159, Val Loss: 0.6970, Recon: 0.6366, KL: 0.0793
Epoch 25/200, Train Loss: 0.7033, Val Loss: 0.6915, Recon: 0.6251, KL: 0.0782
Epoch 30/200, Train Loss: 0.7000, Val Loss: 0.6862, Recon: 0.6213, KL: 0.0787
Epoch 35/200, Train Loss: 0.6950, Val Loss: 0.6906, Recon: 0.6167, KL: 0.0783
Epoch 40/200, Train Loss: 0.6977, Val Loss: 0.6843, Recon: 0.6179, KL: 0.0798
Epoch 45/200, Train Loss: 0.6945, Val Loss: 0.6881, Recon: 0.6148, KL: 0.0797
Epoch 50/200, Train Loss: 0.6943, Val Loss: 0.6857, Recon: 0.6142, KL: 0.0802
Epoch 55/200, Train Loss: 0.6919, Val Loss: 0.6845, Recon: 0.6116, KL: 0.0803
Epoch 60/200, Train Loss: 0.6912, Val Loss: 0.6843, Recon: 0.6120, KL: 0.0792
Epoch 65/200, Train Loss: 0.6918, Val Loss: 0.6890, Recon: 0.6110, KL: 0.0808
Epoch 70/200, Train Loss: 0.6902, Val Loss: 0.6795, Recon: 0.6123, KL: 0.0779
Epoch 75/200, Train Loss: 0.6928, Val Loss: 0.6815, Recon: 0.6111, KL: 0.0817
Epoch 80/200, Train Loss: 0.6900, Val Loss: 0.6872, Recon: 0.6091, KL: 0.0808
Epoch 85/200, Train Loss: 0.6896, Val Loss: 0.6795, Recon: 0.6092, KL: 0.0804
Epoch 90/200, Train Loss: 0.6917, Val Loss: 0.6806, Recon: 0.6104, KL: 0.0812
Epoch 95/200, Train Loss: 0.6901, Val Loss: 0.6792, Recon: 0.6091, KL: 0.0810
Epoch 100/200, Train Loss: 0.6903, Val Loss: 0.6819, Recon: 0.6109, KL: 0.0794
Epoch 105/200, Train Loss: 0.6894, Val Loss: 0.6846, Recon: 0.6090, KL: 0.0804
Epoch 110/200, Train Loss: 0.6892, Val Loss: 0.6847, Recon: 0.6096, KL: 0.0796
Epoch 115/200, Train Loss: 0.6879, Val Loss: 0.6899, Recon: 0.6077, KL: 0.0801
Epoch 120/200, Train Loss: 0.6872, Val Loss: 0.6815, Recon: 0.6061, KL: 0.0811
Epoch 125/200, Train Loss: 0.6863, Val Loss: 0.6858, Recon: 0.6056, KL: 0.0808
Epoch 130/200, Train Loss: 0.6877, Val Loss: 0.6793, Recon: 0.6084, KL: 0.0793
Epoch 135/200, Train Loss: 0.6888, Val Loss: 0.6841, Recon: 0.6078, KL: 0.0810
Epoch 140/200, Train Loss: 0.6890, Val Loss: 0.6820, Recon: 0.6065, KL: 0.0825
Epoch 145/200, Train Loss: 0.6854, Val Loss: 0.6814, Recon: 0.6059, KL: 0.0795
Epoch 150/200, Train Loss: 0.6839, Val Loss: 0.6780, Recon: 0.6049, KL: 0.0789
Epoch 155/200, Train Loss: 0.6868, Val Loss: 0.6850, Recon: 0.6069, KL: 0.0799
Epoch 160/200, Train Loss: 0.6855, Val Loss: 0.6788, Recon: 0.6059, KL: 0.0796
Epoch 165/200, Train Loss: 0.6862, Val Loss: 0.6832, Recon: 0.6060, KL: 0.0801
Epoch 170/200, Train Loss: 0.6854, Val Loss: 0.6829, Recon: 0.6050, KL: 0.0805
Epoch 175/200, Train Loss: 0.6860, Val Loss: 0.6763, Recon: 0.6049, KL: 0.0811
Epoch 180/200, Train Loss: 0.6827, Val Loss: 0.6890, Recon: 0.6030, KL: 0.0797
Epoch 185/200, Train Loss: 0.6827, Val Loss: 0.6826, Recon: 0.6029, KL: 0.0798
Epoch 190/200, Train Loss: 0.6854, Val Loss: 0.6809, Recon: 0.6048, KL: 0.0806
Epoch 195/200, Train Loss: 0.6848, Val Loss: 0.6798, Recon: 0.6038, KL: 0.0810
Epoch 200/200, Train Loss: 0.6860, Val Loss: 0.6827, Recon: 0.6056, KL: 0.0804
Saved model 9 to /net/data.isilon/ag-cherrmann/lduttenhoefer/project/VAE_model/analysis/TRAINING/norm_results_HC_a_l_l_all_20251022_1630/models/bootstrap_model_8.pt
Training bootstrap model 10/100
Training data shape IM MODEL: torch.Size([1560, 1142])
Epoch 1/200, Train Loss: 1.1805, Val Loss: 1.0163, Recon: 1.0424, KL: 0.1380
Epoch 5/200, Train Loss: 1.0364, Val Loss: 0.9879, Recon: 1.0338, KL: 0.0027
Epoch 10/200, Train Loss: 0.7977, Val Loss: 0.7556, Recon: 0.7048, KL: 0.0929
Epoch 15/200, Train Loss: 0.7710, Val Loss: 0.7348, Recon: 0.6810, KL: 0.0899
Epoch 20/200, Train Loss: 0.7422, Val Loss: 0.7273, Recon: 0.6524, KL: 0.0898
Epoch 25/200, Train Loss: 0.7166, Val Loss: 0.6947, Recon: 0.6314, KL: 0.0852
Epoch 30/200, Train Loss: 0.7038, Val Loss: 0.6838, Recon: 0.6206, KL: 0.0832
Epoch 35/200, Train Loss: 0.7025, Val Loss: 0.6850, Recon: 0.6189, KL: 0.0836
Epoch 40/200, Train Loss: 0.6987, Val Loss: 0.6846, Recon: 0.6180, KL: 0.0807
Epoch 45/200, Train Loss: 0.6970, Val Loss: 0.6809, Recon: 0.6156, KL: 0.0814
Epoch 50/200, Train Loss: 0.7001, Val Loss: 0.6825, Recon: 0.6162, KL: 0.0840
Epoch 55/200, Train Loss: 0.7001, Val Loss: 0.6831, Recon: 0.6169, KL: 0.0831
Epoch 60/200, Train Loss: 0.6964, Val Loss: 0.6834, Recon: 0.6134, KL: 0.0831
Epoch 65/200, Train Loss: 0.6954, Val Loss: 0.6843, Recon: 0.6144, KL: 0.0811
Epoch 70/200, Train Loss: 0.6931, Val Loss: 0.6830, Recon: 0.6121, KL: 0.0810
Epoch 75/200, Train Loss: 0.6967, Val Loss: 0.6887, Recon: 0.6118, KL: 0.0849
Epoch 80/200, Train Loss: 0.6953, Val Loss: 0.6842, Recon: 0.6117, KL: 0.0836
Epoch 85/200, Train Loss: 0.6946, Val Loss: 0.6807, Recon: 0.6129, KL: 0.0817
Epoch 90/200, Train Loss: 0.6933, Val Loss: 0.6874, Recon: 0.6108, KL: 0.0825
Epoch 95/200, Train Loss: 0.6928, Val Loss: 0.6916, Recon: 0.6099, KL: 0.0829
Epoch 100/200, Train Loss: 0.6965, Val Loss: 0.6805, Recon: 0.6138, KL: 0.0827
Epoch 105/200, Train Loss: 0.6933, Val Loss: 0.6844, Recon: 0.6095, KL: 0.0838
Epoch 110/200, Train Loss: 0.6940, Val Loss: 0.6874, Recon: 0.6107, KL: 0.0833
Epoch 115/200, Train Loss: 0.6920, Val Loss: 0.6827, Recon: 0.6100, KL: 0.0820
